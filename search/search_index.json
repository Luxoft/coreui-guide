{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to QML Core UI Guide Info This material is work in progress and will change! Preface When you are part of a team that works on Qt Automotive Suite (short - Qt Auto), as Qt's vertical extension into the automotive market, you always wonder how new customers will approach Qt Auto, and how they will adapt it to their needs to create a truly stunning user experience for their automotive customers. From our research projects and production projects with various customers, we have gained valuable insights into this interesting market. Each project has its own unique constellation of management, design, development, and partnerships. This guide attempts to lay out the ground for a discussion about creating user interfaces wich scale using technologies including in Qt Auto, using an architecture we named the Core UI architecture. Naturally, customers shall be motivated to deviate from this Core UI Guide where necessary. This guide helps customers to get a base for fundamental discussions, internally and externally and hopefully the support required to come to a conclusion that helps them to achieve their own goals. / jryannel Why A fundamental aspect of creating an architecture is to define a vocabulary and vision of that architecture. Most of the work in this guide is funded by Luxoft, an engineering services company. You may wonder why a service company is willing to publish essential knowledge in open source under fairly permissive licenses. This is because, when we conduct customer projects in the UI domain, we have noticed certain recurring patterns. Our philosophy is not based on watching customers stumble over the same problems. Instead, we would like to be part of the solution, and prevent these problems from recurring in the first place. In this guide, you will see many mentions of \"automotive\". This starts with the name \"Qt Automotive Suite\". Automotive has various specifics aspects. The same applies to embedded hardware and software in the Industrial sector. They have one interesting thing in common: they speak about Human Machine Interface (HMI) or about Man-Machine Interface (MMI), whereas HighTech speaks about User Interfaces (UI). User Experience (UX) is still known in Automotive, but for a long time, it mostly was in terms of interior of the car and all about using buttons, switches, and pedals arranged around the steering wheel. In the course of convergence and digitalization, Automotive started to invest in making interfaces for users and less for machines and in seeing this as essential part of UX. We firmly believe that the Industrial sector and Embedded in general will follow this trend soon to and benefit from this guide. The Team This guide was initially designed and worked out as part of the Qt Auto effort at Luxoft. Being part of a team means the author is not the only contributor. Others contributed by ideas, converstations or even contributions. I would like to thank the Qt Auto team at Luxoft to allow me to write this guide as part of my daily work License Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free > Documentation License (FDL) version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. The code samples in this document are provided under BSD 3-Clause \"New\" or \"Revised\" License as published by the SPDX Workgroup a Linux Foundation Project","title":"Overview"},{"location":"#welcome-to-qml-core-ui-guide","text":"Info This material is work in progress and will change!","title":"Welcome to QML Core UI Guide"},{"location":"#preface","text":"When you are part of a team that works on Qt Automotive Suite (short - Qt Auto), as Qt's vertical extension into the automotive market, you always wonder how new customers will approach Qt Auto, and how they will adapt it to their needs to create a truly stunning user experience for their automotive customers. From our research projects and production projects with various customers, we have gained valuable insights into this interesting market. Each project has its own unique constellation of management, design, development, and partnerships. This guide attempts to lay out the ground for a discussion about creating user interfaces wich scale using technologies including in Qt Auto, using an architecture we named the Core UI architecture. Naturally, customers shall be motivated to deviate from this Core UI Guide where necessary. This guide helps customers to get a base for fundamental discussions, internally and externally and hopefully the support required to come to a conclusion that helps them to achieve their own goals. / jryannel","title":"Preface"},{"location":"#why","text":"A fundamental aspect of creating an architecture is to define a vocabulary and vision of that architecture. Most of the work in this guide is funded by Luxoft, an engineering services company. You may wonder why a service company is willing to publish essential knowledge in open source under fairly permissive licenses. This is because, when we conduct customer projects in the UI domain, we have noticed certain recurring patterns. Our philosophy is not based on watching customers stumble over the same problems. Instead, we would like to be part of the solution, and prevent these problems from recurring in the first place. In this guide, you will see many mentions of \"automotive\". This starts with the name \"Qt Automotive Suite\". Automotive has various specifics aspects. The same applies to embedded hardware and software in the Industrial sector. They have one interesting thing in common: they speak about Human Machine Interface (HMI) or about Man-Machine Interface (MMI), whereas HighTech speaks about User Interfaces (UI). User Experience (UX) is still known in Automotive, but for a long time, it mostly was in terms of interior of the car and all about using buttons, switches, and pedals arranged around the steering wheel. In the course of convergence and digitalization, Automotive started to invest in making interfaces for users and less for machines and in seeing this as essential part of UX. We firmly believe that the Industrial sector and Embedded in general will follow this trend soon to and benefit from this guide.","title":"Why"},{"location":"#the-team","text":"This guide was initially designed and worked out as part of the Qt Auto effort at Luxoft. Being part of a team means the author is not the only contributor. Others contributed by ideas, converstations or even contributions. I would like to thank the Qt Auto team at Luxoft to allow me to write this guide as part of my daily work","title":"The Team"},{"location":"#license","text":"Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free > Documentation License (FDL) version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. The code samples in this document are provided under BSD 3-Clause \"New\" or \"Revised\" License as published by the SPDX Workgroup a Linux Foundation Project","title":"License"},{"location":"admin/build/","text":"Qt Automotive Setup To create your first project you first need to have QtAuto installed. The easiest way is to use an existing Qt installation and install the remaining QtAuto modules. A more advanced option is to compile your own Qt5 and then install the QtAuto modules. A own Qt build is required if you are using linux and want to use the multi-process mode, as it requires a qt build with wayland support. The coreui-admin tool will support you in both scenarios. Note This chapter requires that you successfully installed the coreui-admin script. Please see the installation chapter for guidance. Existing Qt Please install Qt5 using the Qt online installer first. Now you should create a folder to host the QtAuto components and initialize the folder. source mkdir qauto cd qauto coreui-admin init The init command will create a coreui.yml project document. You can either edit the document yourself or add config values. To edit the configuration just type coreui-admin config --edit This will start your default editor and open the qauto document. Now we will tell qauto where the existing qt installation is by passing the path to the qmake executable. For example on MACOS this should look like this: coreui-admin config qmake ~/Qt/5.11.0/clang_64/bin/qmake From now on coreui-admin will use the existing Qt installation as base. Note In case you need to build your own Qt leave the qmake configuration empty and use the coreui-admin qt command to build your custom Qt5 from source. See the section Setup using custom Qt . Now we clone the QtAuto modules and build them. First we can check the auto target using:: coreui-admin targets auto This will print the currently listed repositories vailable under the auto target. A target is an ordered list or repositories. The ordering defines the build order. This information is stored in the coreui.yml targets section. ______name______|______________________repos______________________ auto | appman, qtivi, neptune3-ui Note If no target is given target all is automatically invoked. The list may vary based on your coreui.yml configuration. The next step would be to clone and build all auto repositories. coreui-admin clone auto coreui-admin build auto The clones repositories are available in the source/<repo-name> and build/<repo-name> locations. After building the repositories will be automatically installed into install/<repo-name> . !! note Be aware some repositories will automatically install as qt modules into the Qt directory and can not be found in the install location . If you later want to update your installation, you can simple run update. coreui-admin update auto coreui-admin build auto To clean the build you can run coreui-admin clean auto Custom Qt If you want to use the multi-process setup on Linux or just want to use a custom Qt the script will support you in building Qt for your platform. The first step is to check if your OS can build Qt and the QAuto components. For this run the OS command. coreui-admin os --check Note: The OS command is currently only supported on Ubuntu currently. The check command will either be positive or negative. In the case the result is negative please run the os init command. coreui-admin os --init This command will either print the required steps to initialize your OS or ask you to install several packages onto your system. For this step administration privileges are required. After the OS configuration has been validated Qt can now be downloaded and build. coreui-admin qt --clone coreui-admin qt --config coreui-admin qt --build The last step can take up to an hour, depending on your machine configuration. To set the number of used make jobs (how many CPU cores make can use), you can edit the jobs config value. For example for a great performance on a Core i7 Quad Core Intel CPU you can set the jobs count to 6. You would still have two processors left to continue working. coreui-admin config jobs 6 To check your configuration you can list the configurtion values. coreui-admin config Will output something like this build | build install | install jobs | 6 qmake | ~/Qt/5.10.0/clang_64/bin/qmake source | source To unset a configuration value you can use the config --unset option. coreui-admin config --unset qmake","title":"Building"},{"location":"admin/build/#qt-automotive-setup","text":"To create your first project you first need to have QtAuto installed. The easiest way is to use an existing Qt installation and install the remaining QtAuto modules. A more advanced option is to compile your own Qt5 and then install the QtAuto modules. A own Qt build is required if you are using linux and want to use the multi-process mode, as it requires a qt build with wayland support. The coreui-admin tool will support you in both scenarios. Note This chapter requires that you successfully installed the coreui-admin script. Please see the installation chapter for guidance.","title":"Qt Automotive Setup"},{"location":"admin/build/#existing-qt","text":"Please install Qt5 using the Qt online installer first. Now you should create a folder to host the QtAuto components and initialize the folder. source mkdir qauto cd qauto coreui-admin init The init command will create a coreui.yml project document. You can either edit the document yourself or add config values. To edit the configuration just type coreui-admin config --edit This will start your default editor and open the qauto document. Now we will tell qauto where the existing qt installation is by passing the path to the qmake executable. For example on MACOS this should look like this: coreui-admin config qmake ~/Qt/5.11.0/clang_64/bin/qmake From now on coreui-admin will use the existing Qt installation as base. Note In case you need to build your own Qt leave the qmake configuration empty and use the coreui-admin qt command to build your custom Qt5 from source. See the section Setup using custom Qt . Now we clone the QtAuto modules and build them. First we can check the auto target using:: coreui-admin targets auto This will print the currently listed repositories vailable under the auto target. A target is an ordered list or repositories. The ordering defines the build order. This information is stored in the coreui.yml targets section. ______name______|______________________repos______________________ auto | appman, qtivi, neptune3-ui Note If no target is given target all is automatically invoked. The list may vary based on your coreui.yml configuration. The next step would be to clone and build all auto repositories. coreui-admin clone auto coreui-admin build auto The clones repositories are available in the source/<repo-name> and build/<repo-name> locations. After building the repositories will be automatically installed into install/<repo-name> . !! note Be aware some repositories will automatically install as qt modules into the Qt directory and can not be found in the install location . If you later want to update your installation, you can simple run update. coreui-admin update auto coreui-admin build auto To clean the build you can run coreui-admin clean auto","title":"Existing Qt"},{"location":"admin/build/#custom-qt","text":"If you want to use the multi-process setup on Linux or just want to use a custom Qt the script will support you in building Qt for your platform. The first step is to check if your OS can build Qt and the QAuto components. For this run the OS command. coreui-admin os --check Note: The OS command is currently only supported on Ubuntu currently. The check command will either be positive or negative. In the case the result is negative please run the os init command. coreui-admin os --init This command will either print the required steps to initialize your OS or ask you to install several packages onto your system. For this step administration privileges are required. After the OS configuration has been validated Qt can now be downloaded and build. coreui-admin qt --clone coreui-admin qt --config coreui-admin qt --build The last step can take up to an hour, depending on your machine configuration. To set the number of used make jobs (how many CPU cores make can use), you can edit the jobs config value. For example for a great performance on a Core i7 Quad Core Intel CPU you can set the jobs count to 6. You would still have two processors left to continue working. coreui-admin config jobs 6 To check your configuration you can list the configurtion values. coreui-admin config Will output something like this build | build install | install jobs | 6 qmake | ~/Qt/5.10.0/clang_64/bin/qmake source | source To unset a configuration value you can use the config --unset option. coreui-admin config --unset qmake","title":"Custom Qt"},{"location":"admin/concepts/","text":"Concepts As a project solution the coreui-admin guides you through the initial setup of QtAuto and the creation of an initial user interface based on QAuto. For this it tries to be flexible and uses several generic concepts. Configuration File The admin relies on a per project auto configuration file. It stores information about the build process and involved repositores. Additional you can place environment variables and small scripts into the configuration document. Environment Variables Environment variables passed on to the build or run commands will be read form the shell environment but also can be placed into the qauto config file in the env section. For user contributed env variables it is also possible to add environment variables into an .env file. Repositories and Targets QAuto supports the registration of repositories by name with the git url, branch, build-system information. A repository listed can be made available in the target section. A target allows the bundling of one or more repositories as build unit. Standardized Builds Registered repositories can have different build systems named when registered with qauto. For this it knows currently three build systems (configure, qmake, cmake). Configure is used for the building of Qt itself and other projects may use qmake or cmake based projects. Scripts A script is a command line registered with the auto configuration file. The environment variables are passed on to the scripts. Project Generators QAuto allows you to generate a full project scaffold. The scaffolds are based on smart templates and follow a defined architecture. Aspect Generators Besides generating full project the qauto script allows also to extend the generated project using distinct components. This allows the extension of the generated project.","title":"Concepts"},{"location":"admin/concepts/#concepts","text":"As a project solution the coreui-admin guides you through the initial setup of QtAuto and the creation of an initial user interface based on QAuto. For this it tries to be flexible and uses several generic concepts.","title":"Concepts"},{"location":"admin/concepts/#configuration-file","text":"The admin relies on a per project auto configuration file. It stores information about the build process and involved repositores. Additional you can place environment variables and small scripts into the configuration document.","title":"Configuration File"},{"location":"admin/concepts/#environment-variables","text":"Environment variables passed on to the build or run commands will be read form the shell environment but also can be placed into the qauto config file in the env section. For user contributed env variables it is also possible to add environment variables into an .env file.","title":"Environment Variables"},{"location":"admin/concepts/#repositories-and-targets","text":"QAuto supports the registration of repositories by name with the git url, branch, build-system information. A repository listed can be made available in the target section. A target allows the bundling of one or more repositories as build unit.","title":"Repositories and Targets"},{"location":"admin/concepts/#standardized-builds","text":"Registered repositories can have different build systems named when registered with qauto. For this it knows currently three build systems (configure, qmake, cmake). Configure is used for the building of Qt itself and other projects may use qmake or cmake based projects.","title":"Standardized Builds"},{"location":"admin/concepts/#scripts","text":"A script is a command line registered with the auto configuration file. The environment variables are passed on to the scripts.","title":"Scripts"},{"location":"admin/concepts/#project-generators","text":"QAuto allows you to generate a full project scaffold. The scaffolds are based on smart templates and follow a defined architecture.","title":"Project Generators"},{"location":"admin/concepts/#aspect-generators","text":"Besides generating full project the qauto script allows also to extend the generated project using distinct components. This allows the extension of the generated project.","title":"Aspect Generators"},{"location":"admin/dev/","text":"Developing and Contributing To develop on a listed repository from your config document you need to clone the repository in an independent development folder and build it locally. This separation helps to have always a reference build available based on the upstream source code and a developer build based on your current modified stand. coreui-admin helps you here using the dev command. The dev command allows you to clone and configure a repository inside a dev folder. If you project has support for Qt code-review coreui-admin will install the code-review commit templates and add gerrit as a remote repository. To mark a repository for code-review add a code-review property in the repository section of your config document with the name of the review path. neptune3-ui : url : git://code.qt.io/qt-apps/neptune3-ui.git branch : '5.13' build : qmake os : [ linux , macos ] codereview : \"qt-apps/neptune3-ui\" You use the dev command like this: coreui-admin dev neptune3-ui This will create a dev/source/neptune3-ui and dev/build/neptune3-ui and after a successful build a dev/install/neptune3-ui . These folders are independent from your upstream tracking folders. In this workflow you would edit the code in the dev/source/neptune3-ui folder to contribute on the Neptune3 UI. You can build and if finished upstream your changes. To check the upstream you would simple update the repo using coreui-admin update and build your upstream version of the repo. Note If you like to see what a command is doing, you can simple use the --dry-run option. The command will output a small message how to configure Qt Creator to build and run your project.","title":"Developing"},{"location":"admin/dev/#developing-and-contributing","text":"To develop on a listed repository from your config document you need to clone the repository in an independent development folder and build it locally. This separation helps to have always a reference build available based on the upstream source code and a developer build based on your current modified stand. coreui-admin helps you here using the dev command. The dev command allows you to clone and configure a repository inside a dev folder. If you project has support for Qt code-review coreui-admin will install the code-review commit templates and add gerrit as a remote repository. To mark a repository for code-review add a code-review property in the repository section of your config document with the name of the review path. neptune3-ui : url : git://code.qt.io/qt-apps/neptune3-ui.git branch : '5.13' build : qmake os : [ linux , macos ] codereview : \"qt-apps/neptune3-ui\" You use the dev command like this: coreui-admin dev neptune3-ui This will create a dev/source/neptune3-ui and dev/build/neptune3-ui and after a successful build a dev/install/neptune3-ui . These folders are independent from your upstream tracking folders. In this workflow you would edit the code in the dev/source/neptune3-ui folder to contribute on the Neptune3 UI. You can build and if finished upstream your changes. To check the upstream you would simple update the repo using coreui-admin update and build your upstream version of the repo. Note If you like to see what a command is doing, you can simple use the --dry-run option. The command will output a small message how to configure Qt Creator to build and run your project.","title":"Developing and Contributing"},{"location":"admin/install/","text":"Installation The coreui-admin tool is a script which can be easily installed using standard python tooling. Requirements The script requires a python (2.x or 3.x ) installation with the PIP package manager installed. Installation from Git You can also direcly install from git using the python package manager pip install git+https://github.com/Luxoft/coreui-admin.git@develop --upgrade Note On Ubuntu you might need to add $HOME/.local/bin to you $PATH Editable Installation An editable installation only installs links to the orignal source. In effect updating the git checkout also installs the script. git clone https://github.com/Luxoft/coreui-admin.git cd coreui-admin pip install -e . To update the installation you need to update the repository. cd coreui-admin git pull Now the coreui-admin is updated to the latest from the remote repository. Uninstalling To uninstall the script you can to use the pip tool pip uninstall coreui-admin Using Virtualenv In case you do not want to pollute your local python installation you can use python virtualenv virtualenv -p python3 venv source venv/bin/activate Now install coreui-admin and to exit this python virtual environment call deactivate . First Usage After the installation the coreui-admin command is at your disposal. coreui-admin --help","title":"Installation"},{"location":"admin/install/#installation","text":"The coreui-admin tool is a script which can be easily installed using standard python tooling.","title":"Installation"},{"location":"admin/install/#requirements","text":"The script requires a python (2.x or 3.x ) installation with the PIP package manager installed.","title":"Requirements"},{"location":"admin/install/#installation-from-git","text":"You can also direcly install from git using the python package manager pip install git+https://github.com/Luxoft/coreui-admin.git@develop --upgrade Note On Ubuntu you might need to add $HOME/.local/bin to you $PATH","title":"Installation from Git"},{"location":"admin/install/#editable-installation","text":"An editable installation only installs links to the orignal source. In effect updating the git checkout also installs the script. git clone https://github.com/Luxoft/coreui-admin.git cd coreui-admin pip install -e . To update the installation you need to update the repository. cd coreui-admin git pull Now the coreui-admin is updated to the latest from the remote repository.","title":"Editable Installation"},{"location":"admin/install/#uninstalling","text":"To uninstall the script you can to use the pip tool pip uninstall coreui-admin","title":"Uninstalling"},{"location":"admin/install/#using-virtualenv","text":"In case you do not want to pollute your local python installation you can use python virtualenv virtualenv -p python3 venv source venv/bin/activate Now install coreui-admin and to exit this python virtual environment call deactivate .","title":"Using Virtualenv"},{"location":"admin/install/#first-usage","text":"After the installation the coreui-admin command is at your disposal. coreui-admin --help","title":"First Usage"},{"location":"admin/intro/","text":"Core UI Admin The coreui-admin script allows you to control your QtAuto installation. QtAuto is a set of components on top of Qt5 which allows you to create a typical user interface for the automotive market. To better support the market needs the script propagates an opinionated architecture called the CoreUI Architecture. The script is capable of building the underlying platform as also to generate CoreUI projects and core components of these projects. You can read more about the CoreUI architecture in the CoreUI section of the guide. The script supports your work-flow in several ways: Cloning, building the coreui repositories and Qt5 as also your custom projects Creating and running coreui based projects based on templates for single or multi-process architecture Adding core components based on the CoreUI architecture to a CoreUI project Running scripts to support your custom work-flow Managing your custom environment variable setup You can read more about the individual features in the concepts section of the admin guide. A separate chapter demonstrates the creation of a CoreUI architecture instance using a simple mental model.","title":"Core UI Admin"},{"location":"admin/intro/#core-ui-admin","text":"The coreui-admin script allows you to control your QtAuto installation. QtAuto is a set of components on top of Qt5 which allows you to create a typical user interface for the automotive market. To better support the market needs the script propagates an opinionated architecture called the CoreUI Architecture. The script is capable of building the underlying platform as also to generate CoreUI projects and core components of these projects. You can read more about the CoreUI architecture in the CoreUI section of the guide. The script supports your work-flow in several ways: Cloning, building the coreui repositories and Qt5 as also your custom projects Creating and running coreui based projects based on templates for single or multi-process architecture Adding core components based on the CoreUI architecture to a CoreUI project Running scripts to support your custom work-flow Managing your custom environment variable setup You can read more about the individual features in the concepts section of the admin guide. A separate chapter demonstrates the creation of a CoreUI architecture instance using a simple mental model.","title":"Core UI Admin"},{"location":"admin/projects/","text":"Project Creation Note This chapter expects you have already successfully setup the coreui-admin script (see script setup) and build the QtAuto components (see QtAuto setup). You can create a new project using the new command. coreui-admin new myproject This will by default create a new project in the myproject folder using the single-process template. To change the template you can provide a --template option. To launch your newly created project you can use coreui - admin start It will launch the qmlscene from your given Qt SDK with the correct setup. Note To see all options please use coreui-admin new --help Single Process UI The single process user interface is created using coreui-admin new single-ui --template single It will create a UI project which can be launched from a QtCreator .qmlproject file. External native dependencies are served using QML Plugins. The project is built around the idea that there is a system UI that displays the system-wide user interface portion and applications which display the feature-specific information. System UI The System UI which acts as the desktop-like user interface in which other applications can be shown and contains a status bar to present system-wide information, it also manages any other overlays which do not directly belong to the applications. All other information is part of the individual applications. The SystemUI is started by launching the \"SystemUI.qml\" document in the sui folder or the Main.qml document in the root folder of your project. Note The SystemUI is launched by default when working with the QtCreator project. The SystemUI was also registered as the start script by the new project generator and can be launched using the start option of coreui-admin : coreui-admin start . Application UI An application is contained inside a apps folder and has its own Application.qml document. It is registered with the SystemUI and added to the launcher menu of the SystemUI. Multi Process UI To create a new multi-process project you can use the new command with the --template multi option. coreui-admin new multi-ui --template multi This will create a new user interface project which has support for the Qt ApplicationManager built-in. It follows very similar concepts than the single-process UI but the applications are now designed to be run as separate processed and provide a higher level of flexibility and security. The newly created project can be launched using coreui-admin start The start script invokes the appman executable form your QAuto installation and reads the generated am-config.yaml document in the project which provides all startup information to the application manager. Note The Qt Application manager requires a Wayland window manager to run in multi-process mode, which is often only available on Linux and the target HW. To allow the development of other hosts (e.g. Mac/Windows) the application manager has a single-process model that is automatically invoked on these environments. Please consult the QtApplication Manager documented for more information.","title":"Project Creation"},{"location":"admin/projects/#project-creation","text":"Note This chapter expects you have already successfully setup the coreui-admin script (see script setup) and build the QtAuto components (see QtAuto setup). You can create a new project using the new command. coreui-admin new myproject This will by default create a new project in the myproject folder using the single-process template. To change the template you can provide a --template option. To launch your newly created project you can use coreui - admin start It will launch the qmlscene from your given Qt SDK with the correct setup. Note To see all options please use coreui-admin new --help","title":"Project Creation"},{"location":"admin/projects/#single-process-ui","text":"The single process user interface is created using coreui-admin new single-ui --template single It will create a UI project which can be launched from a QtCreator .qmlproject file. External native dependencies are served using QML Plugins. The project is built around the idea that there is a system UI that displays the system-wide user interface portion and applications which display the feature-specific information.","title":"Single Process UI"},{"location":"admin/projects/#system-ui","text":"The System UI which acts as the desktop-like user interface in which other applications can be shown and contains a status bar to present system-wide information, it also manages any other overlays which do not directly belong to the applications. All other information is part of the individual applications. The SystemUI is started by launching the \"SystemUI.qml\" document in the sui folder or the Main.qml document in the root folder of your project. Note The SystemUI is launched by default when working with the QtCreator project. The SystemUI was also registered as the start script by the new project generator and can be launched using the start option of coreui-admin : coreui-admin start .","title":"System UI"},{"location":"admin/projects/#application-ui","text":"An application is contained inside a apps folder and has its own Application.qml document. It is registered with the SystemUI and added to the launcher menu of the SystemUI.","title":"Application UI"},{"location":"admin/projects/#multi-process-ui","text":"To create a new multi-process project you can use the new command with the --template multi option. coreui-admin new multi-ui --template multi This will create a new user interface project which has support for the Qt ApplicationManager built-in. It follows very similar concepts than the single-process UI but the applications are now designed to be run as separate processed and provide a higher level of flexibility and security. The newly created project can be launched using coreui-admin start The start script invokes the appman executable form your QAuto installation and reads the generated am-config.yaml document in the project which provides all startup information to the application manager. Note The Qt Application manager requires a Wayland window manager to run in multi-process mode, which is often only available on Linux and the target HW. To allow the development of other hosts (e.g. Mac/Windows) the application manager has a single-process model that is automatically invoked on these environments. Please consult the QtApplication Manager documented for more information.","title":"Multi Process UI"},{"location":"admin/reference/","text":"Reference Command Line Usage :: Usage : coreui - admin [ OPTIONS ] COMMAND [ ARGS ]... coreui adminstration tool Options : - v , -- verbose Enables verbose mode . -- dry - run / -- no - dry - run operations are not executed , only printed -- log - level [ info | debug | warning | error ] sets the log level -- help Show this message and exit . Commands : app creates a new application build Builds one or more repos clean cleans the build , install and optional the source folder clone clones the coreui repositories into this workspace config configures coreui env display . env variables generate Creates a new aspect init creates an empty coreui workspace new creates a new coreui project os prepares the OS to build coreui pull updates the coreui repositories qt support for building qt repos manages the listed repos run runs a script from the config script section by name start starts a project targets manages the buildable targets Initialisation Usage : coreui - admin init [ OPTIONS ] Initialized the workspace by writing the ` coreui . yml ` setup document Options : -- help Show this message and exit . Configuration Usage : coreui - admin config [ OPTIONS ] [ NAME ] [ VALUE ] Options : -- unset TEXT -- edit / -- no - edit -- help Show this message and exit . The configuration document coreui.yml contains a section called config to configure coreui-admin general behavior. The supported values are currently: source , install , build path (defaults to \"source\", \"install\", \"build\") jobs : make jobs (defaults to 2) qmake : qmake path (defaults to empty) You can set the option using the config command. For example to set the jobs option to 6 use coreui - admin config jobs 6 In case you want to edit the whole coreui.yml document you can just type coreui - admin config --edit This will open your default editor and display the configuration document. Targets The configuration document has a section of targets , which is a list of repositories. The repositories order is important for the order of build. targets : auto : - appman - dlt - daemon Repositories The coreui.yml document has an own section for repos listed. The repos are listed with a name, url, branch and the build-type. The name is the name the project will be checkout and being identified using other commands. The url should be a standard git url. The branch is the branch being checkout out. The build-type can be qmake or cmake - othe build types are currently not supported. In the coreui.yml document a repos section looks like this config : jobs : 2 qmake : / Users / jryannel / Qt / 5.10.0 / clang_64 / bin / qmake env : QT_SCALE_FACTOR : '0.75' repos : appman : branch : '5.10' build : qmake os : [ linux, macos ] url : git : // code . qt . io / qt / qtapplicationmanager . git dlt - daemon : branch : master build : cmake os : [ linux ] url : git : // github . com / GENIVI / dlt - daemon . git scripts : {} targets : auto : - appman - dlt - daemon You can use the coreui-admin repos command to manage the repositories. See coreui-admin repos --help for more information. A repository can have also a scripts dictionary attached. This dictionary is automatically attached to the scripts section of the coreui-admin config document. Environment Variables All commands wil inherit the system environment variables. There are several ways to add additional environment variables. Either project wide enviroment variables can be set in the coreui.yml document in the env section or using a local .env file next to the coreui.yml . In the coreui.yml document you need to fill in the env section using a key value pair format. env : QT_SCALE_FACTOR : \"0.75\" The .env file is a YAML formatted document with key value pairs. The order of lookup is first user local using .env file second coreui.yml env section last system environment variables You can use the coreui-admin env command to list the different environment variables. See more information using coreui-admin env --help","title":"Reference"},{"location":"admin/reference/#reference","text":"","title":"Reference"},{"location":"admin/reference/#command-line-usage","text":":: Usage : coreui - admin [ OPTIONS ] COMMAND [ ARGS ]... coreui adminstration tool Options : - v , -- verbose Enables verbose mode . -- dry - run / -- no - dry - run operations are not executed , only printed -- log - level [ info | debug | warning | error ] sets the log level -- help Show this message and exit . Commands : app creates a new application build Builds one or more repos clean cleans the build , install and optional the source folder clone clones the coreui repositories into this workspace config configures coreui env display . env variables generate Creates a new aspect init creates an empty coreui workspace new creates a new coreui project os prepares the OS to build coreui pull updates the coreui repositories qt support for building qt repos manages the listed repos run runs a script from the config script section by name start starts a project targets manages the buildable targets","title":"Command Line Usage"},{"location":"admin/reference/#initialisation","text":"Usage : coreui - admin init [ OPTIONS ] Initialized the workspace by writing the ` coreui . yml ` setup document Options : -- help Show this message and exit .","title":"Initialisation"},{"location":"admin/reference/#configuration","text":"Usage : coreui - admin config [ OPTIONS ] [ NAME ] [ VALUE ] Options : -- unset TEXT -- edit / -- no - edit -- help Show this message and exit . The configuration document coreui.yml contains a section called config to configure coreui-admin general behavior. The supported values are currently: source , install , build path (defaults to \"source\", \"install\", \"build\") jobs : make jobs (defaults to 2) qmake : qmake path (defaults to empty) You can set the option using the config command. For example to set the jobs option to 6 use coreui - admin config jobs 6 In case you want to edit the whole coreui.yml document you can just type coreui - admin config --edit This will open your default editor and display the configuration document.","title":"Configuration"},{"location":"admin/reference/#targets","text":"The configuration document has a section of targets , which is a list of repositories. The repositories order is important for the order of build. targets : auto : - appman - dlt - daemon","title":"Targets"},{"location":"admin/reference/#repositories","text":"The coreui.yml document has an own section for repos listed. The repos are listed with a name, url, branch and the build-type. The name is the name the project will be checkout and being identified using other commands. The url should be a standard git url. The branch is the branch being checkout out. The build-type can be qmake or cmake - othe build types are currently not supported. In the coreui.yml document a repos section looks like this config : jobs : 2 qmake : / Users / jryannel / Qt / 5.10.0 / clang_64 / bin / qmake env : QT_SCALE_FACTOR : '0.75' repos : appman : branch : '5.10' build : qmake os : [ linux, macos ] url : git : // code . qt . io / qt / qtapplicationmanager . git dlt - daemon : branch : master build : cmake os : [ linux ] url : git : // github . com / GENIVI / dlt - daemon . git scripts : {} targets : auto : - appman - dlt - daemon You can use the coreui-admin repos command to manage the repositories. See coreui-admin repos --help for more information. A repository can have also a scripts dictionary attached. This dictionary is automatically attached to the scripts section of the coreui-admin config document.","title":"Repositories"},{"location":"admin/reference/#environment-variables","text":"All commands wil inherit the system environment variables. There are several ways to add additional environment variables. Either project wide enviroment variables can be set in the coreui.yml document in the env section or using a local .env file next to the coreui.yml . In the coreui.yml document you need to fill in the env section using a key value pair format. env : QT_SCALE_FACTOR : \"0.75\" The .env file is a YAML formatted document with key value pairs. The order of lookup is first user local using .env file second coreui.yml env section last system environment variables You can use the coreui-admin env command to list the different environment variables. See more information using coreui-admin env --help","title":"Environment Variables"},{"location":"admin/start/","text":"Quick Start Installation To use the admin we first need to install it as part of our environment. git clone git @http : // github . com / Luxoft / coreui - admin . git cd coreui - admin pip install - e . The simplest start is to use an existing Qt SDK (e.g. 5.11 incl. Qt Remote Objects TP) and build of QtAuto components. This is a great start into the creation of a new user interface for systems. Setting up QtAuto Stack Create a project directory mkdir coreui && cd coreui Write the config file coreui.yml coreui - admin init Configure qmake to use existing Qt5 SDK coreui - admin config qmake < path / to / qmake > Clone QtAuto source repositories coreui - admin clone auto Build all QtAuto repositories coreui - admin build auto Note: Please make sure that all coreui components are successfully configured. Now we can start the QtAuto reference user interrface called Neptune3 UI. coreui - admin start The script was automatically registered while building the QtAuto repositories. Setting up a new CoreUI project Now we can create the single-process UI coreui - admin new myproject cd myproject We first let the admin know where the existing Qt SDK is located. For this we point it to the qmake executable for the SDK. coreui - admin config qmake < path / to / qmake > We can launch the UI using the start script, which was registered by the project generator. coreui - admin start To develop with the newly created UI you can open QtCreator and open the myproject/myproject.qmlproject project.","title":"Quick Start"},{"location":"admin/start/#quick-start","text":"","title":"Quick Start"},{"location":"admin/start/#installation","text":"To use the admin we first need to install it as part of our environment. git clone git @http : // github . com / Luxoft / coreui - admin . git cd coreui - admin pip install - e . The simplest start is to use an existing Qt SDK (e.g. 5.11 incl. Qt Remote Objects TP) and build of QtAuto components. This is a great start into the creation of a new user interface for systems.","title":"Installation"},{"location":"admin/start/#setting-up-qtauto-stack","text":"Create a project directory mkdir coreui && cd coreui Write the config file coreui.yml coreui - admin init Configure qmake to use existing Qt5 SDK coreui - admin config qmake < path / to / qmake > Clone QtAuto source repositories coreui - admin clone auto Build all QtAuto repositories coreui - admin build auto Note: Please make sure that all coreui components are successfully configured. Now we can start the QtAuto reference user interrface called Neptune3 UI. coreui - admin start The script was automatically registered while building the QtAuto repositories.","title":"Setting up QtAuto Stack"},{"location":"admin/start/#setting-up-a-new-coreui-project","text":"Now we can create the single-process UI coreui - admin new myproject cd myproject We first let the admin know where the existing Qt SDK is located. For this we point it to the qmake executable for the SDK. coreui - admin config qmake < path / to / qmake > We can launch the UI using the start script, which was registered by the project generator. coreui - admin start To develop with the newly created UI you can open QtCreator and open the myproject/myproject.qmlproject project.","title":"Setting up a new CoreUI project"},{"location":"api/","text":"API Reference Info This material is work in progress and will change!","title":"Getting Started"},{"location":"api/#api-reference","text":"Info This material is work in progress and will change!","title":"API Reference"},{"location":"download/","text":"Download Info This material is work in progress and will change!","title":"Getting Started"},{"location":"download/#download","text":"Info This material is work in progress and will change!","title":"Download"},{"location":"guide/","text":"Getting Started Info This material is work in progress and will change!","title":"Getting Started"},{"location":"guide/#getting-started","text":"Info This material is work in progress and will change!","title":"Getting Started"},{"location":"guide/cookbook/","text":"CookBook Info This material is work in progress and will change!","title":"CookBook"},{"location":"guide/cookbook/#cookbook","text":"Info This material is work in progress and will change!","title":"CookBook"},{"location":"guide/examples/","text":"Examples Info This material is work in progress and will change!","title":"Examples"},{"location":"guide/examples/#examples","text":"Info This material is work in progress and will change!","title":"Examples"},{"location":"guide/install/","text":"Install Info This material is work in progress and will change! CoreUI is not really something to be installed. It is more an approach to write large scaled user interfaces using Qt and Qt Auto. Still there is a helper library and tools to help you getting started and which is used throughout the guide. The tool is called coreui-admin which can be used to create new sample projects or add aspects to these projects. This shall make the guide more compact. Instead of describing in detail how to setup a project, we can now just tell coreui-admin new myproject . The coreui-admin tool is a Python 3 script which can be easily installed using the standard python tooling. Requirements The script requires a Python (3.5> ) installation with the PIP package manager installed. Installation Normally you would install the coreui-admin using the pip package manager. pip install coreui - admin This will install an executable coreui-admin into your path. Install from git You can also directly install from git using the python package manager pip install git + https : // github . com / Luxoft / coreui - admin . git @master --upgrade Note On Ubuntu you might need to add $HOME/.local/bin to you $PATH Editable Installation An editable installation only installs links to the original source. In effect updating the git checkout also installs the script. git clone https : // github . com / Luxoft / coreui - admin . git cd coreui - admin pip install - e . To update the installation you need to update the repository. cd coreui - admin git pull Now the coreui-admin is updated to the latest from the remote repository. Uninstall To de install the script you can to use the pip tool pip uninstall coreui - admin Using Virtualenv In case you do not want to pollute your local python installation you can use python virtualenv pip install virtualenv virtualenv - p python3 venv source venv / bin / activate Now install coreui-admin and to exit this python virtual environment call deactivate . First Usage After the installation the coreui-admin command is at your disposal. coreui - admin --help","title":"Install"},{"location":"guide/install/#install","text":"Info This material is work in progress and will change! CoreUI is not really something to be installed. It is more an approach to write large scaled user interfaces using Qt and Qt Auto. Still there is a helper library and tools to help you getting started and which is used throughout the guide. The tool is called coreui-admin which can be used to create new sample projects or add aspects to these projects. This shall make the guide more compact. Instead of describing in detail how to setup a project, we can now just tell coreui-admin new myproject . The coreui-admin tool is a Python 3 script which can be easily installed using the standard python tooling.","title":"Install"},{"location":"guide/install/#requirements","text":"The script requires a Python (3.5> ) installation with the PIP package manager installed.","title":"Requirements"},{"location":"guide/install/#installation","text":"Normally you would install the coreui-admin using the pip package manager. pip install coreui - admin This will install an executable coreui-admin into your path.","title":"Installation"},{"location":"guide/install/#install-from-git","text":"You can also directly install from git using the python package manager pip install git + https : // github . com / Luxoft / coreui - admin . git @master --upgrade Note On Ubuntu you might need to add $HOME/.local/bin to you $PATH","title":"Install from git"},{"location":"guide/install/#editable-installation","text":"An editable installation only installs links to the original source. In effect updating the git checkout also installs the script. git clone https : // github . com / Luxoft / coreui - admin . git cd coreui - admin pip install - e . To update the installation you need to update the repository. cd coreui - admin git pull Now the coreui-admin is updated to the latest from the remote repository.","title":"Editable Installation"},{"location":"guide/install/#uninstall","text":"To de install the script you can to use the pip tool pip uninstall coreui - admin","title":"Uninstall"},{"location":"guide/install/#using-virtualenv","text":"In case you do not want to pollute your local python installation you can use python virtualenv pip install virtualenv virtualenv - p python3 venv source venv / bin / activate Now install coreui-admin and to exit this python virtual environment call deactivate .","title":"Using Virtualenv"},{"location":"guide/install/#first-usage","text":"After the installation the coreui-admin command is at your disposal. coreui - admin --help","title":"First Usage"},{"location":"guide/whatis/","text":"What is QML Core UI Info This material is work in progress and will change! Abstract CoreUI was created out of the need for a more structured way of creating User Interfaces (UIs) not only for applications but also for large systems. The current process works fine if only a few people work on a small UI. But, as the user interface starts to get bigger and the number of people working on the UI layer increases, then the existing process is no longer well defined. It just doesn't scale. Ideally, CoreUI provides a pattern to scale UI development linearly without scrutinizing the implementation of UI features. Motivation When observing Developers working on larger UIs, it is interesting to see the correlation between the development productivity and the UI complexity. Particularly, the development productivity drops as the UI complexity increases. For example, Developers need to start the whole UI to navigate into a detailed view to fine-tune some UI logic or even animation. Often, this is because the UI can't be broken down into smaller, manageable chunks. In practical terms, it's about isolating a smaller portion of the UI and being able to work and validate this smaller portion. Breaking down the UI often happens on larger layers. But for UI development where the UI experience is an important factor, it's necessary to fine-tune small aspects of the UI to achieve the desired look and behavior. You have to aim for a fast (10ms) round trip time to make the conversation seamless between Design and Development. You can easily avoid this situation with Qt and QML. While QML offers a great component model, it lacks a coherent approach to componentize the UI and to implement these UI components. Looking at the current development approach it is clear that the UI's physical structure and the component types are created by following the UI specification and not from a technical perspective. For a developer, it's not clear when and how exactly to split a component into smaller parts, and to ensure a component is truly reusable as well as usable outside of its context. TODO: Provide an example that shows a very simple UI and then displays the resulting code structure. For example a music player with controls. Consider using our old coding challenge for new developers. CoreUI is an attempt to create an architecture and process to streamline this component creation task, similar to a component factory. What is CoreUI? CoreUI is set of patterns and components to support a common user interface structure. It encourages both Developers and Designers to create a great user experience by focusing on the UI creation process. The CoreUI architecture stems from the creation and re-creation of user interface projects for various markets, especially the automotive one. After several re-creations of user interface projects for vertical markets, some patterns emerged. The CoreUI architecture as presented here is the distillation of these patterns. CoreUI is an embedded development framework using Qt5 and the QML/JS language. Programming embedded software user interfaces can often be unnecessarily complicated. CoreUI makes the programming of these user interfaces easier, by making assumptions about what every developer needs to get started to create stunning user interfaces. It allows you to develop user interfaces by writing less code but accomplishing more. CoreUI aims to bring back the fun and creativity to user interface development so that Developers and Designers can focus on the user experience again. CoreUI is based on the opinions of others. These opinions make assumptions about what is the best way to create user interfaces. CoreUI is meant to be used that way and discourages other ways. If you master CoreUI you'll probably experience a spike in productivity. If you keep up with your old habits and try to retrofit CoreUI with your old ways of working you may not reap CoreUI's full benefits. What CoreUI is not? CoreUI is partly a concrete framework but it's not an exact path; more as a guideline. Often during a project, not all of the requirements are foreseeable and it's necessary to deviate from the path given. CoreUI isn't an implementation of a user interface. It's also not designed for a single application, but covers a multi-application setup. CoreUI is not final :-) CoreUI Stack CoreuI is founded on top of Qt5 and QtAuto. Qt5 is the leading cross-platform native UI toolkit with an unprecedented focus on the user experience. It offers the developer all the necessary APIs to develop a truly native cross-platform application. QtAuto extends Qt5, bringing multi-process application capabilities and a service framework to the table. By this, QtAuto is extending Qt into the space of creating multi-process user interfaces for mid and high-end embedded systems. Even if QtAuto targets primarily the automotive market, it's limited to this market. CoreUI defines patterns and rules for the UI layer of a multi-process UI for embedded systems based on QtAuto. A reference implementation of CoreUI is the Neptune3 UI which is delivered together with QtAuto.","title":"What is Core UI"},{"location":"guide/whatis/#what-is-qml-core-ui","text":"Info This material is work in progress and will change! Abstract CoreUI was created out of the need for a more structured way of creating User Interfaces (UIs) not only for applications but also for large systems. The current process works fine if only a few people work on a small UI. But, as the user interface starts to get bigger and the number of people working on the UI layer increases, then the existing process is no longer well defined. It just doesn't scale. Ideally, CoreUI provides a pattern to scale UI development linearly without scrutinizing the implementation of UI features.","title":"What is QML Core UI"},{"location":"guide/whatis/#motivation","text":"When observing Developers working on larger UIs, it is interesting to see the correlation between the development productivity and the UI complexity. Particularly, the development productivity drops as the UI complexity increases. For example, Developers need to start the whole UI to navigate into a detailed view to fine-tune some UI logic or even animation. Often, this is because the UI can't be broken down into smaller, manageable chunks. In practical terms, it's about isolating a smaller portion of the UI and being able to work and validate this smaller portion. Breaking down the UI often happens on larger layers. But for UI development where the UI experience is an important factor, it's necessary to fine-tune small aspects of the UI to achieve the desired look and behavior. You have to aim for a fast (10ms) round trip time to make the conversation seamless between Design and Development. You can easily avoid this situation with Qt and QML. While QML offers a great component model, it lacks a coherent approach to componentize the UI and to implement these UI components. Looking at the current development approach it is clear that the UI's physical structure and the component types are created by following the UI specification and not from a technical perspective. For a developer, it's not clear when and how exactly to split a component into smaller parts, and to ensure a component is truly reusable as well as usable outside of its context. TODO: Provide an example that shows a very simple UI and then displays the resulting code structure. For example a music player with controls. Consider using our old coding challenge for new developers. CoreUI is an attempt to create an architecture and process to streamline this component creation task, similar to a component factory.","title":"Motivation"},{"location":"guide/whatis/#what-is-coreui","text":"CoreUI is set of patterns and components to support a common user interface structure. It encourages both Developers and Designers to create a great user experience by focusing on the UI creation process. The CoreUI architecture stems from the creation and re-creation of user interface projects for various markets, especially the automotive one. After several re-creations of user interface projects for vertical markets, some patterns emerged. The CoreUI architecture as presented here is the distillation of these patterns. CoreUI is an embedded development framework using Qt5 and the QML/JS language. Programming embedded software user interfaces can often be unnecessarily complicated. CoreUI makes the programming of these user interfaces easier, by making assumptions about what every developer needs to get started to create stunning user interfaces. It allows you to develop user interfaces by writing less code but accomplishing more. CoreUI aims to bring back the fun and creativity to user interface development so that Developers and Designers can focus on the user experience again. CoreUI is based on the opinions of others. These opinions make assumptions about what is the best way to create user interfaces. CoreUI is meant to be used that way and discourages other ways. If you master CoreUI you'll probably experience a spike in productivity. If you keep up with your old habits and try to retrofit CoreUI with your old ways of working you may not reap CoreUI's full benefits.","title":"What is CoreUI?"},{"location":"guide/whatis/#what-coreui-is-not","text":"CoreUI is partly a concrete framework but it's not an exact path; more as a guideline. Often during a project, not all of the requirements are foreseeable and it's necessary to deviate from the path given. CoreUI isn't an implementation of a user interface. It's also not designed for a single application, but covers a multi-application setup. CoreUI is not final :-)","title":"What CoreUI is not?"},{"location":"guide/whatis/#coreui-stack","text":"CoreuI is founded on top of Qt5 and QtAuto. Qt5 is the leading cross-platform native UI toolkit with an unprecedented focus on the user experience. It offers the developer all the necessary APIs to develop a truly native cross-platform application. QtAuto extends Qt5, bringing multi-process application capabilities and a service framework to the table. By this, QtAuto is extending Qt into the space of creating multi-process user interfaces for mid and high-end embedded systems. Even if QtAuto targets primarily the automotive market, it's limited to this market. CoreUI defines patterns and rules for the UI layer of a multi-process UI for embedded systems based on QtAuto. A reference implementation of CoreUI is the Neptune3 UI which is delivered together with QtAuto.","title":"CoreUI Stack"},{"location":"resources/","text":"Resources Info This material is work in progress and will change!","title":"Getting Started"},{"location":"resources/#resources","text":"Info This material is work in progress and will change!","title":"Resources"},{"location":"support/","text":"Support This Info This material is work in progress and will change!","title":"Getting Started"},{"location":"support/#support-this","text":"Info This material is work in progress and will change!","title":"Support This"},{"location":"team/","text":"Team Info This material is work in progress and will change!","title":"Team"},{"location":"team/#team","text":"Info This material is work in progress and will change!","title":"Team"},{"location":"topics/blocks/","text":"Building Blocks Info This material is work in progress and will change! Abstract Building blocks are loosely coupled concepts which when arranged in the right order they form the foundation of the CoreUI. Through the loose coupling, you can also create a different architecture. This follows the principle that CoreUI is an opinionated stack and as such reflects our best efforts. Don't expect ready-made code solutions, these are concepts. User Interface We consider the user interface as the front-facing interface towards the user, aka front-end. For the underlying system facing interface, we use the term back-end. The front-end is concerned about the visual integrity of the UI and its appeal. A special focus lies upon the dialog with the user interface design team to create a stunning user experience for the users as one. The User Interface requires to communicate with the underlying system services as well as with services outside the system (aka remote services). The user interface is responsible to render every pixel on the screen and to achieve being an emotional user interface using animations and transitions. Typically a user interface is seen as a user interface tree, where the root is the initial UI portion being loaded. It is important that the user interface has control about which portions of the UI are loaded as the UI is the only layer which has the understanding. The user interface is typically developed in QML/JavaScript and Qt/C++. Note Describe the definition of the UI and the different building blocks (e.g. SUI/AppS/UIControls) The user interface is the highest layer inside a system. It offers information and interactions to the user. It is driven by the information architecture specification and the user-interface design specification. The central screens of a user interface are typically centralized inside the system UI. These screens are used to show to the user frequently needed information but also other information and interactions to navigate deeper into the user interface. The user interface itself is often seen as a tree of user interface elements, where on the root level you have the display and the structure follows on the high level of the information architecture. There are often links between unrelated UI nodes which provide shortcuts to the user to show or retrieve certain information. The UI tree on the higher levels is also divided into UI layers to ensure the most important information is shown above other less important information. The user interface is framed by the requirements specification, the user interface specification, the UI testing, and the underlying system. For working on a particular software layer it is always important to understand and embrace the adjacent layers. Here the user interface developers work closely together with the design team that creates the user interface specification. The requirements team provides non-functional and functional requirements which need to be adherent by the UI developers. The testing team needs to have support to allow smooth planning of the user interface layer. And the system provides the foundation where the user interface can be executed (either desktop or embedded) and also provides the underlying services the user interface needs to interface with. UI Runtime A runtime is responsible to initialize the user interface library and load a minimal set of extensions that are required to load the initial UI. From then on, the UI itself will take control of the loading of other UI parts. runtime --import imports Main.qml Often a runtime is made using a configuration document which can be written in JSON or a similar data-interchange format. { \"imports\" : [ \"imports\" ], \"document\" : \"Main.qml\" } In the Qt/QML case, the default runtime is the qmlscene which is great for simple prototypes but for a more complex project you want to create a custom runtime, especially for loading your custom boot extensions. UI Extensions An extension extends the runtime with new features and capabilities on dynamically on runtime. They are delivered as a module and typically loaded on-demand from the UI code. In the Qt/QML context, the extensions are called QML plug-ins. An extension, in general, can extend the runtime horizontally with new capabilities (for example to render a new type of content) or vertically (for example to communicate with a tuner service). Loading the extensions on demand allows the execution from different code paths using different extensions. Also as the extensions are looked up using the import path you can inject a mock extension into the import path before the real extension for test purposes. Note These extensions can be either written in QML or in Qt/C++ (or mixed). Often a developer first starts to write some extensions in QML for prototyping and later those will be re-written as C++ extensions to use a browser API and achieve the best performance. System UI The UI started first is called the System UI. Think about your user interface and remove all applications, what is left is called the System UI. The System UI is responsible for booting the user interface system efficiently enough so that a minimal usable user interface, is operational by the user, is reached to be shown on the screen. The System UI is also responsible for layout application windows and to provide additional information overlays to the user. Another important point of the system UI is to act as a gateway to control and prioritize access to the display surface for dialogs and notifications. Lastly, it's responsible for displaying the application launcher that acts as a shell to launch applications. Boot the user interface until a minimal usable state is reached Layout application window surfaces Control display access for dialogs and notifications Manage user interface overlays Present a user interface to launch applications System UI Layers The System UI defines the fundamental visual layering structure of the user interface. It creates the main rendering surface and controls other applications and dialog windows. A typical System UI can be divided into several layer containers. The visual topmost layer is the dialog layer which displays notifications. The notifications are system-wide controlled allowing the system UI to decide when and how a notification shall be displayed, as another, more important, the notification may be currently displayed. Just below the dialog layer, lies the overlay layer. This layer provides additional, not primary, information to the user, enhancing the information awareness and providing shortcuts to frequently used functions such as volume, climate information, etc. Below the overlays there are the application surfaces, that is a standard way to extend the system UI using features packed into applications. An application is mostly displayed full-screen but can also have different states, for example when used as a widget to preview and/or interact with certain application information in a condensed way. The launcher finally displays all available applications. A traditional way to display the different applications is using a grid with icons and a small text containing the application name and when this is clicked to launch the respective application full-screen. Another possibility could be to use a flexible grid of application widgets which when each is clicked expands into a full-screen application. The advantage of the first approach is that the application doesn't have to be launched but only meta information is presented (like its icon and name). Below the launcher, there could be an optional background image, e.g. the desktop background. In QML code this would roughly look like this. // Display.qml Item { id: root Image { id: background } Container { id: launcherLayer } Container { id: appLayer } Container { id: overlayLayer } Container { id: dialogLayer } } Stage Loading To allow the System UI to be launched in a controlled and efficient manner the typical way is to stage load the SysUI. Stage loading is a practice to dynamically load partially user interfaces using a state machine or a similar controller which is controlled by external information and/or the current state of the machine. For this reason, the UI tree represented by the System UI has to be divided into smaller parts that can be loaded independently. The partitioning is done using a standard component approach and the loading is done using the Loader type which is directed by an SCXML state machine. The state machine state changes are triggered by either external events and conditions and the overall loading state. Note For development purposes, it is also possible to shortcut some loading stages. Application An application is a set of UI screens that represent the same logical context and are rendered into the same window surface. In a multi-process system, an application is started into its own process. An application should share ideally only a small and generic API with the other horizontal components (System UI, other applications) on the same layer and use a vertical communication to interface with the system. The System UI is also seen as a special application which responsibilities are specialized in the sense that it is responsible for the early UI startup, managing application windows and displaying a UI to launch these applications as extensions to the UI. Using an application does not have to be the only way to extend or structure the user interface. A small portion of the application will interact with the system UI and window handling. These parts shall be refactored out into own components. Similar is true for application logic interacting with the underlying services. That user interface portion of the application ideally should not expose services to the UI, it should instead be wrapped into an own module bundling this application logic and empowering this way better testability. Communication There are several interfaces defined where an application can interact with the rest of the user interface. In general, it is prohibited that an application directly communicates with another application. These communications should always be routed either through the system UI or the underlying services. If the interface shall also be used by for example other displays, the information is better routed through a service. If the information is only relevant for the current display it shall be routed through the system UI. In general, we talk about horizontal communication if an application talks to the system UI and vertical communication if an application talks to a service. UI Types The user interface follows a hierarchical tree structure. Each node displays a fragment of the information or is used to structure the user interface. Some nodes inside the UI tree have a special purpose and ensure the tree has clear border lines and certain areas do not get exposed to unnecessary dependencies. Adding a dependency to a UI element makes it harder to test it or to launch it independently from the rest of the UI tree. But this should be our target to test and launch individual UI components independently from each other and thus creating an environment where adding more UI elements not necessarily slows down the process. The most prominent UI type is the component. It encapsulates a portion of the UI tree and uses other components to delegate rendering of the required information. As such it provides a higher level of abstraction ( C1 , C2 , C3 ) to a UI feature. These components form an own hierarchy within the UI tree and are used as the base for further specializing components. In general, we differentiate between UI primitives (e.g. rectangles and images) and controls (e.g. buttons) as individual UI types. To combine several UI types panels or views shall be used. These are specific container-types to layout other containers as child UI types or controls. UI primitives are only used inside controls, as the controls have support for styling the UI. The difference between a panel and a view is that the view interfaces with the stores (the business logic layer of the application) but the panel not. Services Service offers a feature to the user interface or other services. Service is located from the architectural perspective below the user interface in a separate layer. Typically a service runs on a different process belonging to the platform. The service exposes a client API which allows the client to access the service. Service is normally started by the system but often can also be started on demand when first used by the client through its API. Services are bundled into a server. A server can contain one or more services. Each service exposes an API to the clients. Typically a service interfaces with the system or external services. Ideally, a service provides the data in a way that clients can easily consume them efficiently. The generic APIs will increase the work needed on the client side to gather all relevant data for a UI view. Services shall be constructed as micro-services and should not directly depend on other services or services APIs. If there are needs for some dependencies between services it is better to use some form of an ID (e.g. a text identifier) to identify the referenced information on the other service. It is then up to the service implementation to resolve the reference. Jobs A job is a long-running piece of work which may return some results. A job execution length is long enough to disturb the UI from rendering. Typically this computing is done on a service in a different process but this is not always possible or desirable. To run a job on the UI process it needs to run inside a thread pool and the result needs to be reported back. In QtC++ the easiest way of doing this would be the QRunnable in conjunction with the QThreadPool. In QML this would be the WorkerScript to execute a long-running JS script. Single / Multi Process In a single-process architecture, all UI code is executed inside a single process. This makes the initial coding and architecture much simpler. A single process architecture lacks separation of concerns. All UI code can access all other UI code API surface and by this depend on each other. This can easily create dirty code when no experienced developers take part in a project. Also, the security means are nonexistent in a single process UI in comparison to a multi-process one. A multi-process UI separates concerns into separate processes and uses the security system of the OS to isolate these processes. An application developer has no means of playing around with the system UI memory apart from the APIs offered to him. This allows for much better scaling of application development efforts as independent teams can work on independent code spots which are separated by process boundaries. Ideally, one team would work on the system UI process and the interface for applications whereas others would work on the applications themselves. The CoreUI architecture is designed to support a single and multi-process architecture. The main difference between these two setups is the separation of applications into different processes. Debugging Qt debugging is described at https://doc.qt.io/qt-5.10/debug.html and QML debugging is described here: http://doc.qt.io/qt-5/qtquick-debugging.html . This section is more about visual UI debugging techniques. As the UI is composed of larger building blocks which the CoreUI Architecture forces to be of a specific type we can add debugging instruments into these blocks. For example, to visually trace views and panels the base classes can render their outline and by this allow a developer to validate its layout. Testing CoreUI forces the developer to extract all business logic into stores. These stores are pure data elements and thus can be nicely tested. The UI shall be concerned only about the UI logic and not the business logic. Further CoreUI cuts the UI into smaller logical pieces called controls, panels, views where each of them has a defined dependency and such it is fairly easy to create a test harness for each of these UI elements. Testing is an integral part of CoreUI. There are dedicated folders with test runners in QML and C++ to ensure your tests are bundled with the code. Inspection Inspection appears when a running UI is inspected live. As a user, you get live insights from the running execution by using a console interface (for QML/JS) or via a visual interface (e.g. visualize the UI hierarchy, component boundaries, z-ordering), or through event reporting where events are logged more or less visually (e.g. events, signals). But also you want to inspect the communication the UI holds horizontally and vertically with the services. Inspection can be either embedded into the process (e.g. into the runtime) or can be attached to a running process. The first case is great for deployment as the runtime is already enabled with the inspection UI but it might have an impact on the runtime performance. The other option is to launch an independent inspector tool (e.g. GammaRay <https://www.kdab.com/development-resources/qt-tools/gammaray/> ) and attach it to the running executable. This inspector tool comes with a dedicated user interface to help you understand the UI execution flow but also being able to manipulate certain values. Package Manager A package manager allows the user or the system to install a binary package. There are two different package types: application and system packages. The application package is used to install and remove an application. It is designed to be easy to use and to bundle all dependencies into the application package. It relies on a refined version of the platform. The system package is a bundle which also contains dependency information and may even run some initialization scripts. The number of features depends on the package system used. This allows a system builder to build a new version of the system and ensure all dependent packages will be also installed. The application package is designed to be self-contained, for security and stability issues. It is not allowed that an application package modifies the system, by e.g. installing a depending service or a new version of a library. Allowing this could lead to an unstable system. It should be noted that it is possible to wrap an application package into a system package. The system package installer would then run the application package manager to install the bundled application. Normally this does not work in reverse: An application package to bundle a system package.","title":"Building Blocks"},{"location":"topics/blocks/#building-blocks","text":"Info This material is work in progress and will change! Abstract Building blocks are loosely coupled concepts which when arranged in the right order they form the foundation of the CoreUI. Through the loose coupling, you can also create a different architecture. This follows the principle that CoreUI is an opinionated stack and as such reflects our best efforts. Don't expect ready-made code solutions, these are concepts.","title":"Building Blocks"},{"location":"topics/blocks/#user-interface","text":"We consider the user interface as the front-facing interface towards the user, aka front-end. For the underlying system facing interface, we use the term back-end. The front-end is concerned about the visual integrity of the UI and its appeal. A special focus lies upon the dialog with the user interface design team to create a stunning user experience for the users as one. The User Interface requires to communicate with the underlying system services as well as with services outside the system (aka remote services). The user interface is responsible to render every pixel on the screen and to achieve being an emotional user interface using animations and transitions. Typically a user interface is seen as a user interface tree, where the root is the initial UI portion being loaded. It is important that the user interface has control about which portions of the UI are loaded as the UI is the only layer which has the understanding. The user interface is typically developed in QML/JavaScript and Qt/C++. Note Describe the definition of the UI and the different building blocks (e.g. SUI/AppS/UIControls) The user interface is the highest layer inside a system. It offers information and interactions to the user. It is driven by the information architecture specification and the user-interface design specification. The central screens of a user interface are typically centralized inside the system UI. These screens are used to show to the user frequently needed information but also other information and interactions to navigate deeper into the user interface. The user interface itself is often seen as a tree of user interface elements, where on the root level you have the display and the structure follows on the high level of the information architecture. There are often links between unrelated UI nodes which provide shortcuts to the user to show or retrieve certain information. The UI tree on the higher levels is also divided into UI layers to ensure the most important information is shown above other less important information. The user interface is framed by the requirements specification, the user interface specification, the UI testing, and the underlying system. For working on a particular software layer it is always important to understand and embrace the adjacent layers. Here the user interface developers work closely together with the design team that creates the user interface specification. The requirements team provides non-functional and functional requirements which need to be adherent by the UI developers. The testing team needs to have support to allow smooth planning of the user interface layer. And the system provides the foundation where the user interface can be executed (either desktop or embedded) and also provides the underlying services the user interface needs to interface with.","title":"User Interface"},{"location":"topics/blocks/#ui-runtime","text":"A runtime is responsible to initialize the user interface library and load a minimal set of extensions that are required to load the initial UI. From then on, the UI itself will take control of the loading of other UI parts. runtime --import imports Main.qml Often a runtime is made using a configuration document which can be written in JSON or a similar data-interchange format. { \"imports\" : [ \"imports\" ], \"document\" : \"Main.qml\" } In the Qt/QML case, the default runtime is the qmlscene which is great for simple prototypes but for a more complex project you want to create a custom runtime, especially for loading your custom boot extensions.","title":"UI Runtime"},{"location":"topics/blocks/#ui-extensions","text":"An extension extends the runtime with new features and capabilities on dynamically on runtime. They are delivered as a module and typically loaded on-demand from the UI code. In the Qt/QML context, the extensions are called QML plug-ins. An extension, in general, can extend the runtime horizontally with new capabilities (for example to render a new type of content) or vertically (for example to communicate with a tuner service). Loading the extensions on demand allows the execution from different code paths using different extensions. Also as the extensions are looked up using the import path you can inject a mock extension into the import path before the real extension for test purposes. Note These extensions can be either written in QML or in Qt/C++ (or mixed). Often a developer first starts to write some extensions in QML for prototyping and later those will be re-written as C++ extensions to use a browser API and achieve the best performance.","title":"UI Extensions"},{"location":"topics/blocks/#system-ui","text":"The UI started first is called the System UI. Think about your user interface and remove all applications, what is left is called the System UI. The System UI is responsible for booting the user interface system efficiently enough so that a minimal usable user interface, is operational by the user, is reached to be shown on the screen. The System UI is also responsible for layout application windows and to provide additional information overlays to the user. Another important point of the system UI is to act as a gateway to control and prioritize access to the display surface for dialogs and notifications. Lastly, it's responsible for displaying the application launcher that acts as a shell to launch applications. Boot the user interface until a minimal usable state is reached Layout application window surfaces Control display access for dialogs and notifications Manage user interface overlays Present a user interface to launch applications","title":"System UI"},{"location":"topics/blocks/#system-ui-layers","text":"The System UI defines the fundamental visual layering structure of the user interface. It creates the main rendering surface and controls other applications and dialog windows. A typical System UI can be divided into several layer containers. The visual topmost layer is the dialog layer which displays notifications. The notifications are system-wide controlled allowing the system UI to decide when and how a notification shall be displayed, as another, more important, the notification may be currently displayed. Just below the dialog layer, lies the overlay layer. This layer provides additional, not primary, information to the user, enhancing the information awareness and providing shortcuts to frequently used functions such as volume, climate information, etc. Below the overlays there are the application surfaces, that is a standard way to extend the system UI using features packed into applications. An application is mostly displayed full-screen but can also have different states, for example when used as a widget to preview and/or interact with certain application information in a condensed way. The launcher finally displays all available applications. A traditional way to display the different applications is using a grid with icons and a small text containing the application name and when this is clicked to launch the respective application full-screen. Another possibility could be to use a flexible grid of application widgets which when each is clicked expands into a full-screen application. The advantage of the first approach is that the application doesn't have to be launched but only meta information is presented (like its icon and name). Below the launcher, there could be an optional background image, e.g. the desktop background. In QML code this would roughly look like this. // Display.qml Item { id: root Image { id: background } Container { id: launcherLayer } Container { id: appLayer } Container { id: overlayLayer } Container { id: dialogLayer } }","title":"System UI Layers"},{"location":"topics/blocks/#stage-loading","text":"To allow the System UI to be launched in a controlled and efficient manner the typical way is to stage load the SysUI. Stage loading is a practice to dynamically load partially user interfaces using a state machine or a similar controller which is controlled by external information and/or the current state of the machine. For this reason, the UI tree represented by the System UI has to be divided into smaller parts that can be loaded independently. The partitioning is done using a standard component approach and the loading is done using the Loader type which is directed by an SCXML state machine. The state machine state changes are triggered by either external events and conditions and the overall loading state. Note For development purposes, it is also possible to shortcut some loading stages.","title":"Stage Loading"},{"location":"topics/blocks/#application","text":"An application is a set of UI screens that represent the same logical context and are rendered into the same window surface. In a multi-process system, an application is started into its own process. An application should share ideally only a small and generic API with the other horizontal components (System UI, other applications) on the same layer and use a vertical communication to interface with the system. The System UI is also seen as a special application which responsibilities are specialized in the sense that it is responsible for the early UI startup, managing application windows and displaying a UI to launch these applications as extensions to the UI. Using an application does not have to be the only way to extend or structure the user interface. A small portion of the application will interact with the system UI and window handling. These parts shall be refactored out into own components. Similar is true for application logic interacting with the underlying services. That user interface portion of the application ideally should not expose services to the UI, it should instead be wrapped into an own module bundling this application logic and empowering this way better testability.","title":"Application"},{"location":"topics/blocks/#communication","text":"There are several interfaces defined where an application can interact with the rest of the user interface. In general, it is prohibited that an application directly communicates with another application. These communications should always be routed either through the system UI or the underlying services. If the interface shall also be used by for example other displays, the information is better routed through a service. If the information is only relevant for the current display it shall be routed through the system UI. In general, we talk about horizontal communication if an application talks to the system UI and vertical communication if an application talks to a service.","title":"Communication"},{"location":"topics/blocks/#ui-types","text":"The user interface follows a hierarchical tree structure. Each node displays a fragment of the information or is used to structure the user interface. Some nodes inside the UI tree have a special purpose and ensure the tree has clear border lines and certain areas do not get exposed to unnecessary dependencies. Adding a dependency to a UI element makes it harder to test it or to launch it independently from the rest of the UI tree. But this should be our target to test and launch individual UI components independently from each other and thus creating an environment where adding more UI elements not necessarily slows down the process. The most prominent UI type is the component. It encapsulates a portion of the UI tree and uses other components to delegate rendering of the required information. As such it provides a higher level of abstraction ( C1 , C2 , C3 ) to a UI feature. These components form an own hierarchy within the UI tree and are used as the base for further specializing components. In general, we differentiate between UI primitives (e.g. rectangles and images) and controls (e.g. buttons) as individual UI types. To combine several UI types panels or views shall be used. These are specific container-types to layout other containers as child UI types or controls. UI primitives are only used inside controls, as the controls have support for styling the UI. The difference between a panel and a view is that the view interfaces with the stores (the business logic layer of the application) but the panel not.","title":"UI Types"},{"location":"topics/blocks/#services","text":"Service offers a feature to the user interface or other services. Service is located from the architectural perspective below the user interface in a separate layer. Typically a service runs on a different process belonging to the platform. The service exposes a client API which allows the client to access the service. Service is normally started by the system but often can also be started on demand when first used by the client through its API. Services are bundled into a server. A server can contain one or more services. Each service exposes an API to the clients. Typically a service interfaces with the system or external services. Ideally, a service provides the data in a way that clients can easily consume them efficiently. The generic APIs will increase the work needed on the client side to gather all relevant data for a UI view. Services shall be constructed as micro-services and should not directly depend on other services or services APIs. If there are needs for some dependencies between services it is better to use some form of an ID (e.g. a text identifier) to identify the referenced information on the other service. It is then up to the service implementation to resolve the reference.","title":"Services"},{"location":"topics/blocks/#jobs","text":"A job is a long-running piece of work which may return some results. A job execution length is long enough to disturb the UI from rendering. Typically this computing is done on a service in a different process but this is not always possible or desirable. To run a job on the UI process it needs to run inside a thread pool and the result needs to be reported back. In QtC++ the easiest way of doing this would be the QRunnable in conjunction with the QThreadPool. In QML this would be the WorkerScript to execute a long-running JS script.","title":"Jobs"},{"location":"topics/blocks/#single-multi-process","text":"In a single-process architecture, all UI code is executed inside a single process. This makes the initial coding and architecture much simpler. A single process architecture lacks separation of concerns. All UI code can access all other UI code API surface and by this depend on each other. This can easily create dirty code when no experienced developers take part in a project. Also, the security means are nonexistent in a single process UI in comparison to a multi-process one. A multi-process UI separates concerns into separate processes and uses the security system of the OS to isolate these processes. An application developer has no means of playing around with the system UI memory apart from the APIs offered to him. This allows for much better scaling of application development efforts as independent teams can work on independent code spots which are separated by process boundaries. Ideally, one team would work on the system UI process and the interface for applications whereas others would work on the applications themselves. The CoreUI architecture is designed to support a single and multi-process architecture. The main difference between these two setups is the separation of applications into different processes.","title":"Single / Multi Process"},{"location":"topics/blocks/#debugging","text":"Qt debugging is described at https://doc.qt.io/qt-5.10/debug.html and QML debugging is described here: http://doc.qt.io/qt-5/qtquick-debugging.html . This section is more about visual UI debugging techniques. As the UI is composed of larger building blocks which the CoreUI Architecture forces to be of a specific type we can add debugging instruments into these blocks. For example, to visually trace views and panels the base classes can render their outline and by this allow a developer to validate its layout.","title":"Debugging"},{"location":"topics/blocks/#testing","text":"CoreUI forces the developer to extract all business logic into stores. These stores are pure data elements and thus can be nicely tested. The UI shall be concerned only about the UI logic and not the business logic. Further CoreUI cuts the UI into smaller logical pieces called controls, panels, views where each of them has a defined dependency and such it is fairly easy to create a test harness for each of these UI elements. Testing is an integral part of CoreUI. There are dedicated folders with test runners in QML and C++ to ensure your tests are bundled with the code.","title":"Testing"},{"location":"topics/blocks/#inspection","text":"Inspection appears when a running UI is inspected live. As a user, you get live insights from the running execution by using a console interface (for QML/JS) or via a visual interface (e.g. visualize the UI hierarchy, component boundaries, z-ordering), or through event reporting where events are logged more or less visually (e.g. events, signals). But also you want to inspect the communication the UI holds horizontally and vertically with the services. Inspection can be either embedded into the process (e.g. into the runtime) or can be attached to a running process. The first case is great for deployment as the runtime is already enabled with the inspection UI but it might have an impact on the runtime performance. The other option is to launch an independent inspector tool (e.g. GammaRay <https://www.kdab.com/development-resources/qt-tools/gammaray/> ) and attach it to the running executable. This inspector tool comes with a dedicated user interface to help you understand the UI execution flow but also being able to manipulate certain values.","title":"Inspection"},{"location":"topics/blocks/#package-manager","text":"A package manager allows the user or the system to install a binary package. There are two different package types: application and system packages. The application package is used to install and remove an application. It is designed to be easy to use and to bundle all dependencies into the application package. It relies on a refined version of the platform. The system package is a bundle which also contains dependency information and may even run some initialization scripts. The number of features depends on the package system used. This allows a system builder to build a new version of the system and ensure all dependent packages will be also installed. The application package is designed to be self-contained, for security and stability issues. It is not allowed that an application package modifies the system, by e.g. installing a depending service or a new version of a library. Allowing this could lead to an unstable system. It should be noted that it is possible to wrap an application package into a system package. The system package installer would then run the application package manager to install the bundled application. Normally this does not work in reverse: An application package to bundle a system package.","title":"Package Manager"},{"location":"topics/controls/","text":"Common Controls Info This material is work in progress and will change! Common Controls are shared controls between the applications. They form semantic user interfaces. Often they are built out of UI primitives such as rectangles, mouse areas, images, etc. and expose a defined high-level API. These controls are designed after the user interface specification and especially they follow the UI style guide as a central guide which defines the visual appearance. Controls are tightly bound to styles as the style defines the visual appearance of a control. It is often desirable to separate the logic of a control from the visual appearance and ideally make the appearance pluggable. This can be reached by thinking about a control as a template for a real control. This template contains only the common logic of a control and can even be coded in C++ for optimization. The visual appearance would then be added when a concrete control is defined. To know which concrete control needs to be used, the framework contains a logic to use a different control based on the style setting. This acts very much like a factory class where the object creation is separated from the object creation request. The framework takes care about ensuring the correct concrete control is created. This is the pattern used in the QtQuick.Controls V2 ( https://doc.qt.io/qt-5.10/qtquickcontrols2-index.html ) controls library. It forms a common set of controls which is used typically in modern touch-based user interfaces without coupling them to the style. The library comes with a common set of styles to get started and allows a team to define fully its own style. On a high level, this is done by having the template classes implement the control logic and a style adding the geometry and appearance of background and content to the control ( https://doc.qt.io/qt-5.10/qtquickcontrols2-customize.html ). It is also possible to create completely new controls but often this is not required and a new control can often be formed by either styling or aggregating two or more controls to a new control. Note As long as a control behaves like an existing control template (e.g. a button is clicked) the visual appearance can be adjusted. Typical Controls These are the controls currently supported by QtQuick Controls 2. This should be used as a short overview of the available controls and to form a vocabulary with the design team. Control - Control is the base type of user interface controls. Buttons Controls AbstractButton - Abstract base type providing functionality common to buttons Button - Push-button that can be clicked to perform a command or to answer a question CheckBox - Check button that can be toggled on or off DelayButton - Check button that triggers when held down long enough RadioButton - Exclusive radio button that can be toggled on or off RoundButton - A push-button control with rounded corners that can be clicked by the user Switch - Button that can be toggled on or off ToolButton - Button with a look suitable for a ToolBar Container Controls ApplicationWindow - Styled top-level window with support for a header and footer Container - Abstract base type providing functionality common to containers Frame - Visual frame for a logical group of controls GroupBox - Visual frame and title for a logical group of controls Page - Styled page control with support for a header and footer Pane - Provides a background matching with the application style and theme ScrollView - Scrollable view StackView - Provides a stack-based navigation model SwipeView - Enables the user to navigate pages by swiping sideways TabBar - Allows the user to switch between different views or subtasks ToolBar - Container for context-sensitive controls Delegate Controls ItemDelegate - Presents a checkable control that can be pressed and clicked by the user. CheckDelegate - Item delegate with a check indicator that can be toggled on or off RadioDelegate - Exclusive item delegate with a radio indicator that can be toggled on or off SwipeDelegate - Swipable item delegate SwitchDelegate - Item delegate with a switch indicator that can be toggled on or off Indicator Controls BusyIndicator - Indicates background activity, for example, while content is being loaded PageIndicator - Indicates the currently active page ProgressBar - Indicates the progress of an operation ScrollBar - Vertical or horizontal interactive scroll bar ScrollIndicator - Vertical or horizontal non-interactive scroll indicator Input Controls ComboBox - Combined button and popup list for selecting options Dial - Circular dial that is rotated to set a value RangeSlider - Used to select a range of values by sliding two handles along a track Slider - Used to select a value by sliding a handle along a track TextArea - Multi-line text input area TextField - Single-line text input field Tumbler - Spinnable wheel of items that can be selected Menu Controls Menu - Popup that can be used as a context menu or popup menu MenuBar - Provides a window menu bar MenuBarItem - Presents a drop-down menu within a MenuBar MenuItem - Presents an item within a Menu Navigation Controls Drawer - Side panel that can be opened and closed using a swipe gesture StackView - Provides a stack-based navigation model SwipeView - Enables the user to navigate pages by swiping sideways TabBar - Allows the user to switch between different views or subtasks TabButton - Button with a look suitable for a TabBar Popup Controls Dialog - Popup dialog with standard buttons and a title, used for short-term interaction with the user Drawer - Side panel that can be opened and closed using a swipe gesture Menu - Popup that can be used as a context menu or popup menu Popup - a Base type of popup-like user interface controls ToolTip - Provides tooltips for any control Separator Controls MenuSeparator - Separates a group of items in a menu from adjacent items ToolSeparator - Separates a group of items in a toolbar from adjacent items Laying out Controls Laying out controls is the process of positioning controls on a panel and deciding on their growth policy. Either the control shall expand when the parent is resized or not. If an item is not intended to grow positioners can do the work, otherwise layouts are always preferred. To support layout mirroring the LayoutMirroring attached property is available. Positioners Container items that manage the positions of items. Grid - Positions its children in grid formation Row - Positions its children in a row Column - Positions its children in a column Flow - Positions its children side by side, wrapping as necessary Layouts Used to arrange items in a user interface. RowLayout - Identical to GridLayout, but having only one row. ColumnLayout - Identical to GridLayout, but having only one column. GridLayout - Provides a way of dynamically arranging items in a grid. StackLayout - Provides a stack of items where only one item is visible at a time The behavior of the items inside a layout can be influenced using the [Layout ` attached property. Common vs. Application Controls Common controls are shared between all applications and are designed to work in these different contexts. An application control is private to an application. Often an application control is derived from the need of the UI specification for a very special visual appearance. This could be for example a slider to change the radio frequency. This control would be very specific to a radio application and normally not required by other application. As such it would be defined inside the application and not in a common control library. Besides this difference of physical location, the creation process is the same.","title":"Controls"},{"location":"topics/controls/#common-controls","text":"Info This material is work in progress and will change! Common Controls are shared controls between the applications. They form semantic user interfaces. Often they are built out of UI primitives such as rectangles, mouse areas, images, etc. and expose a defined high-level API. These controls are designed after the user interface specification and especially they follow the UI style guide as a central guide which defines the visual appearance. Controls are tightly bound to styles as the style defines the visual appearance of a control. It is often desirable to separate the logic of a control from the visual appearance and ideally make the appearance pluggable. This can be reached by thinking about a control as a template for a real control. This template contains only the common logic of a control and can even be coded in C++ for optimization. The visual appearance would then be added when a concrete control is defined. To know which concrete control needs to be used, the framework contains a logic to use a different control based on the style setting. This acts very much like a factory class where the object creation is separated from the object creation request. The framework takes care about ensuring the correct concrete control is created. This is the pattern used in the QtQuick.Controls V2 ( https://doc.qt.io/qt-5.10/qtquickcontrols2-index.html ) controls library. It forms a common set of controls which is used typically in modern touch-based user interfaces without coupling them to the style. The library comes with a common set of styles to get started and allows a team to define fully its own style. On a high level, this is done by having the template classes implement the control logic and a style adding the geometry and appearance of background and content to the control ( https://doc.qt.io/qt-5.10/qtquickcontrols2-customize.html ). It is also possible to create completely new controls but often this is not required and a new control can often be formed by either styling or aggregating two or more controls to a new control. Note As long as a control behaves like an existing control template (e.g. a button is clicked) the visual appearance can be adjusted.","title":"Common Controls"},{"location":"topics/controls/#typical-controls","text":"These are the controls currently supported by QtQuick Controls 2. This should be used as a short overview of the available controls and to form a vocabulary with the design team. Control - Control is the base type of user interface controls.","title":"Typical Controls"},{"location":"topics/controls/#buttons-controls","text":"AbstractButton - Abstract base type providing functionality common to buttons Button - Push-button that can be clicked to perform a command or to answer a question CheckBox - Check button that can be toggled on or off DelayButton - Check button that triggers when held down long enough RadioButton - Exclusive radio button that can be toggled on or off RoundButton - A push-button control with rounded corners that can be clicked by the user Switch - Button that can be toggled on or off ToolButton - Button with a look suitable for a ToolBar","title":"Buttons Controls"},{"location":"topics/controls/#container-controls","text":"ApplicationWindow - Styled top-level window with support for a header and footer Container - Abstract base type providing functionality common to containers Frame - Visual frame for a logical group of controls GroupBox - Visual frame and title for a logical group of controls Page - Styled page control with support for a header and footer Pane - Provides a background matching with the application style and theme ScrollView - Scrollable view StackView - Provides a stack-based navigation model SwipeView - Enables the user to navigate pages by swiping sideways TabBar - Allows the user to switch between different views or subtasks ToolBar - Container for context-sensitive controls","title":"Container Controls"},{"location":"topics/controls/#delegate-controls","text":"ItemDelegate - Presents a checkable control that can be pressed and clicked by the user. CheckDelegate - Item delegate with a check indicator that can be toggled on or off RadioDelegate - Exclusive item delegate with a radio indicator that can be toggled on or off SwipeDelegate - Swipable item delegate SwitchDelegate - Item delegate with a switch indicator that can be toggled on or off","title":"Delegate Controls"},{"location":"topics/controls/#indicator-controls","text":"BusyIndicator - Indicates background activity, for example, while content is being loaded PageIndicator - Indicates the currently active page ProgressBar - Indicates the progress of an operation ScrollBar - Vertical or horizontal interactive scroll bar ScrollIndicator - Vertical or horizontal non-interactive scroll indicator","title":"Indicator Controls"},{"location":"topics/controls/#input-controls","text":"ComboBox - Combined button and popup list for selecting options Dial - Circular dial that is rotated to set a value RangeSlider - Used to select a range of values by sliding two handles along a track Slider - Used to select a value by sliding a handle along a track TextArea - Multi-line text input area TextField - Single-line text input field Tumbler - Spinnable wheel of items that can be selected","title":"Input Controls"},{"location":"topics/controls/#menu-controls","text":"Menu - Popup that can be used as a context menu or popup menu MenuBar - Provides a window menu bar MenuBarItem - Presents a drop-down menu within a MenuBar MenuItem - Presents an item within a Menu","title":"Menu Controls"},{"location":"topics/controls/#navigation-controls","text":"Drawer - Side panel that can be opened and closed using a swipe gesture StackView - Provides a stack-based navigation model SwipeView - Enables the user to navigate pages by swiping sideways TabBar - Allows the user to switch between different views or subtasks TabButton - Button with a look suitable for a TabBar","title":"Navigation Controls"},{"location":"topics/controls/#popup-controls","text":"Dialog - Popup dialog with standard buttons and a title, used for short-term interaction with the user Drawer - Side panel that can be opened and closed using a swipe gesture Menu - Popup that can be used as a context menu or popup menu Popup - a Base type of popup-like user interface controls ToolTip - Provides tooltips for any control","title":"Popup Controls"},{"location":"topics/controls/#separator-controls","text":"MenuSeparator - Separates a group of items in a menu from adjacent items ToolSeparator - Separates a group of items in a toolbar from adjacent items","title":"Separator Controls"},{"location":"topics/controls/#laying-out-controls","text":"Laying out controls is the process of positioning controls on a panel and deciding on their growth policy. Either the control shall expand when the parent is resized or not. If an item is not intended to grow positioners can do the work, otherwise layouts are always preferred. To support layout mirroring the LayoutMirroring attached property is available.","title":"Laying out Controls"},{"location":"topics/controls/#positioners","text":"Container items that manage the positions of items. Grid - Positions its children in grid formation Row - Positions its children in a row Column - Positions its children in a column Flow - Positions its children side by side, wrapping as necessary","title":"Positioners"},{"location":"topics/controls/#layouts","text":"Used to arrange items in a user interface. RowLayout - Identical to GridLayout, but having only one row. ColumnLayout - Identical to GridLayout, but having only one column. GridLayout - Provides a way of dynamically arranging items in a grid. StackLayout - Provides a stack of items where only one item is visible at a time The behavior of the items inside a layout can be influenced using the [Layout ` attached property.","title":"Layouts"},{"location":"topics/controls/#common-vs-application-controls","text":"Common controls are shared between all applications and are designed to work in these different contexts. An application control is private to an application. Often an application control is derived from the need of the UI specification for a very special visual appearance. This could be for example a slider to change the radio frequency. This control would be very specific to a radio application and normally not required by other application. As such it would be defined inside the application and not in a common control library. Besides this difference of physical location, the creation process is the same.","title":"Common vs. Application Controls"},{"location":"topics/extensions/","text":"Extensions Info This material is work in progress and will change!","title":"Extensions"},{"location":"topics/extensions/#extensions","text":"Info This material is work in progress and will change!","title":"Extensions"},{"location":"topics/foundations/","text":"Foundations Info This material is work in progress and will change! Abstract CoreUI is founded on some core-principles collected over the years, which all contribute to the overall design decisions. These principles are based on the opinions of many but may not be applicable to everyone. Here are some key principles: Follow the Agile Principles - UX depends on flexibility and agility. Keep it that way. Enable Hot-Reloading everywhere - Allow changes to be visible in a fraction of a second. Testability and dependency management is paramount - You can't trust code you cannot test. And trust is the foundation of large systems. Separation of Hardware and Software - As a UI developer you don't want to depend on something you cannot control or isn't even available at an early stage. UX Design is a bi-directional conversation - Design has a great impact on the UX, but also the chosen technology. Finding the balance and pushing forward together makes heroes. Thinking in Components and Building Blocks - Component-based programming leads to a better structure and allows for building larger user interfaces. Component separation is good, process separation is better - Trust is good, having control is better. A process gives you more control. Aspect driven components - Design your component layers around different aspects of your software. Each aspect provides another piece to the puzzle. A detailed description for each principle can be found below. Agile Principles CoreUI embodies the core values of the Manifesto for Agile Software development. Agility means in its core to \"walk the path even if you don't know the whole path yet\". It is about taking the opportunity and relying on motivated teams. Individuals and Interactions over processes and tools: Tools and processes are important, but it's more important to have competent people working together effectively. Working Software over comprehensive documentation : Good documentation is useful in helping people to understand how the software is built and how to use it, but the main point of development is to create software, not documentation. Customer Collaboration over contract negotiation : A contract is important but is no substitute for working closely with customers to discover what they need. Responding to Change over following a plan : A project plan is important, but it mustn't be too rigid to accommodate changes in technology or the environment, stakeholders' priorities, and people's understanding of the problem and its solution. In short, while there is value in the items on the right, they value the items on the left more. [^AgilePrinciples] Sources: Wikipedia, Agile Manifesto Live-reloading Live-reloading is the practice of reloading the program as a whole or as part of a particular change in the underlying source code. That change can be triggered by a keystroke, a timer, or based on document persistence. The reloading can be either state preserving or state resetting. Enabling live-reloading throughout the CoreUI architecture serves several goals: Productivity: CoreUI enforces a clean abstraction of business-logic and visual-logic, thus making the reloading of business tests part of the daily work-flow. Testability: CoreUI not only supports live-reloading of the whole program but also encourages Developers to live-reload individual pieces of the user interface. As such it encourages the developer to think about components and their dependencies, thus resulting in better testability. UX Creation: Reloading also plays a crucial role in enabling great UX by making the conversation that the developer has with the UI teams more fluent. Testability and Controlled Dependency CoreUI separates user interface pieces into different components with clearly-defined dependencies and interfaces. CoreUI encourages the developer to create smaller, well-defined, components. The idea is less about re-use but more about splitting the UI into small, manageable, pieces which can be implemented independently. This principle manages dependencies and smaller components, enabling testability with fewer headaches or overhead. CoreUI comes with a test harness which enables both manual component testing and automated component testing. Manual component testing is especially useful during development, when you want to try out a specific component. All of this can be paired with live-reloading of such tests: either when the test code itself or the underlying component changes. Separation of Hardware from Software Developing embedded software means always working with the target hardware. However, often the target hardware is not available in the early stages of development or even at later stages. Additionally, there may also be a shortage of devices and each developer can't have his or her own device to work with. These hardware can be big and difficult to place in an office. Consequently, the ability to develop as much software as possible without depending on the target hardware is highly desirable. Nevertheless, it is still required to go on the hardware as early as possible. This brings up the requirement of being flexible enough to support compatibility between different back-ends using the same front-end software. Ideally, you are able to run the front-end with either a simulation backend or with the real, production, one. Ideally, the simulation back-end can also run on the target HW. To foster easier front-end development it should also be possible to run the front-end on a desktop and have it using a back-end running on the target HW. To achieve this, the interface between front-end and back-end must be done via a cross-device communication protocol (typically TCP/IP based). UX Design Conversations Creating a stunning UX is a team effort involving UI designers, UI developers, and other stakeholders. The System needs to be able to deliver the processing power and graphics capabilities allowing a stunning user experience at first place, but even if this is given, still there is not a guarantee that a great UX will be created. To achieve a truly beautiful UX it is required that the visionary people who design the product and deliver the information architecture and UI appearance, work closely together with the people programming the UI. Only then a great UX can be achieved. The UI developers know what the system can deliver and which special effects and/or animations will take down the system and will start introducing an unsatisfying user experience to the user. The UI designers have their own vision into their head but often the documentation is lacking behind and also does not tell the whole story. These internal concepts not documented but expressed in design are important for the UI developers as they also need to base their detailed UI appearance on fundamental concepts. If these fundamental concepts diverge because of not being aware of each other, the UI code will always look like someone has patched it to make it work. A true harmony and understanding of UI design of the UI developer can be seen in the clean UI code produced by the developers. Thinking in Components While the UI developer using QML is forced to think in components as its basic building block, designers often don't think in terms of components. This is probably related to the pixels on a display and the tooling used that is based on pixel manipulation, less vector art, and objects. A component is a piece of a reusable user interface from which the information architecture receives a clear set of data and provides a clearly defined interaction to the user. This component can then be re-used in other parts of the user interface by manipulating the incoming properties. For example, a Button receives a text property which can be set when created, and allows the user to click on it as its interaction. This component can be used anywhere a button is used by assigning a different text property and reacting differently to the click interaction. Designing a square rectangle of pixels with a nice gradient, without thinking about how this rectangle eventually becomes a component with appearance, incoming data, and interaction - will result in the designer not being able to use the button everywhere coherently. Consequently, the developer will have to implement each of these buttons, providing the different flavors of buttons by adding more complex code to the initial component. Ideally, the designer comes up with a Style and Component guide which lists all common usable components together with their modifiers and interactions. This list should then be used to construct concrete user interfaces out of these components; custom components should be a rare exception. There is a common set of components that users are used to, which are often provided as standard components by the UI toolkits. Qt, for example, provides the QtQuick Controls 2 library. On a higher level, it is also worth thinking about larger components, such as components that act as a container for other components. In CoreUI, they are called panels. Panels provide a defined layout and interaction possibility for a set of components laid out together, for either a specific or a more general purpose. If a component can be re-used in different contexts it can also be re-used in a test setup. That said, it's important to display a component independently from its UI context to validate its appearance and behavior. Components vs. Processes A component is a reusable piece of user interface, with a known exported programming interface. A process is an execution unit, which allows the CPU to schedule it independently from other processes and manage the memory independently from other processes. A process provides security and separation of interfaces. Inside a process, you cannot easily call an API which is available inside another process. You always need to export this API and then make use of that from within the other process via some form of IPC. But processes can be re-used the same as components, but on a different level and with a much stricter control. Typically an application is a deciding factor to create a new process. An application can stem from a 3rd party and might introduce a security risk, so it is better to control its access to the system. In a single process UI where an application is merely a component, these security mechanisms do not exist, so any application can in general access every API. Aspect-driven Components Traditional UI development follows the user interface specifications and starts with the main document and then the folder structure mirrors the feature set of the UI specification. Applying this on larger user interfaces provides several drawbacks. The code gets more complex as deeper the folder structure goes. There is no guideline about dependency, which leads to the fact that even components on the edge of the UI tree might have dependencies to central components or worse other edges of the tree. Not controlling dependency is the main factor that the development speed slows down when the UI gets more complex. Aspect driven development tries to focus on the different aspects of a user interface (e.g. views, panels, controls, animations, helpers) and tries to provide clear guidance how such a component shall be constructed and which dependencies it might create. Release Early, Release Often Celebrate releasing your software. Releasing software is a practice which needs to be repeated and automated as much as possible. Always keep your software in a releasable state. Releasing usually means you have to interrupt your software development to make a release. By repeating this process over and over and perfecting the workflow, you can minimize the disruption a release creates and ensure your code stays in good health. You want to run a Continuous Integration (CI) workflow with a maximum number of automated tests, which ideally proves the test coverage. Try to release software that acts as feedback to your developers so that they experience releasing as a natural step forward. in the software development process. For example, if you work on the UI, you can release the platform that the UI is based on and ensure all developers use the same platform. See: https://en.wikipedia.org/wiki/Release_early,_release_often","title":"Foundations"},{"location":"topics/foundations/#foundations","text":"Info This material is work in progress and will change! Abstract CoreUI is founded on some core-principles collected over the years, which all contribute to the overall design decisions. These principles are based on the opinions of many but may not be applicable to everyone. Here are some key principles: Follow the Agile Principles - UX depends on flexibility and agility. Keep it that way. Enable Hot-Reloading everywhere - Allow changes to be visible in a fraction of a second. Testability and dependency management is paramount - You can't trust code you cannot test. And trust is the foundation of large systems. Separation of Hardware and Software - As a UI developer you don't want to depend on something you cannot control or isn't even available at an early stage. UX Design is a bi-directional conversation - Design has a great impact on the UX, but also the chosen technology. Finding the balance and pushing forward together makes heroes. Thinking in Components and Building Blocks - Component-based programming leads to a better structure and allows for building larger user interfaces. Component separation is good, process separation is better - Trust is good, having control is better. A process gives you more control. Aspect driven components - Design your component layers around different aspects of your software. Each aspect provides another piece to the puzzle. A detailed description for each principle can be found below.","title":"Foundations"},{"location":"topics/foundations/#agile-principles","text":"CoreUI embodies the core values of the Manifesto for Agile Software development. Agility means in its core to \"walk the path even if you don't know the whole path yet\". It is about taking the opportunity and relying on motivated teams. Individuals and Interactions over processes and tools: Tools and processes are important, but it's more important to have competent people working together effectively. Working Software over comprehensive documentation : Good documentation is useful in helping people to understand how the software is built and how to use it, but the main point of development is to create software, not documentation. Customer Collaboration over contract negotiation : A contract is important but is no substitute for working closely with customers to discover what they need. Responding to Change over following a plan : A project plan is important, but it mustn't be too rigid to accommodate changes in technology or the environment, stakeholders' priorities, and people's understanding of the problem and its solution. In short, while there is value in the items on the right, they value the items on the left more. [^AgilePrinciples] Sources: Wikipedia, Agile Manifesto","title":"Agile Principles"},{"location":"topics/foundations/#live-reloading","text":"Live-reloading is the practice of reloading the program as a whole or as part of a particular change in the underlying source code. That change can be triggered by a keystroke, a timer, or based on document persistence. The reloading can be either state preserving or state resetting. Enabling live-reloading throughout the CoreUI architecture serves several goals: Productivity: CoreUI enforces a clean abstraction of business-logic and visual-logic, thus making the reloading of business tests part of the daily work-flow. Testability: CoreUI not only supports live-reloading of the whole program but also encourages Developers to live-reload individual pieces of the user interface. As such it encourages the developer to think about components and their dependencies, thus resulting in better testability. UX Creation: Reloading also plays a crucial role in enabling great UX by making the conversation that the developer has with the UI teams more fluent.","title":"Live-reloading"},{"location":"topics/foundations/#testability-and-controlled-dependency","text":"CoreUI separates user interface pieces into different components with clearly-defined dependencies and interfaces. CoreUI encourages the developer to create smaller, well-defined, components. The idea is less about re-use but more about splitting the UI into small, manageable, pieces which can be implemented independently. This principle manages dependencies and smaller components, enabling testability with fewer headaches or overhead. CoreUI comes with a test harness which enables both manual component testing and automated component testing. Manual component testing is especially useful during development, when you want to try out a specific component. All of this can be paired with live-reloading of such tests: either when the test code itself or the underlying component changes.","title":"Testability and Controlled Dependency"},{"location":"topics/foundations/#separation-of-hardware-from-software","text":"Developing embedded software means always working with the target hardware. However, often the target hardware is not available in the early stages of development or even at later stages. Additionally, there may also be a shortage of devices and each developer can't have his or her own device to work with. These hardware can be big and difficult to place in an office. Consequently, the ability to develop as much software as possible without depending on the target hardware is highly desirable. Nevertheless, it is still required to go on the hardware as early as possible. This brings up the requirement of being flexible enough to support compatibility between different back-ends using the same front-end software. Ideally, you are able to run the front-end with either a simulation backend or with the real, production, one. Ideally, the simulation back-end can also run on the target HW. To foster easier front-end development it should also be possible to run the front-end on a desktop and have it using a back-end running on the target HW. To achieve this, the interface between front-end and back-end must be done via a cross-device communication protocol (typically TCP/IP based).","title":"Separation of Hardware from Software"},{"location":"topics/foundations/#ux-design-conversations","text":"Creating a stunning UX is a team effort involving UI designers, UI developers, and other stakeholders. The System needs to be able to deliver the processing power and graphics capabilities allowing a stunning user experience at first place, but even if this is given, still there is not a guarantee that a great UX will be created. To achieve a truly beautiful UX it is required that the visionary people who design the product and deliver the information architecture and UI appearance, work closely together with the people programming the UI. Only then a great UX can be achieved. The UI developers know what the system can deliver and which special effects and/or animations will take down the system and will start introducing an unsatisfying user experience to the user. The UI designers have their own vision into their head but often the documentation is lacking behind and also does not tell the whole story. These internal concepts not documented but expressed in design are important for the UI developers as they also need to base their detailed UI appearance on fundamental concepts. If these fundamental concepts diverge because of not being aware of each other, the UI code will always look like someone has patched it to make it work. A true harmony and understanding of UI design of the UI developer can be seen in the clean UI code produced by the developers.","title":"UX Design Conversations"},{"location":"topics/foundations/#thinking-in-components","text":"While the UI developer using QML is forced to think in components as its basic building block, designers often don't think in terms of components. This is probably related to the pixels on a display and the tooling used that is based on pixel manipulation, less vector art, and objects. A component is a piece of a reusable user interface from which the information architecture receives a clear set of data and provides a clearly defined interaction to the user. This component can then be re-used in other parts of the user interface by manipulating the incoming properties. For example, a Button receives a text property which can be set when created, and allows the user to click on it as its interaction. This component can be used anywhere a button is used by assigning a different text property and reacting differently to the click interaction. Designing a square rectangle of pixels with a nice gradient, without thinking about how this rectangle eventually becomes a component with appearance, incoming data, and interaction - will result in the designer not being able to use the button everywhere coherently. Consequently, the developer will have to implement each of these buttons, providing the different flavors of buttons by adding more complex code to the initial component. Ideally, the designer comes up with a Style and Component guide which lists all common usable components together with their modifiers and interactions. This list should then be used to construct concrete user interfaces out of these components; custom components should be a rare exception. There is a common set of components that users are used to, which are often provided as standard components by the UI toolkits. Qt, for example, provides the QtQuick Controls 2 library. On a higher level, it is also worth thinking about larger components, such as components that act as a container for other components. In CoreUI, they are called panels. Panels provide a defined layout and interaction possibility for a set of components laid out together, for either a specific or a more general purpose. If a component can be re-used in different contexts it can also be re-used in a test setup. That said, it's important to display a component independently from its UI context to validate its appearance and behavior.","title":"Thinking in Components"},{"location":"topics/foundations/#components-vs-processes","text":"A component is a reusable piece of user interface, with a known exported programming interface. A process is an execution unit, which allows the CPU to schedule it independently from other processes and manage the memory independently from other processes. A process provides security and separation of interfaces. Inside a process, you cannot easily call an API which is available inside another process. You always need to export this API and then make use of that from within the other process via some form of IPC. But processes can be re-used the same as components, but on a different level and with a much stricter control. Typically an application is a deciding factor to create a new process. An application can stem from a 3rd party and might introduce a security risk, so it is better to control its access to the system. In a single process UI where an application is merely a component, these security mechanisms do not exist, so any application can in general access every API.","title":"Components vs. Processes"},{"location":"topics/foundations/#aspect-driven-components","text":"Traditional UI development follows the user interface specifications and starts with the main document and then the folder structure mirrors the feature set of the UI specification. Applying this on larger user interfaces provides several drawbacks. The code gets more complex as deeper the folder structure goes. There is no guideline about dependency, which leads to the fact that even components on the edge of the UI tree might have dependencies to central components or worse other edges of the tree. Not controlling dependency is the main factor that the development speed slows down when the UI gets more complex. Aspect driven development tries to focus on the different aspects of a user interface (e.g. views, panels, controls, animations, helpers) and tries to provide clear guidance how such a component shall be constructed and which dependencies it might create.","title":"Aspect-driven Components"},{"location":"topics/foundations/#release-early-release-often","text":"Celebrate releasing your software. Releasing software is a practice which needs to be repeated and automated as much as possible. Always keep your software in a releasable state. Releasing usually means you have to interrupt your software development to make a release. By repeating this process over and over and perfecting the workflow, you can minimize the disruption a release creates and ensure your code stays in good health. You want to run a Continuous Integration (CI) workflow with a maximum number of automated tests, which ideally proves the test coverage. Try to release software that acts as feedback to your developers so that they experience releasing as a natural step forward. in the software development process. For example, if you work on the UI, you can release the platform that the UI is based on and ensure all developers use the same platform. See: https://en.wikipedia.org/wiki/Release_early,_release_often","title":"Release Early, Release Often"},{"location":"topics/fslayout/","text":"Physical Layout Info This material is work in progress and will change! Abstract The structure is the physical file and folder structure which defines the UI layer. It is composed of a sysui, applications, a controls library and styles. The UI is launched using a runtime and can be extended by native and qml extensions. The high-level structure divides the UI in SysUI and Apps as also an imports folder where shared components are located. Main . qml sysui / apps / imports / You would run the UI using your custom runtime something like this: runtime -I imports Main.qml The SysUI is seen as a specialized application. The concept of an application allows the developer to split the code into smaller manageable parts which are loosely coupled and have a high degree of separation (open-close-principle). Thus allowing a developer to extend an application with clean interfaces without harming the system UI. Open Closed Principle The open/closed principle states \"software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification\"; that is, such an entity can allow its behavior to be extended without modifying its source code ( https://en.wikipedia.org/wiki/Open/closed_principle ). System UI Structure The System UI is a specialized application which is the initial UI is started. Depending of the complexity of the SysUI the sysui itself can be structured like an application or in a complex SysUI each aspect of the SysUI (e.g. home, launcher, app container, overlays) can be structured similarly to an application. For a simple and medium complex SysUI the structure might look like this sysui / AppShell . qml controls / panels / views / HomeLayerView . qml LauncherLayerView . qml AppContainerLayerView . qml OverlayLayerView . qml DisplayView . qml stores / RootStore . qml HomeStore . qml ApplicationStore . qml OverlayStore . qml helpers / For a complex SysUI the structure might be divided by the different UI aspects and each aspect will be formed as an independent application structure. It is important that an aspect does not directly depend on other aspects. They might depend on incoming properties, and services. sysui / AppShell . qml home / controls / panels / views / stores / helpers / overlays / controls / panels / views / stores / helpers / launcher / controls / panels / views / stores / helpers / display - Is concerned about UI portions which affect the entire display, such as the main display UI element or virtual keyboard. home - Contains the UI portions for the initial home page to be shown to the user. This screen is often very customizable and centrally to the further exploration of the UI. launcher - Shows the launcher screen, which allows you to launch more applications. Often this is a grid of application icons but it could have any form. Sometimes the designed user interface also does not require a dedicated launcher page. appcontainer - The application container the place where launched applications are shown. It contains also any application decoration or in case the application can have also a widget state the common widget decoration. overlays - Overlays is an own container in which overlays (e.g. system information, climate control, audio control) can be placed, based on the UI design. Note An application can have often several visual states. When the application is minimized and presents only a minimal UI (for example a weather app shows only the current temperature), this application UI is called a widget. A widget is typically arranged into a grid with other widgets and when activated it expands to the full application. Each of these portions of the system UI shall be structured like an independent light-weight application. It may be necessary for the future to move one of these system UI portions out into an own standalone application for performance or startup time reasons, or just for manageability. Application Structure An application is a collection of UI blocks glued together using a container. The service communication is created using a store mechanism. The store is a hierarchical object tree where each object represents a portion of the overall user interface. Todo Add diagram for store and UI relationship apps / demo / Application . qml info . yaml stores / RootStore . qml StatusStore . qml views / ContainerView . qml WelcomeView . qml StatusView . qml panels / MasterDetailsPanel . qml controls / CustomButton . qml store - A store encapsulates the business logic and vertical communication view - A view larger UI building block which is allowed to use a store panel - A panel UI container for controls with no direct dependency to a store control - A control is a smaller building block for user interfaces Import Structure The imports folder contains shared modules, which can be used by either the system UI or an application. These imports are mainly QML based imports. Other Qt C++ native imports can be provided by using the Qt QML plugin system. A module is an extension to the runtime. A runtime can load modules from more than one import location located in different folders. By default all imports are loaded which are in the Qt SDK under the qml directory, this is also the default location for custom QtQuick plugins. Note The UI layer should only be composed of QML/JS documents to ensure frontend developers are not exposed to C++ code and can focus on the UX. Module names should be chosen carefully that they do not conflict with the Qt5 module but they should also not be so long as to feel cumbersome for the user to type. There is no need for 1st and 2nd party modules to use the reverse URI scheme for module naming. It has provided more useful to name the modules with two name depth or more to the user. Typical module names could be: controls - for the custom control library controls.style - for the style information inside y9our control utils - for shared helper modules The SysUI has an own import path to ensure privately used modules by the SysUI are not exposed to other applications. ui / apps / imports / sysui / imports / Native plugins are part of the platform layer and are nor part of the UI layer. Note Shared modules are part of the official API exposed to the applications. You should ensure all APIs are well designed and thought through as these APIs are difficult to change afterwards.","title":"Filesystem layout"},{"location":"topics/fslayout/#physical-layout","text":"Info This material is work in progress and will change! Abstract The structure is the physical file and folder structure which defines the UI layer. It is composed of a sysui, applications, a controls library and styles. The UI is launched using a runtime and can be extended by native and qml extensions. The high-level structure divides the UI in SysUI and Apps as also an imports folder where shared components are located. Main . qml sysui / apps / imports / You would run the UI using your custom runtime something like this: runtime -I imports Main.qml The SysUI is seen as a specialized application. The concept of an application allows the developer to split the code into smaller manageable parts which are loosely coupled and have a high degree of separation (open-close-principle). Thus allowing a developer to extend an application with clean interfaces without harming the system UI. Open Closed Principle The open/closed principle states \"software entities (classes, modules, functions, etc.) should be open for extension, but closed for modification\"; that is, such an entity can allow its behavior to be extended without modifying its source code ( https://en.wikipedia.org/wiki/Open/closed_principle ).","title":"Physical Layout"},{"location":"topics/fslayout/#system-ui-structure","text":"The System UI is a specialized application which is the initial UI is started. Depending of the complexity of the SysUI the sysui itself can be structured like an application or in a complex SysUI each aspect of the SysUI (e.g. home, launcher, app container, overlays) can be structured similarly to an application. For a simple and medium complex SysUI the structure might look like this sysui / AppShell . qml controls / panels / views / HomeLayerView . qml LauncherLayerView . qml AppContainerLayerView . qml OverlayLayerView . qml DisplayView . qml stores / RootStore . qml HomeStore . qml ApplicationStore . qml OverlayStore . qml helpers / For a complex SysUI the structure might be divided by the different UI aspects and each aspect will be formed as an independent application structure. It is important that an aspect does not directly depend on other aspects. They might depend on incoming properties, and services. sysui / AppShell . qml home / controls / panels / views / stores / helpers / overlays / controls / panels / views / stores / helpers / launcher / controls / panels / views / stores / helpers / display - Is concerned about UI portions which affect the entire display, such as the main display UI element or virtual keyboard. home - Contains the UI portions for the initial home page to be shown to the user. This screen is often very customizable and centrally to the further exploration of the UI. launcher - Shows the launcher screen, which allows you to launch more applications. Often this is a grid of application icons but it could have any form. Sometimes the designed user interface also does not require a dedicated launcher page. appcontainer - The application container the place where launched applications are shown. It contains also any application decoration or in case the application can have also a widget state the common widget decoration. overlays - Overlays is an own container in which overlays (e.g. system information, climate control, audio control) can be placed, based on the UI design. Note An application can have often several visual states. When the application is minimized and presents only a minimal UI (for example a weather app shows only the current temperature), this application UI is called a widget. A widget is typically arranged into a grid with other widgets and when activated it expands to the full application. Each of these portions of the system UI shall be structured like an independent light-weight application. It may be necessary for the future to move one of these system UI portions out into an own standalone application for performance or startup time reasons, or just for manageability.","title":"System UI Structure"},{"location":"topics/fslayout/#application-structure","text":"An application is a collection of UI blocks glued together using a container. The service communication is created using a store mechanism. The store is a hierarchical object tree where each object represents a portion of the overall user interface. Todo Add diagram for store and UI relationship apps / demo / Application . qml info . yaml stores / RootStore . qml StatusStore . qml views / ContainerView . qml WelcomeView . qml StatusView . qml panels / MasterDetailsPanel . qml controls / CustomButton . qml store - A store encapsulates the business logic and vertical communication view - A view larger UI building block which is allowed to use a store panel - A panel UI container for controls with no direct dependency to a store control - A control is a smaller building block for user interfaces","title":"Application Structure"},{"location":"topics/fslayout/#import-structure","text":"The imports folder contains shared modules, which can be used by either the system UI or an application. These imports are mainly QML based imports. Other Qt C++ native imports can be provided by using the Qt QML plugin system. A module is an extension to the runtime. A runtime can load modules from more than one import location located in different folders. By default all imports are loaded which are in the Qt SDK under the qml directory, this is also the default location for custom QtQuick plugins. Note The UI layer should only be composed of QML/JS documents to ensure frontend developers are not exposed to C++ code and can focus on the UX. Module names should be chosen carefully that they do not conflict with the Qt5 module but they should also not be so long as to feel cumbersome for the user to type. There is no need for 1st and 2nd party modules to use the reverse URI scheme for module naming. It has provided more useful to name the modules with two name depth or more to the user. Typical module names could be: controls - for the custom control library controls.style - for the style information inside y9our control utils - for shared helper modules The SysUI has an own import path to ensure privately used modules by the SysUI are not exposed to other applications. ui / apps / imports / sysui / imports / Native plugins are part of the platform layer and are nor part of the UI layer. Note Shared modules are part of the official API exposed to the applications. You should ensure all APIs are well designed and thought through as these APIs are difficult to change afterwards.","title":"Import Structure"},{"location":"topics/intro/","text":"Introduction Info This material is work in progress and will change! CoreUI was created out of the need for a more structured way of creating User Interfaces (UIs) not only for applications but also for large systems. The current process works fine if only a few people work on a small UI. But, as the user interface starts to get bigger and the number of people working on the UI layer increases, then the existing process is no longer well defined. It just doesn't scale. Ideally, CoreUI provides a pattern to scale UI development linearly without scrutinizing the implementation of UI features. Motivation When observing Developers working on larger UIs, it is interesting to see the correlation between the development productivity and the UI complexity. Particularly, the development productivity drops as the UI complexity increases. For example, Developers need to start the whole UI to navigate into a detailed view to fine-tune some UI logic or even animation. Often, this is because the UI can't be broken down into smaller, manageable chunks. In practical terms, it's about isolating a smaller portion of the UI and being able to work and validate this smaller portion. Breaking down the UI often happens on larger layers. But for UI development where the UI experience is an important factor, it's necessary to fine-tune small aspects of the UI to achieve the desired look and behavior. You have to aim for a fast (10ms) round trip time to make the conversation seamless between Design and Development. You can easily avoid this situation with Qt and QML. While QML offers a great component model, it lacks a coherent approach to componentize the UI and to implement these UI components. Looking at the current development approach it is clear that the UI's physical structure and the component types are created by following the UI specification and not from a technical perspective. For a developer, it's not clear when and how exactly to split a component into smaller parts, and to ensure a component is truly reusable as well as usable outside of its context. TODO: Provide an example that shows a very simple UI and then displays the resulting code structure. For example a music player with controls. Consider using our old coding challenge for new developers. CoreUI is an attempt to create an architecture and process to streamline this component creation task, similar to a component factory. Enjoy the ride - JRyannel What is CoreUI? CoreUI is set of patterns and components to support a common user interface structure. It encourages both Developers and Designers to create a great user experience by focusing on the UI creation process. The CoreUI architecture stems from the creation and re-creation of user interface projects for various markets, especially the automotive one. After several re-creations of user interface projects for vertical markets, some patterns emerged. The CoreUI architecture as presented here is the distillation of these patterns. CoreUI is an embedded development framework using Qt5 and the QML/JS language. Programming embedded software user interfaces can often be unnecessarily complicated. CoreUI makes the programming of these user interfaces easier, by making assumptions about what every developer needs to get started to create stunning user interfaces. It allows you to develop user interfaces by writing less code but accomplishing more. CoreUI aims to bring back the fun and creativity to user interface development so that Developers and Designers can focus on the user experience again. CoreUI is based on the opinions of others. These opinions make assumptions about what is the best way to create user interfaces. CoreUI is meant to be used that way and discourages other ways. If you master CoreUI you'll probably experience a spike in productivity. If you keep up with your old habits and try to retrofit CoreUI with your old ways of working you may not reap CoreUI's full benefits. What CoreUI is not? CoreUI is partly a concrete framework but it's not an exact path; more as a guideline. Often during a project, not all of the requirements are foreseeable and it's necessary to deviate from the path given. CoreUI isn't an implementation of a user interface. It's also not designed for a single application, but covers a multi-application setup. CoreUI is not final :-) CoreUI Stack CoreuI is founded on top of Qt5 and QtAuto. Qt5 is the leading cross-platform native UI toolkit with an unprecedented focus on the user experience. It offers the developer all the necessary APIs to develop a truly native cross-platform application. QtAuto extends Qt5, bringing multi-process application capabilities and a service framework to the table. By this, QtAuto is extending Qt into the space of creating multi-process user interfaces for mid and high-end embedded systems. Even if QtAuto targets primarily the automotive market, it's limited to this market. CoreUI defines patterns and rules for the UI layer of a multi-process UI for embedded systems based on QtAuto. A reference implementation of CoreUI is the Neptune3 UI which is delivered together with QtAuto.","title":"Introduction"},{"location":"topics/intro/#introduction","text":"Info This material is work in progress and will change! CoreUI was created out of the need for a more structured way of creating User Interfaces (UIs) not only for applications but also for large systems. The current process works fine if only a few people work on a small UI. But, as the user interface starts to get bigger and the number of people working on the UI layer increases, then the existing process is no longer well defined. It just doesn't scale. Ideally, CoreUI provides a pattern to scale UI development linearly without scrutinizing the implementation of UI features.","title":"Introduction"},{"location":"topics/intro/#motivation","text":"When observing Developers working on larger UIs, it is interesting to see the correlation between the development productivity and the UI complexity. Particularly, the development productivity drops as the UI complexity increases. For example, Developers need to start the whole UI to navigate into a detailed view to fine-tune some UI logic or even animation. Often, this is because the UI can't be broken down into smaller, manageable chunks. In practical terms, it's about isolating a smaller portion of the UI and being able to work and validate this smaller portion. Breaking down the UI often happens on larger layers. But for UI development where the UI experience is an important factor, it's necessary to fine-tune small aspects of the UI to achieve the desired look and behavior. You have to aim for a fast (10ms) round trip time to make the conversation seamless between Design and Development. You can easily avoid this situation with Qt and QML. While QML offers a great component model, it lacks a coherent approach to componentize the UI and to implement these UI components. Looking at the current development approach it is clear that the UI's physical structure and the component types are created by following the UI specification and not from a technical perspective. For a developer, it's not clear when and how exactly to split a component into smaller parts, and to ensure a component is truly reusable as well as usable outside of its context. TODO: Provide an example that shows a very simple UI and then displays the resulting code structure. For example a music player with controls. Consider using our old coding challenge for new developers. CoreUI is an attempt to create an architecture and process to streamline this component creation task, similar to a component factory. Enjoy the ride - JRyannel","title":"Motivation"},{"location":"topics/intro/#what-is-coreui","text":"CoreUI is set of patterns and components to support a common user interface structure. It encourages both Developers and Designers to create a great user experience by focusing on the UI creation process. The CoreUI architecture stems from the creation and re-creation of user interface projects for various markets, especially the automotive one. After several re-creations of user interface projects for vertical markets, some patterns emerged. The CoreUI architecture as presented here is the distillation of these patterns. CoreUI is an embedded development framework using Qt5 and the QML/JS language. Programming embedded software user interfaces can often be unnecessarily complicated. CoreUI makes the programming of these user interfaces easier, by making assumptions about what every developer needs to get started to create stunning user interfaces. It allows you to develop user interfaces by writing less code but accomplishing more. CoreUI aims to bring back the fun and creativity to user interface development so that Developers and Designers can focus on the user experience again. CoreUI is based on the opinions of others. These opinions make assumptions about what is the best way to create user interfaces. CoreUI is meant to be used that way and discourages other ways. If you master CoreUI you'll probably experience a spike in productivity. If you keep up with your old habits and try to retrofit CoreUI with your old ways of working you may not reap CoreUI's full benefits.","title":"What is CoreUI?"},{"location":"topics/intro/#what-coreui-is-not","text":"CoreUI is partly a concrete framework but it's not an exact path; more as a guideline. Often during a project, not all of the requirements are foreseeable and it's necessary to deviate from the path given. CoreUI isn't an implementation of a user interface. It's also not designed for a single application, but covers a multi-application setup. CoreUI is not final :-)","title":"What CoreUI is not?"},{"location":"topics/intro/#coreui-stack","text":"CoreuI is founded on top of Qt5 and QtAuto. Qt5 is the leading cross-platform native UI toolkit with an unprecedented focus on the user experience. It offers the developer all the necessary APIs to develop a truly native cross-platform application. QtAuto extends Qt5, bringing multi-process application capabilities and a service framework to the table. By this, QtAuto is extending Qt into the space of creating multi-process user interfaces for mid and high-end embedded systems. Even if QtAuto targets primarily the automotive market, it's limited to this market. CoreUI defines patterns and rules for the UI layer of a multi-process UI for embedded systems based on QtAuto. A reference implementation of CoreUI is the Neptune3 UI which is delivered together with QtAuto.","title":"CoreUI Stack"},{"location":"topics/layouts/","text":"Layout Info This material is work in progress and will change! In the past the UI was a static view on the information to be presented. Today this view is very dynamic and the user expects the view to change its appearance based on the context the display is in. Another aspect of layout is the support for different screen sizes out of one code base. This aspect is important to support for example a low-end device and a mid and high-end device from only one code-base without re-writing the whole UI layer. The dynamic aspect of the layout of the visual elements always requires some fundamental rules defined by the design team the UI shall follow, the so called design language. Often these rules are based on a grid system or on other geometrical constraints. If such a fundamental layout system does not exist it will be impossible for a UI developer to code a UI that follows the UI specification in all different scenarios. The complexity of testing increases when a new device configuration is added to the supported list of devices. The testing requires to test all device configurations with all market variations. There needs to be though a test strategy planned for the UI testing. Resources https://www.designbetter.co/design-systems-handbook/ Layout Aspects The user interface specification is the base for the user interface implementation. To achieve a coherent UI the UI specification is linked to a design style guide identifying the different style elements used in the specification. The information and interaction is derived from an information architecture guide. These documents build the design foundation for the user interface implementation. A document does not have to be a typical document it can also be a set of documents or nowadays often wiki pages. Wiki pages have the advantage that they are less formal and transparent for the users to provide feedback and to interact with the authors of the content. It is important to create an open discussion between design and development teams to enrich the overall content and create the best experience for the users. The layout of a system includes the placing of UI elements but also their behavior on geometry changes. Additionally the layout also includes information about the used font and icons. The layout needs to adapt to the changes of the display size, or display orientation but also to changes based on the user interaction. Design Systems The most commonly used design system is the grid. It allows to divide the display in equally wide columns with common spacing. The content is vertically aligned which pleases the eye. Each major UI element needs to be placed according to the grid system. The grid content is not static it can be resized but it will snap on these grid cells. Geometry User interface elements are defined by the x,y position and their width, height expansion. The x,y position is relative to the parent element. The place in the UI tree is as such another aspect which defines a UI element. The position in the tree also defines the z-order of the element. The z-order defines if an element is rendered above or below another element. Through the property binding of QML it is possible to simply define relations between aspects of an item. Item { id: root width: 200 height: 200 Item { width: root . width / 2 height: root . height } Item { x: root . width / 2 width: root . width / 2 height: root . height } } Geometry relations can be easily expressed using the x,y,width,height properties and bind them either to static values or to another properties as an expression. Anchoring Anchoring is the process to bind one anchor line of an element to another anchor line of another (parent or sibling) element. The anchor lines can be left, right, top, bottom and the vertical and horizontal center. Anchoring can happen with an offset or so called margin to allow spacing of the elements. Anchoring of UI elements is a very powerful and strong way to express geometrical relationships between UI elements. It is used for major UI elements which should have a clear relationship. Positioning Special positioner elements allow to manipulate the x,y position according given rules. These positioners are called Row, Column, Grid, Flow. Be aware that these positioners only manipulate the x,y position of an element not width and height. Positioning is used when the width, height of elements should not have an influence on the layout. Most often Layout Managers are the preferred solution. Layout Manager A layout manager manages the full geometry of a UI element. There exist currenty three types of layout managers: RowLayout, ColumnLayout and GridLayout. In practice RowLayout and ColumnLayout are just simplified versions of the GridLayout. The GridLayout is really powerful, it supports setting preferred sizes, spacing, fills, spans, max/min sizes and margins. As a bonus the Layout supports also mirroring which can be used in user interfaces that should take care about different writing directions or in cars where the steering wheel is placed on the right or left side according to the country rules. Custom Layout Manager A layout of component is often defined inside a panel. It is also possible to extract the layout part of the panel into an own component. The layout component would then use loaders and component properties to load the components taking part in the layout and to control the layout. Here is an example of a border layout import QtQuick 2.10 import QtQuick . Controls 2.3 import QtQuick . Layouts 1.3 Control { id: control property alias topComponent: topLoader . sourceComponent property alias leftComponent: leftLoader . sourceComponent property alias rightComponent: rightLoader . sourceComponent property alias bottomComponent: bottomLoader . sourceComponent property alias centerComponent: centerLoader . sourceComponent background: ColumnLayout { implicitWidth: 640 implicitHeight: 480 spacing: 0 Loader { id: topLoader Layout.fillWidth: true Layout.preferredHeight: item ? item.height: - 1 } RowLayout { Layout.fillWidth: true Layout.fillHeight: true spacing: 0 Loader { id: leftLoader Layout.fillHeight: true Layout.preferredWidth: item ? item.width: - 1 } Loader { id: centerLoader Layout.fillWidth: true Layout.fillHeight: true } Loader { id: rightLoader Layout.fillHeight: true Layout.preferredWidth: item ? item.width: - 1 } } Loader { id: bottomLoader Layout.fillWidth: true Layout.preferredHeight: item ? item.height: - 1 } } } The loader acts as a placeholder for the control to be placed. The layout parameters depend on the existence of the particular control (e.g. Layout.preferredHeight: item?item.height:-1 ). By this you can create also more complex layouts and testing of these layouts can be done indepently from the UI. This custom layout can be used like any other component. import QtQuick 2.10 import QtQuick . Controls 2.3 BorderLayout { topComponent: Button { text: \"TOP\" } bottomComponent: Button { text: \"BOTTOM\" } rightComponent: Button { text: \"RIGHT\" } leftComponent: Button { text: \"LEFT\" } centerComponent: Button { text: \"CENTER\" } } Note A layout can also be implemented in QtC++ in a more performant way. This QML based layout has a small impact on performance as it creates a Loader for each part. In case you notice any delay you might want to look into moving this layout to QtC++.","title":"Layouts"},{"location":"topics/layouts/#layout","text":"Info This material is work in progress and will change! In the past the UI was a static view on the information to be presented. Today this view is very dynamic and the user expects the view to change its appearance based on the context the display is in. Another aspect of layout is the support for different screen sizes out of one code base. This aspect is important to support for example a low-end device and a mid and high-end device from only one code-base without re-writing the whole UI layer. The dynamic aspect of the layout of the visual elements always requires some fundamental rules defined by the design team the UI shall follow, the so called design language. Often these rules are based on a grid system or on other geometrical constraints. If such a fundamental layout system does not exist it will be impossible for a UI developer to code a UI that follows the UI specification in all different scenarios. The complexity of testing increases when a new device configuration is added to the supported list of devices. The testing requires to test all device configurations with all market variations. There needs to be though a test strategy planned for the UI testing. Resources https://www.designbetter.co/design-systems-handbook/","title":"Layout"},{"location":"topics/layouts/#layout-aspects","text":"The user interface specification is the base for the user interface implementation. To achieve a coherent UI the UI specification is linked to a design style guide identifying the different style elements used in the specification. The information and interaction is derived from an information architecture guide. These documents build the design foundation for the user interface implementation. A document does not have to be a typical document it can also be a set of documents or nowadays often wiki pages. Wiki pages have the advantage that they are less formal and transparent for the users to provide feedback and to interact with the authors of the content. It is important to create an open discussion between design and development teams to enrich the overall content and create the best experience for the users. The layout of a system includes the placing of UI elements but also their behavior on geometry changes. Additionally the layout also includes information about the used font and icons. The layout needs to adapt to the changes of the display size, or display orientation but also to changes based on the user interaction.","title":"Layout Aspects"},{"location":"topics/layouts/#design-systems","text":"The most commonly used design system is the grid. It allows to divide the display in equally wide columns with common spacing. The content is vertically aligned which pleases the eye. Each major UI element needs to be placed according to the grid system. The grid content is not static it can be resized but it will snap on these grid cells.","title":"Design Systems"},{"location":"topics/layouts/#geometry","text":"User interface elements are defined by the x,y position and their width, height expansion. The x,y position is relative to the parent element. The place in the UI tree is as such another aspect which defines a UI element. The position in the tree also defines the z-order of the element. The z-order defines if an element is rendered above or below another element. Through the property binding of QML it is possible to simply define relations between aspects of an item. Item { id: root width: 200 height: 200 Item { width: root . width / 2 height: root . height } Item { x: root . width / 2 width: root . width / 2 height: root . height } } Geometry relations can be easily expressed using the x,y,width,height properties and bind them either to static values or to another properties as an expression.","title":"Geometry"},{"location":"topics/layouts/#anchoring","text":"Anchoring is the process to bind one anchor line of an element to another anchor line of another (parent or sibling) element. The anchor lines can be left, right, top, bottom and the vertical and horizontal center. Anchoring can happen with an offset or so called margin to allow spacing of the elements. Anchoring of UI elements is a very powerful and strong way to express geometrical relationships between UI elements. It is used for major UI elements which should have a clear relationship.","title":"Anchoring"},{"location":"topics/layouts/#positioning","text":"Special positioner elements allow to manipulate the x,y position according given rules. These positioners are called Row, Column, Grid, Flow. Be aware that these positioners only manipulate the x,y position of an element not width and height. Positioning is used when the width, height of elements should not have an influence on the layout. Most often Layout Managers are the preferred solution.","title":"Positioning"},{"location":"topics/layouts/#layout-manager","text":"A layout manager manages the full geometry of a UI element. There exist currenty three types of layout managers: RowLayout, ColumnLayout and GridLayout. In practice RowLayout and ColumnLayout are just simplified versions of the GridLayout. The GridLayout is really powerful, it supports setting preferred sizes, spacing, fills, spans, max/min sizes and margins. As a bonus the Layout supports also mirroring which can be used in user interfaces that should take care about different writing directions or in cars where the steering wheel is placed on the right or left side according to the country rules.","title":"Layout Manager"},{"location":"topics/layouts/#custom-layout-manager","text":"A layout of component is often defined inside a panel. It is also possible to extract the layout part of the panel into an own component. The layout component would then use loaders and component properties to load the components taking part in the layout and to control the layout. Here is an example of a border layout import QtQuick 2.10 import QtQuick . Controls 2.3 import QtQuick . Layouts 1.3 Control { id: control property alias topComponent: topLoader . sourceComponent property alias leftComponent: leftLoader . sourceComponent property alias rightComponent: rightLoader . sourceComponent property alias bottomComponent: bottomLoader . sourceComponent property alias centerComponent: centerLoader . sourceComponent background: ColumnLayout { implicitWidth: 640 implicitHeight: 480 spacing: 0 Loader { id: topLoader Layout.fillWidth: true Layout.preferredHeight: item ? item.height: - 1 } RowLayout { Layout.fillWidth: true Layout.fillHeight: true spacing: 0 Loader { id: leftLoader Layout.fillHeight: true Layout.preferredWidth: item ? item.width: - 1 } Loader { id: centerLoader Layout.fillWidth: true Layout.fillHeight: true } Loader { id: rightLoader Layout.fillHeight: true Layout.preferredWidth: item ? item.width: - 1 } } Loader { id: bottomLoader Layout.fillWidth: true Layout.preferredHeight: item ? item.height: - 1 } } } The loader acts as a placeholder for the control to be placed. The layout parameters depend on the existence of the particular control (e.g. Layout.preferredHeight: item?item.height:-1 ). By this you can create also more complex layouts and testing of these layouts can be done indepently from the UI. This custom layout can be used like any other component. import QtQuick 2.10 import QtQuick . Controls 2.3 BorderLayout { topComponent: Button { text: \"TOP\" } bottomComponent: Button { text: \"BOTTOM\" } rightComponent: Button { text: \"RIGHT\" } leftComponent: Button { text: \"LEFT\" } centerComponent: Button { text: \"CENTER\" } } Note A layout can also be implemented in QtC++ in a more performant way. This QML based layout has a small impact on performance as it creates a Loader for each part. In case you notice any delay you might want to look into moving this layout to QtC++.","title":"Custom Layout Manager"},{"location":"topics/preface/","text":"Preface Info This material is work in progress and will change! When you are part of a team that works on Qt Automotive Suite (short - Qt Auto), as Qt's vertical extension into the automotive market, you always wonder how new customers will approach Qt Auto, and how they will adapt it to their needs to create a truly stunning user experience for their automotive users. From our research projects and production projects with various customers, we have gained valuable insights into this interesting market. Each project has its own unique constellation of management, design, development, and partnerships. This guide attempts to lay the ground for a discussion about creating user interfaces with the technologies included in Qt Auto, using the Core UI architecture.. Naturally, customers may be motivated to deviate from this Core UI Guide where necessary. This book helps customers to get a base for fundamental discussions, internally, and the support required to come to a conclusion that helps them to achieve their own goals. /jryannel Why Most of the work in this guide is funded by Luxoft, an engineering services company. You may wonder why a service company is willing to publish essential knowledge in open source under fairly permissive licenses. This is because, when we conduct customer projects in the UI domain, we have noticed certain recurring patterns. Our philosophy is not based on watching customers stumble over the same problems. Instead, we would like to be part of the solution, and prevent these problems from recurring in the first place. In this guide, you will see many mentions of \"automotive\". This starts with the name \"Qt Automotive Suite\". Automotive has various specifics aspects. The same applies to embedded hardware and software in the Industrial sector. They have one interesting thing in common: they speak about Human Machine Interface (HMI) or about Man-Machine Interface (MMI), whereas HighTech speaks about User Interfaces (UI). User Experience (UX) is still known in Automotive, but for a long time, it mostly was in terms of interior of the car and all about using buttons, switches, and pedals arranged around the steering wheel. In the course of convergence and digitalization, Automotive started to invest in making interfaces for users and less for machines and in seeing this as essential part of UX. We firmly believe that the Industrial sector and Embedded in general will follow this trend soon to and benefit from this guide. The beginning This guide was initially designed and worked out by J\u00fcrgen Bocklage-Ryannel. Being a part of the team, he continues to contribute and collaborate with others who are listed below. The other sentence could be \"Unless otherwise noted, at the time of writing, all contributors are staff members of Luxoft. Contributors Bramastyo Harimukti Santoso Daniel d'Andrada Vladimir Minenko Alexandra Betouni License Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License (FDL) version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. The code samples in this document are provided under BSD 3-Clause \"New\" or \"Revised\" License as published by the SPDX Workgroup a Linux Foundation Project","title":"Preface"},{"location":"topics/preface/#preface","text":"Info This material is work in progress and will change! When you are part of a team that works on Qt Automotive Suite (short - Qt Auto), as Qt's vertical extension into the automotive market, you always wonder how new customers will approach Qt Auto, and how they will adapt it to their needs to create a truly stunning user experience for their automotive users. From our research projects and production projects with various customers, we have gained valuable insights into this interesting market. Each project has its own unique constellation of management, design, development, and partnerships. This guide attempts to lay the ground for a discussion about creating user interfaces with the technologies included in Qt Auto, using the Core UI architecture.. Naturally, customers may be motivated to deviate from this Core UI Guide where necessary. This book helps customers to get a base for fundamental discussions, internally, and the support required to come to a conclusion that helps them to achieve their own goals. /jryannel","title":"Preface"},{"location":"topics/preface/#why","text":"Most of the work in this guide is funded by Luxoft, an engineering services company. You may wonder why a service company is willing to publish essential knowledge in open source under fairly permissive licenses. This is because, when we conduct customer projects in the UI domain, we have noticed certain recurring patterns. Our philosophy is not based on watching customers stumble over the same problems. Instead, we would like to be part of the solution, and prevent these problems from recurring in the first place. In this guide, you will see many mentions of \"automotive\". This starts with the name \"Qt Automotive Suite\". Automotive has various specifics aspects. The same applies to embedded hardware and software in the Industrial sector. They have one interesting thing in common: they speak about Human Machine Interface (HMI) or about Man-Machine Interface (MMI), whereas HighTech speaks about User Interfaces (UI). User Experience (UX) is still known in Automotive, but for a long time, it mostly was in terms of interior of the car and all about using buttons, switches, and pedals arranged around the steering wheel. In the course of convergence and digitalization, Automotive started to invest in making interfaces for users and less for machines and in seeing this as essential part of UX. We firmly believe that the Industrial sector and Embedded in general will follow this trend soon to and benefit from this guide.","title":"Why"},{"location":"topics/preface/#the-beginning","text":"This guide was initially designed and worked out by J\u00fcrgen Bocklage-Ryannel. Being a part of the team, he continues to contribute and collaborate with others who are listed below. The other sentence could be \"Unless otherwise noted, at the time of writing, all contributors are staff members of Luxoft.","title":"The beginning"},{"location":"topics/preface/#contributors","text":"Bramastyo Harimukti Santoso Daniel d'Andrada Vladimir Minenko Alexandra Betouni","title":"Contributors"},{"location":"topics/preface/#license","text":"Permission is granted to copy, distribute and/or modify this document under the terms of the GNU Free Documentation License (FDL) version 1.3 or any later version published by the Free Software Foundation; with no Invariant Sections, no Front-Cover Texts, and no Back-Cover Texts. The code samples in this document are provided under BSD 3-Clause \"New\" or \"Revised\" License as published by the SPDX Workgroup a Linux Foundation Project","title":"License"},{"location":"topics/prototyping/","text":"Prototyping Info This material is work in progress and will change! User interface prototyping shall allow an early project to advance in the exploration of the user interface using a lean work flow. It is desirable but not always realistic that the resulting code shall follow the same architecture patterns and guides created for standard projects. Ideally, also the technology and used and the environment the technology is applied to shall be near a production. Making efforts to re-create a potential production environment ensures the outcome is somewhat comparable to a real scenario. For embedded devices it important also get as close as possible to the target setup by using a similar or even less powerful board and a similar display and input methods. Also the housing can be prototyped to allow a user to experience the UI in a near real setup scenario. Introduction What is the value of a user interface demonstrated on a high-end PC compared to the experience a user interface gives you in a comparable HW inside a setup comparable to the real HW where the user can explore the user interface? There needs always a balance between investment and revenue. If the revenue is high enough it is worthwhile going the extra mile to allow a potential user and stakeholders to experience the real device. During prototyping, you want to focus on the UX less on system creation. You want to be agile and move fast. The turnaround time of a solution might be just hours or days and you focus less on testing or completeness or even correctness. You feel okay to fake data or behavior when needed and use the real data when suitable. All of these decisions come with a cost, the prototyping software will never be your production software. The solution if carefully created might be used as a starting point for a product but seldom will evolve into a product. Often is is better and cheaper to start over again from the learning of the prototype code. Using a common architecture which is suited for prototyping and production increases the potential reuse and shortens time to market and the overall product creation costs. Todo Show a diagram which shows a product platform being used for UI exploration by using and extending services and by using and extending the UI layer. A carefully crafted production architecture should be flexible enough to be scaled from a prototyping phase into a production phase. It might require certain parts to be re-written as long as these parts are clearly marked and understood the effort and risk should be acceptable. Architecture In an early prototyping architecture, you might want to skip the multi-process mode of AppMan as it removes the dependency to a Wayland setup. You still want to keep the SysUI/Application structure as it provides you a clean plan where to provide your QML components. Services should be written using QML/JS and mock the behavior of a real service. A service with static data can be purely written using a QML file. If more dynamic data is require a JSON reader plug-in of HTTP requests API can be used to request more data, e.g. from JSON files or a JSON web service. Using JSON as the underlying mock-data format makes it easy to convert it into the QML/JS data types. Also MQTT can be easily used to provide mock-data and behavior or any. An important aspect of the data source used it should be easily installable on different systems and the data must be easily create and changeable. Otherwise the idea of prototyping is not full-filled. Todo Draw a diagram which showcases a production setup and a prototyping setup where the services are using other technologies but the client APIs are in QML. // service/counter/Counter.qml import http . requests 1.0 QtObject { id: root Requests { id: requests baseUrl: 'http://localhost:8888/api' } property var _state : ({ count: 0 }) readonly property int count: _state . count void increment () { requests . post ( 'increment' , function ( resp ) { _state = resp . data ; }); } void decrement () { requests . post ( 'decrement' , function ( resp ) { _state = resp . data ; }); } } The code snippet above uses a JSON rest API provided on local host, which on every call will return the full state of that interface. This makes the coding of the state update much easier. Your prototyping implementation might look completely different. A good technology to use could be the JSON server from NodeJS (see https://github.com/typicode/json-server ). Ideally, the resulting QML API can be easily consumed by the UI or the Stores. The API should hide which technology was used and only export the data and operations of the client API. By this, we can later change the implementation using a different technology and keep the UI from being cluttered with IPC calls. You would then use this mocked service client API as usual inside the RootStore. // stores/RootStore.qml import services . counter 1.0 QtObject { id: root Counter { id: counter } property alias count: counter . count function up () { if ( count < 10 ) { counter . increment () } } function down () { if ( count > 0 ) { counter . decrement () } } } This code snippet looks a little bit superficial as nothing really happens here, but in a more complex UI, a client and a store both carry different aspects of logic. It is a good practice to separate this aspect. A client to adopt an IPC conversation to a QML API and the Store to ensure the UI is clean of business logic. Reloading As the client API is now a QML part we can enable live-reloading on this part. No need to compile source code or deploy libraries. If a NodeJS server is used it also supports already live-reloading using the nodemon tool, which means our whole chain would be live re-loadable, which is one of the cornerstones for Rapid-UI-Prototyping. Live-reload everything! Enjoy!","title":"Protoyping"},{"location":"topics/prototyping/#prototyping","text":"Info This material is work in progress and will change! User interface prototyping shall allow an early project to advance in the exploration of the user interface using a lean work flow. It is desirable but not always realistic that the resulting code shall follow the same architecture patterns and guides created for standard projects. Ideally, also the technology and used and the environment the technology is applied to shall be near a production. Making efforts to re-create a potential production environment ensures the outcome is somewhat comparable to a real scenario. For embedded devices it important also get as close as possible to the target setup by using a similar or even less powerful board and a similar display and input methods. Also the housing can be prototyped to allow a user to experience the UI in a near real setup scenario.","title":"Prototyping"},{"location":"topics/prototyping/#introduction","text":"What is the value of a user interface demonstrated on a high-end PC compared to the experience a user interface gives you in a comparable HW inside a setup comparable to the real HW where the user can explore the user interface? There needs always a balance between investment and revenue. If the revenue is high enough it is worthwhile going the extra mile to allow a potential user and stakeholders to experience the real device. During prototyping, you want to focus on the UX less on system creation. You want to be agile and move fast. The turnaround time of a solution might be just hours or days and you focus less on testing or completeness or even correctness. You feel okay to fake data or behavior when needed and use the real data when suitable. All of these decisions come with a cost, the prototyping software will never be your production software. The solution if carefully created might be used as a starting point for a product but seldom will evolve into a product. Often is is better and cheaper to start over again from the learning of the prototype code. Using a common architecture which is suited for prototyping and production increases the potential reuse and shortens time to market and the overall product creation costs. Todo Show a diagram which shows a product platform being used for UI exploration by using and extending services and by using and extending the UI layer. A carefully crafted production architecture should be flexible enough to be scaled from a prototyping phase into a production phase. It might require certain parts to be re-written as long as these parts are clearly marked and understood the effort and risk should be acceptable.","title":"Introduction"},{"location":"topics/prototyping/#architecture","text":"In an early prototyping architecture, you might want to skip the multi-process mode of AppMan as it removes the dependency to a Wayland setup. You still want to keep the SysUI/Application structure as it provides you a clean plan where to provide your QML components. Services should be written using QML/JS and mock the behavior of a real service. A service with static data can be purely written using a QML file. If more dynamic data is require a JSON reader plug-in of HTTP requests API can be used to request more data, e.g. from JSON files or a JSON web service. Using JSON as the underlying mock-data format makes it easy to convert it into the QML/JS data types. Also MQTT can be easily used to provide mock-data and behavior or any. An important aspect of the data source used it should be easily installable on different systems and the data must be easily create and changeable. Otherwise the idea of prototyping is not full-filled. Todo Draw a diagram which showcases a production setup and a prototyping setup where the services are using other technologies but the client APIs are in QML. // service/counter/Counter.qml import http . requests 1.0 QtObject { id: root Requests { id: requests baseUrl: 'http://localhost:8888/api' } property var _state : ({ count: 0 }) readonly property int count: _state . count void increment () { requests . post ( 'increment' , function ( resp ) { _state = resp . data ; }); } void decrement () { requests . post ( 'decrement' , function ( resp ) { _state = resp . data ; }); } } The code snippet above uses a JSON rest API provided on local host, which on every call will return the full state of that interface. This makes the coding of the state update much easier. Your prototyping implementation might look completely different. A good technology to use could be the JSON server from NodeJS (see https://github.com/typicode/json-server ). Ideally, the resulting QML API can be easily consumed by the UI or the Stores. The API should hide which technology was used and only export the data and operations of the client API. By this, we can later change the implementation using a different technology and keep the UI from being cluttered with IPC calls. You would then use this mocked service client API as usual inside the RootStore. // stores/RootStore.qml import services . counter 1.0 QtObject { id: root Counter { id: counter } property alias count: counter . count function up () { if ( count < 10 ) { counter . increment () } } function down () { if ( count > 0 ) { counter . decrement () } } } This code snippet looks a little bit superficial as nothing really happens here, but in a more complex UI, a client and a store both carry different aspects of logic. It is a good practice to separate this aspect. A client to adopt an IPC conversation to a QML API and the Store to ensure the UI is clean of business logic.","title":"Architecture"},{"location":"topics/prototyping/#reloading","text":"As the client API is now a QML part we can enable live-reloading on this part. No need to compile source code or deploy libraries. If a NodeJS server is used it also supports already live-reloading using the nodemon tool, which means our whole chain would be live re-loadable, which is one of the cornerstones for Rapid-UI-Prototyping. Live-reload everything! Enjoy!","title":"Reloading"},{"location":"topics/refactor/","text":"Refactoring Info This material is work in progress and will change! Refactoring shall provide the reader with insights how to re-factor slowly an existing user interface architecture toward the CoreUI architecture by applying a series of micro-re-factorings. A micro-refactoring is a small rewrite of source code which fits mentally inside the developers head. This is important to ensure the developer is aware about any side-effects and can fix these before committing. We must avoid a large refactoring where the developer require days before the software is stable again. Ideally the software stays stable all the time during refactoring. Refactoring must be planned and executed over time. A larger user interface project can not be moved over night into a new direction, especially when many developer participate and still defects and features are on the road-map. To ensure the team has an understanding of the healthiness of the architecture certain KPI must be introduced and measured over time. Architecture KPIs A KPI (key performance indicator) provides high level insights about the healthiness of the software architecture. To understand the KPIs presented we need to understand that the UI is a tree with a root node and edge nodes and many nodes in between. Ideally the outer nodes are clean from difficult dependencies, whereas the inner notes can depend on those dependencies but even here ideally these dependencies are extracted into another set of objects, the stores. In general we have stores, views, panels and controls. The controls form the edge nodes of our UI tree. Right above the controls are the panels. The panels care the most UI load as they use semantic free controls to introduce application semantic. On top of the panels sit the views, they bring together the UI surface with the data providers the stores. Ideally these views only depend on these store. The stores finally encapsulate the application business logic and interface the platform services. Based on this description we can start to extract some KPIs. At first we need to identify the difficult dependencies. These are dependencies which make unit testing more painful. These harmful dependencies can be a module which uses a network service or a global object introducing global state or a rendering node which introduces certain hardware dependencies. We must ensure our goal to decompose the UI and unit test each component must not be compromised. Info Ensure UI can be decomposed and run independent and the testability is guaranteed. KPI - Number of singletons used in edge nodes Measure the number of singletons used in edge nodes and above (2nd level edges). This number indicates how much these nodes depend on global state. This number should go down over time. KPI - Relation of kind of components count vs the classic component count This measures the relation between the identified and converted kind of components to the uncategorized components. The goal is to ensure over time the number of components with unmanaged dependencies are reduced and the converted components can be checked for harmful imports. KPI - Number of harmful imports per kind of component This counts the number of harmful imports per kind of component. Ideally the controls and panels will reduce the number of harmful components and most harmful imports will be isolated inside the stores. Refactoring Cookbook See also: https://martinfowler.com/tags/refactoring.html Recipe: Stop leaking objects from singletons A singleton which exposes an object opens the opportunity for everyone to navigate the object internals. By this open up all kind of cross-dependencies. To close down this leakage we need to investigate how the object is used. Often we see pattern in the usage. The patterns then need to be extracted into a function, and the function would then navigate the object. Over time we will be able to eliminate the object from the public interface and only allow users to use these functions. From now on we can ensure no new internals of this object will be leaked. Recipe: Push singletons up When investigating the usage of certain singletons often they are used in a related code area. It seems developers where to lazy to pass in these dependencies and rather shortcut the relations. We can revert this by looking at the singleton usage in one component and move the usage up to the root level. In the next step we can then move the singleton onto the other side and pass it into the component. By this we effectively push the singleton usage on level up. Normally it is expected after several of these pushes you will reach a level where several child components suddenly depend on the same information injected from the singleton. To effectively predict how many levels you need to push up this dependency we would need to identify the node which creates the child nodes using the singleton. If we reach that point there is no need for a singleton and we can convert the singleton into an instance of even eliminate it all together. Recipe: Eliminate singletons A singleton normally shares global state, functionality and events. To eliminate this we need to find the common ancestor node from where we can inject the dependencies. For a share event, we often can just connect the signal with a state change on that level, for shared properties we could do similar. For common functionality we can connect a signal which bubbles up to a function being executed. Ideally the function is extracted into a store if its application business relevant. Recipe: Extract harmful dependency conditions A harmful dependency is a dependency which breaks decomposition and testability by introducing (often indirect) not testable dependencies (e.g. network, hardware, global state). For this to be eliminated we need to push the dependency up, by first moving the dependency out of the internal of the component to the root level of the component and in a second step injecting the dependency into the component form the outside. By this practically removing the dependency from that particular component. Recipe: Convert Component to Kinds A kind of component is a component which fits into a category. For this the component needs to be moved to a kind folder where all components of the same kind and which similar dependencies are collected. Ideally you start with the edge nodes and convert them to controls or panels. A component which uses other controls or panels is a panel. If a panel uses another panel it is better to start with the child panel. The component is just moved into a kind folder and the dependency from the calling component is updated. In a later step we can now start with that component. Be sure to only move components which follow the dependency guidelines, otherwise it is better to first eliminate of push up the harmful dependencies before moving the component. Recipe: Extract a Store After pushing conditions up tot he root level of the current component sometimes it is a good practice to collect them into an object. So the object gets injected into this component. This component is the first version of a potential store. This object then collects these dependencies and will carry the harmful dependencies. The component itself will only depend on this particular object (aka store). This makes it also easier to push dependencies up the UI tree as we only have to push the object up not individual properties.","title":"Refactoring"},{"location":"topics/refactor/#refactoring","text":"Info This material is work in progress and will change! Refactoring shall provide the reader with insights how to re-factor slowly an existing user interface architecture toward the CoreUI architecture by applying a series of micro-re-factorings. A micro-refactoring is a small rewrite of source code which fits mentally inside the developers head. This is important to ensure the developer is aware about any side-effects and can fix these before committing. We must avoid a large refactoring where the developer require days before the software is stable again. Ideally the software stays stable all the time during refactoring. Refactoring must be planned and executed over time. A larger user interface project can not be moved over night into a new direction, especially when many developer participate and still defects and features are on the road-map. To ensure the team has an understanding of the healthiness of the architecture certain KPI must be introduced and measured over time.","title":"Refactoring"},{"location":"topics/refactor/#architecture-kpis","text":"A KPI (key performance indicator) provides high level insights about the healthiness of the software architecture. To understand the KPIs presented we need to understand that the UI is a tree with a root node and edge nodes and many nodes in between. Ideally the outer nodes are clean from difficult dependencies, whereas the inner notes can depend on those dependencies but even here ideally these dependencies are extracted into another set of objects, the stores. In general we have stores, views, panels and controls. The controls form the edge nodes of our UI tree. Right above the controls are the panels. The panels care the most UI load as they use semantic free controls to introduce application semantic. On top of the panels sit the views, they bring together the UI surface with the data providers the stores. Ideally these views only depend on these store. The stores finally encapsulate the application business logic and interface the platform services. Based on this description we can start to extract some KPIs. At first we need to identify the difficult dependencies. These are dependencies which make unit testing more painful. These harmful dependencies can be a module which uses a network service or a global object introducing global state or a rendering node which introduces certain hardware dependencies. We must ensure our goal to decompose the UI and unit test each component must not be compromised. Info Ensure UI can be decomposed and run independent and the testability is guaranteed.","title":"Architecture KPIs"},{"location":"topics/refactor/#kpi-number-of-singletons-used-in-edge-nodes","text":"Measure the number of singletons used in edge nodes and above (2nd level edges). This number indicates how much these nodes depend on global state. This number should go down over time.","title":"KPI - Number of singletons used in edge nodes"},{"location":"topics/refactor/#kpi-relation-of-kind-of-components-count-vs-the-classic-component-count","text":"This measures the relation between the identified and converted kind of components to the uncategorized components. The goal is to ensure over time the number of components with unmanaged dependencies are reduced and the converted components can be checked for harmful imports.","title":"KPI - Relation of kind of components count vs the classic component count"},{"location":"topics/refactor/#kpi-number-of-harmful-imports-per-kind-of-component","text":"This counts the number of harmful imports per kind of component. Ideally the controls and panels will reduce the number of harmful components and most harmful imports will be isolated inside the stores.","title":"KPI - Number of harmful imports per kind of component"},{"location":"topics/refactor/#refactoring-cookbook","text":"See also: https://martinfowler.com/tags/refactoring.html","title":"Refactoring Cookbook"},{"location":"topics/refactor/#recipe-stop-leaking-objects-from-singletons","text":"A singleton which exposes an object opens the opportunity for everyone to navigate the object internals. By this open up all kind of cross-dependencies. To close down this leakage we need to investigate how the object is used. Often we see pattern in the usage. The patterns then need to be extracted into a function, and the function would then navigate the object. Over time we will be able to eliminate the object from the public interface and only allow users to use these functions. From now on we can ensure no new internals of this object will be leaked.","title":"Recipe: Stop leaking objects from singletons"},{"location":"topics/refactor/#recipe-push-singletons-up","text":"When investigating the usage of certain singletons often they are used in a related code area. It seems developers where to lazy to pass in these dependencies and rather shortcut the relations. We can revert this by looking at the singleton usage in one component and move the usage up to the root level. In the next step we can then move the singleton onto the other side and pass it into the component. By this we effectively push the singleton usage on level up. Normally it is expected after several of these pushes you will reach a level where several child components suddenly depend on the same information injected from the singleton. To effectively predict how many levels you need to push up this dependency we would need to identify the node which creates the child nodes using the singleton. If we reach that point there is no need for a singleton and we can convert the singleton into an instance of even eliminate it all together.","title":"Recipe: Push singletons up"},{"location":"topics/refactor/#recipe-eliminate-singletons","text":"A singleton normally shares global state, functionality and events. To eliminate this we need to find the common ancestor node from where we can inject the dependencies. For a share event, we often can just connect the signal with a state change on that level, for shared properties we could do similar. For common functionality we can connect a signal which bubbles up to a function being executed. Ideally the function is extracted into a store if its application business relevant.","title":"Recipe: Eliminate singletons"},{"location":"topics/refactor/#recipe-extract-harmful-dependency-conditions","text":"A harmful dependency is a dependency which breaks decomposition and testability by introducing (often indirect) not testable dependencies (e.g. network, hardware, global state). For this to be eliminated we need to push the dependency up, by first moving the dependency out of the internal of the component to the root level of the component and in a second step injecting the dependency into the component form the outside. By this practically removing the dependency from that particular component.","title":"Recipe: Extract harmful dependency conditions"},{"location":"topics/refactor/#recipe-convert-component-to-kinds","text":"A kind of component is a component which fits into a category. For this the component needs to be moved to a kind folder where all components of the same kind and which similar dependencies are collected. Ideally you start with the edge nodes and convert them to controls or panels. A component which uses other controls or panels is a panel. If a panel uses another panel it is better to start with the child panel. The component is just moved into a kind folder and the dependency from the calling component is updated. In a later step we can now start with that component. Be sure to only move components which follow the dependency guidelines, otherwise it is better to first eliminate of push up the harmful dependencies before moving the component.","title":"Recipe: Convert Component to Kinds"},{"location":"topics/refactor/#recipe-extract-a-store","text":"After pushing conditions up tot he root level of the current component sometimes it is a good practice to collect them into an object. So the object gets injected into this component. This component is the first version of a potential store. This object then collects these dependencies and will carry the harmful dependencies. The component itself will only depend on this particular object (aka store). This makes it also easier to push dependencies up the UI tree as we only have to push the object up not individual properties.","title":"Recipe: Extract a Store"},{"location":"topics/services/","text":"Services Info This material is work in progress and will change! Services exposes features either from the system or a networked resource to the application layer. Services can be categorized based on their process-association, inter-service dependencies and the handling of state. In general a service is an instance of vertical communication. This vertical communication can be done via an IPC out-of-process or via a library in-process. The API can be designed state-less or state-full. You should prefer state-full if the API shall reflect the system state (e.g. volume, temperature) which shall be shown on several displays and state-less if the API is used to primary query backends and no shared state is required. In general in embedded system a state-full service is preferred as the system shall reflect the machine state. A service is a vertical communication layer APIs in embedded devices are primary state-full Be aware that the service API will not directly consumed by the UI elements and rather be wrapped by a store API optimized for UI consumption. A service API will not be directly consumed by the UI Services are system features which expose an API surface published using primary a system specific IPC. A service is often defined as a client/server model, where the client (e.g. the UI or another service) and the server (a bundle of services in one process) communicate via an IPC (typically TCP/IP based or D-BUS based). During development a service needs to be simulated in case the endpoint is not available or depends on a hardware which is difficult to gain access to or work with. Often HW is also not available in an early project phase, still the UI development needs to start. When looking on a system there exists often many services, and ideally each service can be individually configured to use either a simulation or a real backend. Simulation and services will often be used across device boundaries. For example a host running the user interface tries to connect to an embedded device connected via an ethernet or serial connection. In these cases it is important that the selected IPC supports this use case. This is why the author things D-BUS is not a valid choice for this layer and TCP/IP based solutions are better suited. A service needs to support a simulation backend A simulation backend needs to be enabled per service For out-of-process services of the IPC is very specific to the individual project and the service needs to be able to adapt to this communication library. IN a rare case the project does not define an IPC solution and the developers can choose their best fiffting solution. There is a difference between the services consumed by the UI and the services the system is offering. Often system services are available using D-BUS as IPC and are meant to be consumed using some low-level API. These middle-ware services offer a higher-level API already defined with the UI in mind, still, the API is only loosely coupled towards the UI. It is assumed that this service API will change over the development time of the project and it will take several iterations to get a stable API. As such it is not wise that the UI directly consumes this API. The changes will lead to many small defects in the UI which will make it very hard to detect and fix them. Hint It is preferred that the service client API either be consumed by a C++ native extension or in a QML/JS based UI store. The C++ compiler will detect many API changes and report them before they appear in the UI and when using a QML/JS based store there needs to be 100% test coverage to ensure that these changes will be detected. It is important that the release cycle of the store API is fully controlled by the UI developer to avoid suprises and the release cycle of the service API is harmonized between the UI and platform developers. API Shape The API should be shaped after easy to understand patterns and ideally be familiar to the developer but also easy to explain to non-technical API authors. The API should define a common vocabulary and provide a way to structure larger projects. The API shall be shaped around the idea of a module. Each module is identified by a reverse URI (e.g. like a Java package convention). Each module can contain a list of interfaces. An interface is a collection of properties, operations and signals. The collection of properties define the state of the interface. The operations provide a mean to modify the state or to retrieve data. Signals allow a service to notify a client about external changes. It is assumed for pure property changes the API will auto-provide signals. - module # module is a namespace for all child symbols exists - Interface # named symbol which defines a set of properties , operations , and signals - Properties # data entry with a name and type - Operations # operation with parameters and return value - Signals # notification sent from the service back to the consumer - Struct # data structure to define a message - Fields # entries of a struct with name and type - Enum / Flag # An enumeration which can be used e . g . for properties and / or operations - Values # entries of an enumeration with name and value A module can have one or more interfaces, structs or enums/flags. As such a module is a higher level feature. To adhere to the micro-service architecture a service API should not depend directly on another service, instead, the API author should use identifiers (IDs), which are typically integers or strings to identify a resource from another module. Below is an example of a simple counter API. Please be aware this is a state-full example as the state of the interface is encoded in the count property. module counter 1.0 interface Counter { int count void increment () void decrement () } A state-less example would look like this module counter 1.0 interface Counter { int count () int increment () int decrement () } Interface Definition The API exposed by all middle-ware services needs to be harmonized across all services. To ensure a well defined and harmonized API can be created the API shall be defined in an interface definition language (IDL) with an attached code generation. The IDL should be independent of the target technology to allow securing the investment into an API also if the UI technology or the backend technolgy changes in the future. The IDL should be designed so that it is simple to understand and expressive. It should be able to express the API exact enough for developers to get an idea which code will be generated out of the API, still, it should be high level enough that a non-technical person understands which features are covered in the API. The IDL needs to be able to generate a well-defined API documentation for externals to lookup the documentation as a reference how to use the API. Also, the IDL shall allow extensions to provide meta information to transport project specific information such as deployment information or specific directives for the code generator. Code Generation The IDL should have a sophisticated code generator attached, ideally independent from the target technology, to allow customers to use a different technology or a different IPC. During the lifetime of a project, there are many needs to generate a different kind of source code or reports about an API. For example also if the client/server communication is done in C++ using a TCP/IP based IPC there might be a requirement during development to potentially use a WebSocket JSON protocol to make debugging easier. Also, developers would like to generate documentation with a custom style to map the project colors or in a format which can be consumed by their tool-chain. In the past, there was also some need to report back some statistics about the API. All of these use cases call for a flexible yet powerful code generation framework where a development team can use existing code generator or provide their own if the requirements of the project change. Still, the investment into the API definition should not be lost and be reusable. Service Implementation A service generated from the code generator should ideally already be compilable and runnable by the user also if it does not provide any implementation. This allows the user to implement features piece by piece iteratively. This normally results in a conflict if the code generator writes files which need to be edited by the user. It is important that the code generator differentiate between files which can be overwritten and those which need to be preserved for the user. The service implementation is typically based on an abstract base class which provides the interface to be implemented. The developer then needs to edit the concrete classes and implement the interface. Client Usage From the UI perspective the client should just be instantiated. The UI should be in charge to decide at which time a client is created and connected to the device. The client configuration should be read from some kind of data storage (e.g. settings file) and/or environment variable. By this configuration of the client is separated from the instantiation. The UI shall be in charge of the startup sequence. And as such must be able to delay certain clients only to be constructed on demand. A service API shall not be exposed to the UI, this is merely to allow better testing. For this a store wrappes the used service APIs in a common API for the UI. The store can be written either in QML/JS or C++. QML/JS is great during prototyping but C++ offers more performance and better control of the API usage. // store/RootStore.qml import services . phone 1.0 Store { id: root property alias callActive: phone . callActive PhoneService { id: phone active: true } function call ( number ) { if ( ! phone . enabled ) { return ; } phone . call ( number , function ( result ) { if ( result . error ) { console . warning ( 'ERROR: ' , result . error ); } }); } } Calling service function is often more complex than just calling the operation. Certain conditions defeind by the requirements specification and or error cases needs to be handled. To avoid this code pollutes the UI these functions are coded inside a store. Often used functions can also be encoded into helpers to even more reduce code clutter. Service Simulation Service simulation allows a client to be used without a real-service attached and furthermore allows the testing of service conditions which are difficult to establish. It is used in the UI creation when user stories need to be tested to ensure certain system conditions are established to effectively validate the user story. This does not replace the need for system testing as these kinds of prototypes are more designed to demo a user story to a product owner before it will be validated in the actual hardware. Establishing flexible simulated services is the key factor to separate the UI software from the hardware. Simulation needs to be switched per service base so that the system can run in a mixed simulation mode. This requires a service not to depend on other services which leads to a micro-service architecture. In case a service depends on an object from another service it is better to exchange object ids and the other service would acquire the object using this object id. A simulated service should be more than just a static representation of the service state, it should also be able to simulate the execution of operations and their effects. Ideally the simulation is able to simulate how data changes over time, e.g. a time or event based scripting. This could be a script attached to the simulated service or as simple as a timed data read from a file. The configuration of the services is ideally located in one shared document and can be edited to switch between real-services and simulated services. Most of the times a service is bound through a TCP/IP protocol, the switch could then be as simple as changing the port or the IP address of a service.","title":"Services"},{"location":"topics/services/#services","text":"Info This material is work in progress and will change! Services exposes features either from the system or a networked resource to the application layer. Services can be categorized based on their process-association, inter-service dependencies and the handling of state. In general a service is an instance of vertical communication. This vertical communication can be done via an IPC out-of-process or via a library in-process. The API can be designed state-less or state-full. You should prefer state-full if the API shall reflect the system state (e.g. volume, temperature) which shall be shown on several displays and state-less if the API is used to primary query backends and no shared state is required. In general in embedded system a state-full service is preferred as the system shall reflect the machine state. A service is a vertical communication layer APIs in embedded devices are primary state-full Be aware that the service API will not directly consumed by the UI elements and rather be wrapped by a store API optimized for UI consumption. A service API will not be directly consumed by the UI Services are system features which expose an API surface published using primary a system specific IPC. A service is often defined as a client/server model, where the client (e.g. the UI or another service) and the server (a bundle of services in one process) communicate via an IPC (typically TCP/IP based or D-BUS based). During development a service needs to be simulated in case the endpoint is not available or depends on a hardware which is difficult to gain access to or work with. Often HW is also not available in an early project phase, still the UI development needs to start. When looking on a system there exists often many services, and ideally each service can be individually configured to use either a simulation or a real backend. Simulation and services will often be used across device boundaries. For example a host running the user interface tries to connect to an embedded device connected via an ethernet or serial connection. In these cases it is important that the selected IPC supports this use case. This is why the author things D-BUS is not a valid choice for this layer and TCP/IP based solutions are better suited. A service needs to support a simulation backend A simulation backend needs to be enabled per service For out-of-process services of the IPC is very specific to the individual project and the service needs to be able to adapt to this communication library. IN a rare case the project does not define an IPC solution and the developers can choose their best fiffting solution. There is a difference between the services consumed by the UI and the services the system is offering. Often system services are available using D-BUS as IPC and are meant to be consumed using some low-level API. These middle-ware services offer a higher-level API already defined with the UI in mind, still, the API is only loosely coupled towards the UI. It is assumed that this service API will change over the development time of the project and it will take several iterations to get a stable API. As such it is not wise that the UI directly consumes this API. The changes will lead to many small defects in the UI which will make it very hard to detect and fix them. Hint It is preferred that the service client API either be consumed by a C++ native extension or in a QML/JS based UI store. The C++ compiler will detect many API changes and report them before they appear in the UI and when using a QML/JS based store there needs to be 100% test coverage to ensure that these changes will be detected. It is important that the release cycle of the store API is fully controlled by the UI developer to avoid suprises and the release cycle of the service API is harmonized between the UI and platform developers.","title":"Services"},{"location":"topics/services/#api-shape","text":"The API should be shaped after easy to understand patterns and ideally be familiar to the developer but also easy to explain to non-technical API authors. The API should define a common vocabulary and provide a way to structure larger projects. The API shall be shaped around the idea of a module. Each module is identified by a reverse URI (e.g. like a Java package convention). Each module can contain a list of interfaces. An interface is a collection of properties, operations and signals. The collection of properties define the state of the interface. The operations provide a mean to modify the state or to retrieve data. Signals allow a service to notify a client about external changes. It is assumed for pure property changes the API will auto-provide signals. - module # module is a namespace for all child symbols exists - Interface # named symbol which defines a set of properties , operations , and signals - Properties # data entry with a name and type - Operations # operation with parameters and return value - Signals # notification sent from the service back to the consumer - Struct # data structure to define a message - Fields # entries of a struct with name and type - Enum / Flag # An enumeration which can be used e . g . for properties and / or operations - Values # entries of an enumeration with name and value A module can have one or more interfaces, structs or enums/flags. As such a module is a higher level feature. To adhere to the micro-service architecture a service API should not depend directly on another service, instead, the API author should use identifiers (IDs), which are typically integers or strings to identify a resource from another module. Below is an example of a simple counter API. Please be aware this is a state-full example as the state of the interface is encoded in the count property. module counter 1.0 interface Counter { int count void increment () void decrement () } A state-less example would look like this module counter 1.0 interface Counter { int count () int increment () int decrement () }","title":"API Shape"},{"location":"topics/services/#interface-definition","text":"The API exposed by all middle-ware services needs to be harmonized across all services. To ensure a well defined and harmonized API can be created the API shall be defined in an interface definition language (IDL) with an attached code generation. The IDL should be independent of the target technology to allow securing the investment into an API also if the UI technology or the backend technolgy changes in the future. The IDL should be designed so that it is simple to understand and expressive. It should be able to express the API exact enough for developers to get an idea which code will be generated out of the API, still, it should be high level enough that a non-technical person understands which features are covered in the API. The IDL needs to be able to generate a well-defined API documentation for externals to lookup the documentation as a reference how to use the API. Also, the IDL shall allow extensions to provide meta information to transport project specific information such as deployment information or specific directives for the code generator.","title":"Interface Definition"},{"location":"topics/services/#code-generation","text":"The IDL should have a sophisticated code generator attached, ideally independent from the target technology, to allow customers to use a different technology or a different IPC. During the lifetime of a project, there are many needs to generate a different kind of source code or reports about an API. For example also if the client/server communication is done in C++ using a TCP/IP based IPC there might be a requirement during development to potentially use a WebSocket JSON protocol to make debugging easier. Also, developers would like to generate documentation with a custom style to map the project colors or in a format which can be consumed by their tool-chain. In the past, there was also some need to report back some statistics about the API. All of these use cases call for a flexible yet powerful code generation framework where a development team can use existing code generator or provide their own if the requirements of the project change. Still, the investment into the API definition should not be lost and be reusable.","title":"Code Generation"},{"location":"topics/services/#service-implementation","text":"A service generated from the code generator should ideally already be compilable and runnable by the user also if it does not provide any implementation. This allows the user to implement features piece by piece iteratively. This normally results in a conflict if the code generator writes files which need to be edited by the user. It is important that the code generator differentiate between files which can be overwritten and those which need to be preserved for the user. The service implementation is typically based on an abstract base class which provides the interface to be implemented. The developer then needs to edit the concrete classes and implement the interface.","title":"Service Implementation"},{"location":"topics/services/#client-usage","text":"From the UI perspective the client should just be instantiated. The UI should be in charge to decide at which time a client is created and connected to the device. The client configuration should be read from some kind of data storage (e.g. settings file) and/or environment variable. By this configuration of the client is separated from the instantiation. The UI shall be in charge of the startup sequence. And as such must be able to delay certain clients only to be constructed on demand. A service API shall not be exposed to the UI, this is merely to allow better testing. For this a store wrappes the used service APIs in a common API for the UI. The store can be written either in QML/JS or C++. QML/JS is great during prototyping but C++ offers more performance and better control of the API usage. // store/RootStore.qml import services . phone 1.0 Store { id: root property alias callActive: phone . callActive PhoneService { id: phone active: true } function call ( number ) { if ( ! phone . enabled ) { return ; } phone . call ( number , function ( result ) { if ( result . error ) { console . warning ( 'ERROR: ' , result . error ); } }); } } Calling service function is often more complex than just calling the operation. Certain conditions defeind by the requirements specification and or error cases needs to be handled. To avoid this code pollutes the UI these functions are coded inside a store. Often used functions can also be encoded into helpers to even more reduce code clutter.","title":"Client Usage"},{"location":"topics/services/#service-simulation","text":"Service simulation allows a client to be used without a real-service attached and furthermore allows the testing of service conditions which are difficult to establish. It is used in the UI creation when user stories need to be tested to ensure certain system conditions are established to effectively validate the user story. This does not replace the need for system testing as these kinds of prototypes are more designed to demo a user story to a product owner before it will be validated in the actual hardware. Establishing flexible simulated services is the key factor to separate the UI software from the hardware. Simulation needs to be switched per service base so that the system can run in a mixed simulation mode. This requires a service not to depend on other services which leads to a micro-service architecture. In case a service depends on an object from another service it is better to exchange object ids and the other service would acquire the object using this object id. A simulated service should be more than just a static representation of the service state, it should also be able to simulate the execution of operations and their effects. Ideally the simulation is able to simulate how data changes over time, e.g. a time or event based scripting. This could be a script attached to the simulated service or as simple as a timed data read from a file. The configuration of the services is ideally located in one shared document and can be edited to switch between real-services and simulated services. Most of the times a service is bound through a TCP/IP protocol, the switch could then be as simple as changing the port or the IP address of a service.","title":"Service Simulation"},{"location":"topics/styles/","text":"UI Styling Info This material is work in progress and will change! A style changes the visual appearance of styled controls. These can be common controls as part of the component library but also application controls or even containers. To be able to style a UI successfully, all controls need to adhere to a common style programming guide which shows the developer how to ensure that newly created components are styleable. In case the application does not use custom controls and all styling is already done by the common controls library and no work is needed here. This chapter is more for people who need to create custom controls or have specific UI requirements deviating from a common set. Skin / Style / Theme There are often different terms used for a similar set of functionality offered to change the appearance of the user interface. Here are the terms used in this book. Skin - A skin is a re-programming of the topmost UI layer. It may re-use or adapt larger parts of the existing UI code but in general, a skin deviates so much from the original UI that it can not be embedded into the original code and often this leads to a fork of the UI layer. Style - A central visual appearance hub to manage the appearance of controls. This can contain geometry, colors, effects, font and font geometry or other output methods. Theme - Themes are variants of a given Style. They change some properties of it, such as the color palette, but still share the same essence and major design features. A classic example is having a \"light\" and a \"dark\" theme for you Style, which you change at runtime depending on the time of day or user preference. A theme is the simplest visual change. A theme requires a style which supports the theming functionality. A skin changes the layout of the user interface. If the information architecture is preserved the work required is to re-write the UI layer based custom style. All appearance changes require they run on top of the same platform. Styling versus creating new controls You should strive to have the UI code of your QML application look familiar to any experienced QML UI developer. This means avoiding the introduction of new idioms and concepts unless when actually necessary. Qt Quick Controls 2 comes already with several common controls, such as Button, CheckBox, ComboBox, etc. It's worth making an effort to use those and make them look and behave according to your design specs via styling instead of jumping into the creation new controls such as MySpecialButton, MyProjectNameComboBox, and so on. It's a harder route, but it has multiple benefits, such as: It reduces the learning curve for new members in your team, as there are less new APIs and concepts to be learned. Makes your application easier to maintain. A consequence of the previous point. It's easier to port QML applications made for other platforms into your platform, as there are less APIs and concepts exclusive to your project or platform, which translates into less code changes. Don't reinvent the wheel, or \"stand on the shoulders of giants\". Time and effort was put into making the APIs of Qt Quick Controls 2 components, so it makes sense to try to use them instead of coming up with your own, which could be just duplicating effort. Customizing an existing Style This is the process of modifying one of the built-in styles. It is often the initial step when defining your own style. The API of the controls does not change and for an initial UI, using an existing style and tweaking it for your own purposes is notably simpler than creating a brand new one from scratch. How to customize an existing style is covered :qt5: here <qtquickcontrols2-styles.html> . Creating a new Style If your HMI has its own particlar look and feel, its own UI design guide, the :qt5: existing Qt Quick Controls 2 styles <qtquickcontrols2-styles.html> probably won't suite you and you will have to create your own style to implement what the UI/UX designers envisioned. To exemplify how this is achieved let's start with a simple UI, a sort of components gallery showcasing a handful of Qt Quick Controls 2 components in different states. import QtQuick 2.11 import QtQuick . Controls 2.1 Pane { width: 600 height: 600 Column { anchors.fill: parent padding: 50 spacing: 25 Row { spacing: 25 Button { text: \"Button\" } Button { text: \"Button\" ; enabled: false } } Row { spacing: 25 CheckBox { text: \"Checkbox\" } CheckBox { text: \"Checkbox\" ; checked: true } } Row { spacing: 25 Switch {} Switch { checked: true } } Label { text: \"Label\" } } } Save it as, say, controls.qml. Now run it with the qml tool $ qml controls.qml You should see something like this: Then try it with one of the styles shipped with Qt Quick Controls 2, such as \"material\" $ qml controls.qml -style material Or \"fusion\" (in a desktop environment that's using a dark theme) $ qml controls.qml -style fusion You can see that by using Qt Quick Controls 2 styles you can have the application code independent of the look and feel of its components. So no changes are needed in the components' API exposed to application code. Now we are going to create a new style that implements a different look and feel, which we will call \"foobar\". The first component we will customize in the foobar style is going to be the Pane, as it's the simplest. Create a subdirectory called \"foobar\". Then copy the file QT_INSTALL_DIR/qml/QtQuick/Controls.2/Pane.qml to it, where QT_INSTALL_DIR is the path where your Qt is installed. It should look like the following: import QtQuick 2.12 import QtQuick . Controls 2.5 import QtQuick . Controls . impl 2.5 import QtQuick . Templates 2.5 as T T . Pane { id: control implicitWidth: Math . max ( implicitBackgroundWidth + leftInset + rightInset , contentWidth + leftPadding + rightPadding ) implicitHeight: Math . max ( implicitBackgroundHeight + topInset + bottomInset , contentHeight + topPadding + bottomPadding ) padding: 12 background: Rectangle { color: control . palette . window } } The idea is to collect the standard implementation of the component whose look & feel you want to customize in your style from that directory in Qt to your own style directory and then modify it at will. In our foobar style we want the Pane background to be a Gradient instead, hence we will make the following change: ... background: Rectangle { gradient: Gradient { GradientStop { position: 0.0 ; color: \"dodgerblue\" } GradientStop { position: 1.0 ; color: \"lightsteelblue\" } } } ... Now let's run our controls.qml app with our brand new style. For that we will have to supply two additional environment variables: QT_QUICK_CONTROLS_STYLE_PATH to tell Qt where in the filesystem to look for more styles and QT_QUICK_CONTROLS_FALLBACK_STYLE to tell Qt which style to fallback on in case the chosen one is missing the implementation of some component (more info :qt5: here <qtquickcontrols2-environment.html> ). Since our foobar style just has the implementation of Pane, all other components will fallback to another implementation. $ QT_QUICK_CONTROLS_STYLE_PATH = . QT_QUICK_CONTROLS_FALLBACK_STYLE = Material qml controls.qml -style foobar Next we want to style the Button component. As with did with Pane, just copy Button.qml over from QT_INSTALL_DIR/qml/QtQuick/Controls.2 into our foobar style directory. If you open that file now you will see that it's quite more involded than the Pane: import QtQuick 2.12 import QtQuick . Controls 2.5 import QtQuick . Controls . impl 2.5 import QtQuick . Templates 2.5 as T T . Button { id: control implicitWidth: Math . max ( implicitBackgroundWidth + leftInset + rightInset , implicitContentWidth + leftPadding + rightPadding ) implicitHeight: Math . max ( implicitBackgroundHeight + topInset + bottomInset , implicitContentHeight + topPadding + bottomPadding ) padding: 6 horizontalPadding: padding + 2 spacing: 6 icon.width: 24 icon.height: 24 icon.color: control . checked || control . highlighted ? control.palette.brightText : control . flat && ! control . down ? ( control . visualFocus ? control.palette.highlight : control . palette . windowText ) : control . palette . buttonText contentItem: IconLabel { spacing: control . spacing mirrored: control . mirrored display: control . display icon: control . icon text: control . text font: control . font color: control . checked || control . highlighted ? control.palette.brightText : control . flat && ! control . down ? ( control . visualFocus ? control.palette.highlight : control . palette . windowText ) : control . palette . buttonText } background: Rectangle { implicitWidth: 100 implicitHeight: 40 visible: ! control . flat || control . down || control . checked || control . highlighted color: Color . blend ( control . checked || control . highlighted ? control.palette.dark : control . palette . button , control . palette . mid , control . down ? 0.5 : 0.0 ) border.color: control . palette . highlight border.width: control . visualFocus ? 2 : 0 } } You're free to change anything at will. This is just a default look & feel implementation. You're free to take it as it is, do some small modifications on top of it or wipe it out and do something completely different. What's important is to try to and obey the exising properties (icon, text, impleicitWidth, etc) as much as it makes sense to in your HMI usage and to put the foreground content of your button (eg, text and icon) in contentItem and its background, if any, in background . It's worth noting the widespread usage of the palette property. If you want to tweak its values in your style, the best place to do so would be in the Control.qml style implementation, as all Qt Quick Controls 2 components inherit from it. But if the categories (button, windowText, highlight, etc) in that palette type don't really suite your needs or your UI design guide you're free to use your own structure to keep your custom color and other values instead. We will come back to it later. For now let's just set a hardcoded background color, make the background rounded, make the button larger when down/pushed and have its text rotating (just because we can :) ). These would be the modifications: --- a/foobar/Button.qml +++ b/foobar/Button.qml @@ -15,12 +15,18 @@ T.Button { horizontalPadding: padding + 2 spacing: 6 + scale: control.down ? 1.4 : 1 + Behavior on scale { + NumberAnimation { easing.type: Easing.OutCubic; duration: 200 } + } + icon.width: 24 icon.height: 24 icon.color: control.checked || control.highlighted ? control.palette.brightText : control.flat && !control.down ? (control.visualFocus ? control.palette.highlight : control.palette.windowText) : control.palette.buttonText contentItem: IconLabel { + id: iconLabel spacing: control.spacing mirrored: control.mirrored display: control.display @@ -30,15 +36,29 @@ T.Button { font: control.font color: control.checked || control.highlighted ? control.palette.brightText : control.flat && !control.down ? (control.visualFocus ? control.palette.highlight : control.palette.windowText) : control.palette.buttonText + + RotationAnimator { + target: iconLabel + from: 0; to: 360 + duration: 1500 + running: true + loops: Animation.Infinite + } } background: Rectangle { implicitWidth: 100 implicitHeight: 40 visible: !control.flat || control.down || control.checked || control.highlighted - color: Color.blend(control.checked || control.highlighted ? control.palette.dark : control.palette.button, - control.palette.mid, control.down ? 0.5 : 0.0) + + color: \"seagreen\" + opacity: control.down ? 1 : 0.8 + Behavior on opacity { + NumberAnimation { easing.type: Easing.OutCubic; duration: 200 } + } + border.color: control.palette.highlight border.width: control.visualFocus ? 2 : 0 + radius: width / 2 } } If you run that application again you should see that the buttons are animated and look wildly different from the other styles. This is just to give an idea of how flexible and powerful the Qt Quick Controls 2 styling is. Collecting values in a Style object So far we have been hardcoding color values directly in the component's style implementation. But for better reusability it's prefferable to give them names and collect them all into a single entity. There are a couple of ways of doing it but, again, we will start with the simplest: creating a new qml module containing a singleton QtObject which will hold all the color and other values used throughout the style implementation. In this example we will name that singleton FoobarStyle . Create a subdirectory called imports and inside it yet another subdirectory called FoobarStyle , which will be the name of our qml module. Inside imports/FoobarStyle create a file named qmldir with the following content:: module FoobarStyle singleton FoobarStyle 1.0 FoobarStyle . qml Then proceed to create the file FoobarStyle.qml also inside imports/FoobarStyle :: pragma singleton import QtQuick 2.11 QtObject { property color gradientBackgroundTopColor : \"dodgerblue\" property color gradientBackgroundBottomColor : \"lightsteelblue\" property color buttonBackgroundColor : \"seagreen\" } FoobarStyle collects the colors have been used so far. You can have those names be more specific (eg. button background color) or more generic (eg. secondary control color) according to how they're used throught the implenentation and how your UI Style guide describes them. Now let's get back to Panel.qml and Button.qml replacing the hardcoded values with their corresponding named colors:: --- a/foobar/Button.qml +++ b/foobar/Button.qml @@ -3,6 +3,8 @@ import QtQuick.Controls 2.5 import QtQuick.Controls.impl 2.5 import QtQuick.Templates 2.5 as T +import FoobarStyle 1.0 + T.Button { id: control @@ -51,7 +53,7 @@ T.Button { implicitHeight: 40 visible: !control.flat || control.down || control.checked || control.highlighted - color: \"seagreen\" + color: FoobarStyle.buttonBackgroundColor opacity: control.down ? 1 : 0.8 Behavior on opacity { NumberAnimation { easing.type: Easing.OutCubic; duration: 200 } diff --git a/foobar/Pane.qml b/foobar/Pane.qml index f903afa..b82be7f 100644 --- a/foobar/Pane.qml +++ b/foobar/Pane.qml @@ -3,6 +3,8 @@ import QtQuick.Controls 2.5 import QtQuick.Controls.impl 2.5 import QtQuick.Templates 2.5 as T +import FoobarStyle 1.0 + T.Pane { id: control @@ -15,8 +17,8 @@ T.Pane { background: Rectangle { gradient: Gradient { - GradientStop { position: 0.0; color: \"dodgerblue\" } - GradientStop { position: 1.0; color: \"lightsteelblue\" } + GradientStop { position: 0.0; color: FoobarStyle.gradientBackgroundTopColor } + GradientStop { position: 1.0; color: FoobarStyle.gradientBackgroundBottomColor } } } } Now to be able to run our controls.qml application we will also have to tell the qml tool to look into the imports subdirectory for qml modules. Hence:: QT_QUICK_CONTROLS_STYLE_PATH = . QT_QUICK_CONTROLS_FALLBACK_STYLE = Material qml - I imports controls . qml - style foobar Note that having our named colors conveniently collected in a singleton also enables application code import FoobarStyle and use them directly whenever needed. Adding theming support After having our hardcoded values such as named colors collected in a singleton, adding theming support is a simple, straightforward, step. The idea is that a single property in FooBarStyle , which we will name as theme , will define the value of all others. So this is our improved FoobarStyle.qml , now with theme support: pragma Singleton import QtQuick 2.11 QtObject { // Available themes readonly property int dayTheme: 0 readonly property int nightTheme: 1 // The chosen theme property int theme: dayTheme // The values that make up a theme readonly property color gradientBackgroundTopColor: theme === dayTheme ? \"dodgerblue\" : \"black\" readonly property color gradientBackgroundBottomColor: theme === dayTheme ? \"lightsteelblue\" : \"darkblue\" readonly property color buttonBackgroundColor: theme === dayTheme ? \"seagreen\" : \"maroon\" } And modifying the application code, controls.qml , so that clicking on the first button switches the theme:: --- a/controls.qml +++ b/controls.qml @@ -1,6 +1,8 @@ import QtQuick 2.11 import QtQuick.Controls 2.1 +import FoobarStyle 1.0 + Pane { width: 500 height: 400 @@ -13,7 +15,16 @@ Pane { Row { spacing: 25 - Button { text: \"Button\" } + Button { + text: FoobarStyle.theme === FoobarStyle.dayTheme ? \"Day\" : \"Night\" + onClicked: { + if (FoobarStyle.theme === FoobarStyle.dayTheme) { + FoobarStyle.theme = FoobarStyle.nightTheme; + } else { + FoobarStyle.theme = FoobarStyle.dayTheme; + } + } + } Button { text: \"Button\"; enabled: false } } This is how our controls.qml application should look like after having the theme support added to it: Naming conventions One common mistake when naming colors in particular is naming them after what they look like instead of their function or where they are used. So avoid names such as \"orangeBackgroundColor\" or \"lightTextColor\" and prefer usage, such as \"buttonBackgroundColor\" or a category such as \"primaryColor\" or \"accentColor\". After all, as soon as you have a day/light and a night/dark theme, a color property that used to have a \"yellow\" or \"light\" value will switch to have the opposite, having a \"dark\" or \"brown\" one instead. Naming a color property after the visual caracteristics of its value will void the abstraction level (and hence flexibility) it provides when compared to using hardcoded values directly. Having that said, there might still be value in naming a color in a explicit way in your style object, such as FoobarStyle.red, meaning that whenever your UI uses red, it's not just any red, or the standard 0xFF0000, but a very particular hue of red, which is specified in your style. And that only if the usage of this named red throught the UI is always the same, regardless of the theme. Such as the red that makes up the visual identity of your company or the red that signifies alert or the interruption of a call. Note describe why a sheet is a good concept to display your controls and how should it be built.","title":"Styles"},{"location":"topics/styles/#ui-styling","text":"Info This material is work in progress and will change! A style changes the visual appearance of styled controls. These can be common controls as part of the component library but also application controls or even containers. To be able to style a UI successfully, all controls need to adhere to a common style programming guide which shows the developer how to ensure that newly created components are styleable. In case the application does not use custom controls and all styling is already done by the common controls library and no work is needed here. This chapter is more for people who need to create custom controls or have specific UI requirements deviating from a common set.","title":"UI Styling"},{"location":"topics/styles/#skin-style-theme","text":"There are often different terms used for a similar set of functionality offered to change the appearance of the user interface. Here are the terms used in this book. Skin - A skin is a re-programming of the topmost UI layer. It may re-use or adapt larger parts of the existing UI code but in general, a skin deviates so much from the original UI that it can not be embedded into the original code and often this leads to a fork of the UI layer. Style - A central visual appearance hub to manage the appearance of controls. This can contain geometry, colors, effects, font and font geometry or other output methods. Theme - Themes are variants of a given Style. They change some properties of it, such as the color palette, but still share the same essence and major design features. A classic example is having a \"light\" and a \"dark\" theme for you Style, which you change at runtime depending on the time of day or user preference. A theme is the simplest visual change. A theme requires a style which supports the theming functionality. A skin changes the layout of the user interface. If the information architecture is preserved the work required is to re-write the UI layer based custom style. All appearance changes require they run on top of the same platform.","title":"Skin / Style / Theme"},{"location":"topics/styles/#styling-versus-creating-new-controls","text":"You should strive to have the UI code of your QML application look familiar to any experienced QML UI developer. This means avoiding the introduction of new idioms and concepts unless when actually necessary. Qt Quick Controls 2 comes already with several common controls, such as Button, CheckBox, ComboBox, etc. It's worth making an effort to use those and make them look and behave according to your design specs via styling instead of jumping into the creation new controls such as MySpecialButton, MyProjectNameComboBox, and so on. It's a harder route, but it has multiple benefits, such as: It reduces the learning curve for new members in your team, as there are less new APIs and concepts to be learned. Makes your application easier to maintain. A consequence of the previous point. It's easier to port QML applications made for other platforms into your platform, as there are less APIs and concepts exclusive to your project or platform, which translates into less code changes. Don't reinvent the wheel, or \"stand on the shoulders of giants\". Time and effort was put into making the APIs of Qt Quick Controls 2 components, so it makes sense to try to use them instead of coming up with your own, which could be just duplicating effort.","title":"Styling versus creating new controls"},{"location":"topics/styles/#customizing-an-existing-style","text":"This is the process of modifying one of the built-in styles. It is often the initial step when defining your own style. The API of the controls does not change and for an initial UI, using an existing style and tweaking it for your own purposes is notably simpler than creating a brand new one from scratch. How to customize an existing style is covered :qt5: here <qtquickcontrols2-styles.html> .","title":"Customizing an existing Style"},{"location":"topics/styles/#creating-a-new-style","text":"If your HMI has its own particlar look and feel, its own UI design guide, the :qt5: existing Qt Quick Controls 2 styles <qtquickcontrols2-styles.html> probably won't suite you and you will have to create your own style to implement what the UI/UX designers envisioned. To exemplify how this is achieved let's start with a simple UI, a sort of components gallery showcasing a handful of Qt Quick Controls 2 components in different states. import QtQuick 2.11 import QtQuick . Controls 2.1 Pane { width: 600 height: 600 Column { anchors.fill: parent padding: 50 spacing: 25 Row { spacing: 25 Button { text: \"Button\" } Button { text: \"Button\" ; enabled: false } } Row { spacing: 25 CheckBox { text: \"Checkbox\" } CheckBox { text: \"Checkbox\" ; checked: true } } Row { spacing: 25 Switch {} Switch { checked: true } } Label { text: \"Label\" } } } Save it as, say, controls.qml. Now run it with the qml tool $ qml controls.qml You should see something like this: Then try it with one of the styles shipped with Qt Quick Controls 2, such as \"material\" $ qml controls.qml -style material Or \"fusion\" (in a desktop environment that's using a dark theme) $ qml controls.qml -style fusion You can see that by using Qt Quick Controls 2 styles you can have the application code independent of the look and feel of its components. So no changes are needed in the components' API exposed to application code. Now we are going to create a new style that implements a different look and feel, which we will call \"foobar\". The first component we will customize in the foobar style is going to be the Pane, as it's the simplest. Create a subdirectory called \"foobar\". Then copy the file QT_INSTALL_DIR/qml/QtQuick/Controls.2/Pane.qml to it, where QT_INSTALL_DIR is the path where your Qt is installed. It should look like the following: import QtQuick 2.12 import QtQuick . Controls 2.5 import QtQuick . Controls . impl 2.5 import QtQuick . Templates 2.5 as T T . Pane { id: control implicitWidth: Math . max ( implicitBackgroundWidth + leftInset + rightInset , contentWidth + leftPadding + rightPadding ) implicitHeight: Math . max ( implicitBackgroundHeight + topInset + bottomInset , contentHeight + topPadding + bottomPadding ) padding: 12 background: Rectangle { color: control . palette . window } } The idea is to collect the standard implementation of the component whose look & feel you want to customize in your style from that directory in Qt to your own style directory and then modify it at will. In our foobar style we want the Pane background to be a Gradient instead, hence we will make the following change: ... background: Rectangle { gradient: Gradient { GradientStop { position: 0.0 ; color: \"dodgerblue\" } GradientStop { position: 1.0 ; color: \"lightsteelblue\" } } } ... Now let's run our controls.qml app with our brand new style. For that we will have to supply two additional environment variables: QT_QUICK_CONTROLS_STYLE_PATH to tell Qt where in the filesystem to look for more styles and QT_QUICK_CONTROLS_FALLBACK_STYLE to tell Qt which style to fallback on in case the chosen one is missing the implementation of some component (more info :qt5: here <qtquickcontrols2-environment.html> ). Since our foobar style just has the implementation of Pane, all other components will fallback to another implementation. $ QT_QUICK_CONTROLS_STYLE_PATH = . QT_QUICK_CONTROLS_FALLBACK_STYLE = Material qml controls.qml -style foobar Next we want to style the Button component. As with did with Pane, just copy Button.qml over from QT_INSTALL_DIR/qml/QtQuick/Controls.2 into our foobar style directory. If you open that file now you will see that it's quite more involded than the Pane: import QtQuick 2.12 import QtQuick . Controls 2.5 import QtQuick . Controls . impl 2.5 import QtQuick . Templates 2.5 as T T . Button { id: control implicitWidth: Math . max ( implicitBackgroundWidth + leftInset + rightInset , implicitContentWidth + leftPadding + rightPadding ) implicitHeight: Math . max ( implicitBackgroundHeight + topInset + bottomInset , implicitContentHeight + topPadding + bottomPadding ) padding: 6 horizontalPadding: padding + 2 spacing: 6 icon.width: 24 icon.height: 24 icon.color: control . checked || control . highlighted ? control.palette.brightText : control . flat && ! control . down ? ( control . visualFocus ? control.palette.highlight : control . palette . windowText ) : control . palette . buttonText contentItem: IconLabel { spacing: control . spacing mirrored: control . mirrored display: control . display icon: control . icon text: control . text font: control . font color: control . checked || control . highlighted ? control.palette.brightText : control . flat && ! control . down ? ( control . visualFocus ? control.palette.highlight : control . palette . windowText ) : control . palette . buttonText } background: Rectangle { implicitWidth: 100 implicitHeight: 40 visible: ! control . flat || control . down || control . checked || control . highlighted color: Color . blend ( control . checked || control . highlighted ? control.palette.dark : control . palette . button , control . palette . mid , control . down ? 0.5 : 0.0 ) border.color: control . palette . highlight border.width: control . visualFocus ? 2 : 0 } } You're free to change anything at will. This is just a default look & feel implementation. You're free to take it as it is, do some small modifications on top of it or wipe it out and do something completely different. What's important is to try to and obey the exising properties (icon, text, impleicitWidth, etc) as much as it makes sense to in your HMI usage and to put the foreground content of your button (eg, text and icon) in contentItem and its background, if any, in background . It's worth noting the widespread usage of the palette property. If you want to tweak its values in your style, the best place to do so would be in the Control.qml style implementation, as all Qt Quick Controls 2 components inherit from it. But if the categories (button, windowText, highlight, etc) in that palette type don't really suite your needs or your UI design guide you're free to use your own structure to keep your custom color and other values instead. We will come back to it later. For now let's just set a hardcoded background color, make the background rounded, make the button larger when down/pushed and have its text rotating (just because we can :) ). These would be the modifications: --- a/foobar/Button.qml +++ b/foobar/Button.qml @@ -15,12 +15,18 @@ T.Button { horizontalPadding: padding + 2 spacing: 6 + scale: control.down ? 1.4 : 1 + Behavior on scale { + NumberAnimation { easing.type: Easing.OutCubic; duration: 200 } + } + icon.width: 24 icon.height: 24 icon.color: control.checked || control.highlighted ? control.palette.brightText : control.flat && !control.down ? (control.visualFocus ? control.palette.highlight : control.palette.windowText) : control.palette.buttonText contentItem: IconLabel { + id: iconLabel spacing: control.spacing mirrored: control.mirrored display: control.display @@ -30,15 +36,29 @@ T.Button { font: control.font color: control.checked || control.highlighted ? control.palette.brightText : control.flat && !control.down ? (control.visualFocus ? control.palette.highlight : control.palette.windowText) : control.palette.buttonText + + RotationAnimator { + target: iconLabel + from: 0; to: 360 + duration: 1500 + running: true + loops: Animation.Infinite + } } background: Rectangle { implicitWidth: 100 implicitHeight: 40 visible: !control.flat || control.down || control.checked || control.highlighted - color: Color.blend(control.checked || control.highlighted ? control.palette.dark : control.palette.button, - control.palette.mid, control.down ? 0.5 : 0.0) + + color: \"seagreen\" + opacity: control.down ? 1 : 0.8 + Behavior on opacity { + NumberAnimation { easing.type: Easing.OutCubic; duration: 200 } + } + border.color: control.palette.highlight border.width: control.visualFocus ? 2 : 0 + radius: width / 2 } } If you run that application again you should see that the buttons are animated and look wildly different from the other styles. This is just to give an idea of how flexible and powerful the Qt Quick Controls 2 styling is.","title":"Creating a new Style"},{"location":"topics/styles/#collecting-values-in-a-style-object","text":"So far we have been hardcoding color values directly in the component's style implementation. But for better reusability it's prefferable to give them names and collect them all into a single entity. There are a couple of ways of doing it but, again, we will start with the simplest: creating a new qml module containing a singleton QtObject which will hold all the color and other values used throughout the style implementation. In this example we will name that singleton FoobarStyle . Create a subdirectory called imports and inside it yet another subdirectory called FoobarStyle , which will be the name of our qml module. Inside imports/FoobarStyle create a file named qmldir with the following content:: module FoobarStyle singleton FoobarStyle 1.0 FoobarStyle . qml Then proceed to create the file FoobarStyle.qml also inside imports/FoobarStyle :: pragma singleton import QtQuick 2.11 QtObject { property color gradientBackgroundTopColor : \"dodgerblue\" property color gradientBackgroundBottomColor : \"lightsteelblue\" property color buttonBackgroundColor : \"seagreen\" } FoobarStyle collects the colors have been used so far. You can have those names be more specific (eg. button background color) or more generic (eg. secondary control color) according to how they're used throught the implenentation and how your UI Style guide describes them. Now let's get back to Panel.qml and Button.qml replacing the hardcoded values with their corresponding named colors:: --- a/foobar/Button.qml +++ b/foobar/Button.qml @@ -3,6 +3,8 @@ import QtQuick.Controls 2.5 import QtQuick.Controls.impl 2.5 import QtQuick.Templates 2.5 as T +import FoobarStyle 1.0 + T.Button { id: control @@ -51,7 +53,7 @@ T.Button { implicitHeight: 40 visible: !control.flat || control.down || control.checked || control.highlighted - color: \"seagreen\" + color: FoobarStyle.buttonBackgroundColor opacity: control.down ? 1 : 0.8 Behavior on opacity { NumberAnimation { easing.type: Easing.OutCubic; duration: 200 } diff --git a/foobar/Pane.qml b/foobar/Pane.qml index f903afa..b82be7f 100644 --- a/foobar/Pane.qml +++ b/foobar/Pane.qml @@ -3,6 +3,8 @@ import QtQuick.Controls 2.5 import QtQuick.Controls.impl 2.5 import QtQuick.Templates 2.5 as T +import FoobarStyle 1.0 + T.Pane { id: control @@ -15,8 +17,8 @@ T.Pane { background: Rectangle { gradient: Gradient { - GradientStop { position: 0.0; color: \"dodgerblue\" } - GradientStop { position: 1.0; color: \"lightsteelblue\" } + GradientStop { position: 0.0; color: FoobarStyle.gradientBackgroundTopColor } + GradientStop { position: 1.0; color: FoobarStyle.gradientBackgroundBottomColor } } } } Now to be able to run our controls.qml application we will also have to tell the qml tool to look into the imports subdirectory for qml modules. Hence:: QT_QUICK_CONTROLS_STYLE_PATH = . QT_QUICK_CONTROLS_FALLBACK_STYLE = Material qml - I imports controls . qml - style foobar Note that having our named colors conveniently collected in a singleton also enables application code import FoobarStyle and use them directly whenever needed.","title":"Collecting values in a Style object"},{"location":"topics/styles/#adding-theming-support","text":"After having our hardcoded values such as named colors collected in a singleton, adding theming support is a simple, straightforward, step. The idea is that a single property in FooBarStyle , which we will name as theme , will define the value of all others. So this is our improved FoobarStyle.qml , now with theme support: pragma Singleton import QtQuick 2.11 QtObject { // Available themes readonly property int dayTheme: 0 readonly property int nightTheme: 1 // The chosen theme property int theme: dayTheme // The values that make up a theme readonly property color gradientBackgroundTopColor: theme === dayTheme ? \"dodgerblue\" : \"black\" readonly property color gradientBackgroundBottomColor: theme === dayTheme ? \"lightsteelblue\" : \"darkblue\" readonly property color buttonBackgroundColor: theme === dayTheme ? \"seagreen\" : \"maroon\" } And modifying the application code, controls.qml , so that clicking on the first button switches the theme:: --- a/controls.qml +++ b/controls.qml @@ -1,6 +1,8 @@ import QtQuick 2.11 import QtQuick.Controls 2.1 +import FoobarStyle 1.0 + Pane { width: 500 height: 400 @@ -13,7 +15,16 @@ Pane { Row { spacing: 25 - Button { text: \"Button\" } + Button { + text: FoobarStyle.theme === FoobarStyle.dayTheme ? \"Day\" : \"Night\" + onClicked: { + if (FoobarStyle.theme === FoobarStyle.dayTheme) { + FoobarStyle.theme = FoobarStyle.nightTheme; + } else { + FoobarStyle.theme = FoobarStyle.dayTheme; + } + } + } Button { text: \"Button\"; enabled: false } } This is how our controls.qml application should look like after having the theme support added to it:","title":"Adding theming support"},{"location":"topics/styles/#naming-conventions","text":"One common mistake when naming colors in particular is naming them after what they look like instead of their function or where they are used. So avoid names such as \"orangeBackgroundColor\" or \"lightTextColor\" and prefer usage, such as \"buttonBackgroundColor\" or a category such as \"primaryColor\" or \"accentColor\". After all, as soon as you have a day/light and a night/dark theme, a color property that used to have a \"yellow\" or \"light\" value will switch to have the opposite, having a \"dark\" or \"brown\" one instead. Naming a color property after the visual caracteristics of its value will void the abstraction level (and hence flexibility) it provides when compared to using hardcoded values directly. Having that said, there might still be value in naming a color in a explicit way in your style object, such as FoobarStyle.red, meaning that whenever your UI uses red, it's not just any red, or the standard 0xFF0000, but a very particular hue of red, which is specified in your style. And that only if the usage of this named red throught the UI is always the same, regardless of the theme. Such as the red that makes up the visual identity of your company or the red that signifies alert or the interruption of a call. Note describe why a sheet is a good concept to display your controls and how should it be built.","title":"Naming conventions"},{"location":"topics/testing/","text":"Testing Info This material is work in progress and will change! There are different test strategies from white-box over black-box testing and system, integration and unit testing. System testing requires a whole system to operate and it will be stimulated from outside and the reaction to the stimulation will be validated. This test effort is not in the scope of this document. This chapter will mostly focus on the integration testing and and unit testing of the user interface layer. From the concept description we know there are control, panel, view, store and service component types in our architecture. These component are distributed on the UI layer (control, panel, view, store) and the middle-ware layer (service). Integration Testing When it comes to integration testing the most important aspect is how to integrate the UI layer with the underlying service layer and sure also the Qt5 components with the platform layer. There needs to be some mechanism to make this effort possible. UI Layer Integration Middle-ware Layer Integration Unit Testing A unit in our terms is a component. Also if this is not always exact it gives a good base to work on. To test a component you need to abstract away it dependencies. Control Testing A control is a UI part which only depends on Qt standard data types, as such it can be easily tested as there is no need to abstract away external extra dependencies. TestCase { id: root property Button control Component { id: component Button { } } function init () { // this is run for every test function control = createTemporaryObject ( component , root ); } SignalSpy { id: spy target: control signalName: \"clicked\" } function test_click () { compare ( spy . count , 0 ) control . clicked (); compare ( spy . count , 1 ) } } Panel Testing A panel is a UI container which similar to the control only depends on standard Qt data types. So there is also no need to extract away external dependencies. View Testing A view depends on the store and a store will depend on the services. So it is important to abstract away the store dependencies to allow a better testing if the views. Abstracting the store is the major issue in the testing strategy. A store abstraction is added called IRootStore which will contain the API of the root store. We need to use this IRootStore everywhere in the code to ensure we can switch it later with a root store mock. Here is how such a IRootStore would look like. // stores/IRootStore.qml import CoreUI 1.0 Store { id: root readonly property int count property var increment: function () { console . error ( \"increment not implemented\" ); } property var decrement: function () { console . error ( \"decrement not implemented\" ); } } The exposed API count, increment(), decrement() is implemented without a real implementation. The js functions are declared as var properties so that they can later be overwritten by an actual implementation. The actual store would have the real implementation using in this example a counter service. // stores/RootStore.qml IRootStore { id: root count: service . count property CounterService _service : CounterService { } increment: function () { return service . increment (); } decrement: function () { return service . decrement (); } } To create a mock store we can create one directly in the tests folder, called RootStoreMock. It derives from the IRootStore and implements the API in a way which can be tested. This means the results are exposed. It is also possible to add new API to the mocked store. These properties and functions should be prefixed with an _ to show the user this is not an official API of the root store. // stores/tests/RootStoreMock.qml import \"..\" IRootStore { id: root count: 0 property int _previousCount : count increment: function () { _previousCount = count ; count ++ ; return count ; } decrement: function () { _previousCount = count ; -- count ; return count ; } } Now with the mocked root store we can run the tests. // stores/tests/tst_welcomeview.qml import QtTest 1.1 import \"..\" import \"../mocked\" TestCase { id: root property WelcomeView view ; Component { id: component WelcomeView { store: RootStoreMock {} } } function init () { // this is run for every test function view = createTemporaryObject ( component , root ); // assert initial state compare ( 0 , view . store . count ); } // testing increment action function test_increment () { compare ( 0 , view . store . _previousCount ); var item = findChield ( view , \"increment\" ); mouseClick ( item ); compare ( 0 , view . store . _previousCount ); compare ( 1 , view . store . count ); mouseClick ( item ); compare ( 1 , view . store . _previousCount ); compare ( 2 , view . store . count ); } // testing decrement action function test_decrement () { var item = findChield ( view , \"decrement\" ); mouseClick ( item ); compare ( 0 , view . store . _previousCount ); compare ( - 1 , view . store . count ); } } This should give the reader an idea how to test an view component which depends on a store with many external dependencies. Store Testing A store depends on the services and as such it depends on the chosen service architecture and their limitations. Ideally a store could be tested using a service simulation back-end which will run inside the test process and which is fully controllable. A normal service implementation would use some kind of IPC and requires a second process to be started. As this way of testing is error prone (start two processes, await both are established, initiate connection, wait until connection ready, ...) it would be better we could create a custom service implementation inside our test and would not have to modify the service client. TestCase { id: root CounterService { id: service register: true increment: function () { count ++ ; } decrement: function () { count -- ; } } property IRootStore store ; Component { id: component RootStore { } } function init () { // this is run for every test function store = createTemporaryObject ( component , root ); // assert initial state compare ( 0 , store . count ); } void test_increment () { store . increment (); tryCompare ( store . count , service . count ); } void test_decrement () { store . decrement (); tryCompare ( store . count , service . count ); } } Note Discuss a way when the service can not be embedded into the test case, e.g. sequential testing ... In case the service can not be integrated into the QML test case it is often desirable to let the test case start the service server and reset the particular server. Additional the test should run in sequence. For this we would need to write a small plugin which controls the server (start/stop) ans waits notifies the test case when the server is fully loaded. Also the server control should expose a reset operation to reset the data on the server. Resetting is often faster then shutdown/startup sequence. Finally the test functions should be arranged in sequence. For this we need to ensure the tests are named in a way to they are ordered by name. TestCase { when: control . ready ServerControl { id: control services: \"counter\" } ServerSniffer { id: sniffer server: control . server } CounterClient { id: client } function test_001_increment () { sniffer . reset (); client . increment (); tryCompare ( sniffer . received , \"increment\" ) } function test_002_decrement () { sniffer . reset (); client . decrement (); tryCompare ( sniffer . received , \"decrement\" ) } } Service Testing Testing a service is often divided into testing the client, the transport and the service implementation. As the service implementation is not under the control of the UI layer it is out of scope here. A client can be tested if the simulation back-end uses the same client component and the same transport. A transport should always be tested in isolation as this is often an external library. If the simulation back-end uses a different client and only shares the client API then there is a need to ensure the client is also tested. Often this is not done due to a client is often semi-generated and there is no need to test generated code.","title":"Testing"},{"location":"topics/testing/#testing","text":"Info This material is work in progress and will change! There are different test strategies from white-box over black-box testing and system, integration and unit testing. System testing requires a whole system to operate and it will be stimulated from outside and the reaction to the stimulation will be validated. This test effort is not in the scope of this document. This chapter will mostly focus on the integration testing and and unit testing of the user interface layer. From the concept description we know there are control, panel, view, store and service component types in our architecture. These component are distributed on the UI layer (control, panel, view, store) and the middle-ware layer (service).","title":"Testing"},{"location":"topics/testing/#integration-testing","text":"When it comes to integration testing the most important aspect is how to integrate the UI layer with the underlying service layer and sure also the Qt5 components with the platform layer. There needs to be some mechanism to make this effort possible.","title":"Integration Testing"},{"location":"topics/testing/#ui-layer-integration","text":"","title":"UI Layer Integration"},{"location":"topics/testing/#middle-ware-layer-integration","text":"","title":"Middle-ware Layer Integration"},{"location":"topics/testing/#unit-testing","text":"A unit in our terms is a component. Also if this is not always exact it gives a good base to work on. To test a component you need to abstract away it dependencies.","title":"Unit Testing"},{"location":"topics/testing/#control-testing","text":"A control is a UI part which only depends on Qt standard data types, as such it can be easily tested as there is no need to abstract away external extra dependencies. TestCase { id: root property Button control Component { id: component Button { } } function init () { // this is run for every test function control = createTemporaryObject ( component , root ); } SignalSpy { id: spy target: control signalName: \"clicked\" } function test_click () { compare ( spy . count , 0 ) control . clicked (); compare ( spy . count , 1 ) } }","title":"Control Testing"},{"location":"topics/testing/#panel-testing","text":"A panel is a UI container which similar to the control only depends on standard Qt data types. So there is also no need to extract away external dependencies.","title":"Panel Testing"},{"location":"topics/testing/#view-testing","text":"A view depends on the store and a store will depend on the services. So it is important to abstract away the store dependencies to allow a better testing if the views. Abstracting the store is the major issue in the testing strategy. A store abstraction is added called IRootStore which will contain the API of the root store. We need to use this IRootStore everywhere in the code to ensure we can switch it later with a root store mock. Here is how such a IRootStore would look like. // stores/IRootStore.qml import CoreUI 1.0 Store { id: root readonly property int count property var increment: function () { console . error ( \"increment not implemented\" ); } property var decrement: function () { console . error ( \"decrement not implemented\" ); } } The exposed API count, increment(), decrement() is implemented without a real implementation. The js functions are declared as var properties so that they can later be overwritten by an actual implementation. The actual store would have the real implementation using in this example a counter service. // stores/RootStore.qml IRootStore { id: root count: service . count property CounterService _service : CounterService { } increment: function () { return service . increment (); } decrement: function () { return service . decrement (); } } To create a mock store we can create one directly in the tests folder, called RootStoreMock. It derives from the IRootStore and implements the API in a way which can be tested. This means the results are exposed. It is also possible to add new API to the mocked store. These properties and functions should be prefixed with an _ to show the user this is not an official API of the root store. // stores/tests/RootStoreMock.qml import \"..\" IRootStore { id: root count: 0 property int _previousCount : count increment: function () { _previousCount = count ; count ++ ; return count ; } decrement: function () { _previousCount = count ; -- count ; return count ; } } Now with the mocked root store we can run the tests. // stores/tests/tst_welcomeview.qml import QtTest 1.1 import \"..\" import \"../mocked\" TestCase { id: root property WelcomeView view ; Component { id: component WelcomeView { store: RootStoreMock {} } } function init () { // this is run for every test function view = createTemporaryObject ( component , root ); // assert initial state compare ( 0 , view . store . count ); } // testing increment action function test_increment () { compare ( 0 , view . store . _previousCount ); var item = findChield ( view , \"increment\" ); mouseClick ( item ); compare ( 0 , view . store . _previousCount ); compare ( 1 , view . store . count ); mouseClick ( item ); compare ( 1 , view . store . _previousCount ); compare ( 2 , view . store . count ); } // testing decrement action function test_decrement () { var item = findChield ( view , \"decrement\" ); mouseClick ( item ); compare ( 0 , view . store . _previousCount ); compare ( - 1 , view . store . count ); } } This should give the reader an idea how to test an view component which depends on a store with many external dependencies.","title":"View Testing"},{"location":"topics/testing/#store-testing","text":"A store depends on the services and as such it depends on the chosen service architecture and their limitations. Ideally a store could be tested using a service simulation back-end which will run inside the test process and which is fully controllable. A normal service implementation would use some kind of IPC and requires a second process to be started. As this way of testing is error prone (start two processes, await both are established, initiate connection, wait until connection ready, ...) it would be better we could create a custom service implementation inside our test and would not have to modify the service client. TestCase { id: root CounterService { id: service register: true increment: function () { count ++ ; } decrement: function () { count -- ; } } property IRootStore store ; Component { id: component RootStore { } } function init () { // this is run for every test function store = createTemporaryObject ( component , root ); // assert initial state compare ( 0 , store . count ); } void test_increment () { store . increment (); tryCompare ( store . count , service . count ); } void test_decrement () { store . decrement (); tryCompare ( store . count , service . count ); } } Note Discuss a way when the service can not be embedded into the test case, e.g. sequential testing ... In case the service can not be integrated into the QML test case it is often desirable to let the test case start the service server and reset the particular server. Additional the test should run in sequence. For this we would need to write a small plugin which controls the server (start/stop) ans waits notifies the test case when the server is fully loaded. Also the server control should expose a reset operation to reset the data on the server. Resetting is often faster then shutdown/startup sequence. Finally the test functions should be arranged in sequence. For this we need to ensure the tests are named in a way to they are ordered by name. TestCase { when: control . ready ServerControl { id: control services: \"counter\" } ServerSniffer { id: sniffer server: control . server } CounterClient { id: client } function test_001_increment () { sniffer . reset (); client . increment (); tryCompare ( sniffer . received , \"increment\" ) } function test_002_decrement () { sniffer . reset (); client . decrement (); tryCompare ( sniffer . received , \"decrement\" ) } }","title":"Store Testing"},{"location":"topics/testing/#service-testing","text":"Testing a service is often divided into testing the client, the transport and the service implementation. As the service implementation is not under the control of the UI layer it is out of scope here. A client can be tested if the simulation back-end uses the same client component and the same transport. A transport should always be tested in isolation as this is often an external library. If the simulation back-end uses a different client and only shares the client API then there is a need to ensure the client is also tested. Often this is not done due to a client is often semi-generated and there is no need to test generated code.","title":"Service Testing"},{"location":"topics/uilayer/","text":"User Interface Layer Info This material is work in progress and will change! The UI is the topmost layer in our software stack. It presents the user with important information and offers interactions to the user. It communicates vertically with the services. Blocks of the UI Layer The UI layer is divided into the system UI (SysUI) which acts as the bootstrapping UI, the application UIs (AppUI) and the Common Controls library as also the UI style definition as part of the controls library. The service APIs are used to communicate vertically with the underlying middle-ware services. The UI uses the Qt5 UI toolkit to render the user interface but also to use its platform abstraction to allow the user interface layer to run on various supported platforms. The UI layers follow a defined folder structure to be able to grow the UI in a controlled way, across teams. UI Tree We see the user interface as a tree of components. The root component often called Main.qml will import and create other child components and by this form the UI tree. Applications introduce boundaries into the tree. In a multi-process user interface these boundaries are created using processes. In the tree a window handle is used to keep track on the application process window. The window information is mirrored inside the application window surface. Other UI elements will then be childs to the window surface and continue the UI tree. In a single-process UI there are now windows for applications and an application boundary is just created by the physical location of the code. Note Create a diagram for UI tree The UI tree allows us to see the user interface layer not as a monolith it rather allows us to see the UI as a tree of sub-trees. And each sub-tree when it dependencies are satisfied can be run independent. To run a sub-tree in the simplest form your runtime will just load a different QML component then the Main.qml document. Passing the initial root document to the runtime is an important aspect of staying agile. As only this approach allows us to load partially UI trees. Based on the initial document loaded and the to be created sub-tree the UI may have different dependencies. It is important to understand the layers below the user interface to understand the UI layer itself. Beneath the UI Layer The platform, in general, encompasses the OS and the Qt5 UI Toolkit together with any custom Qt5 platform adaptation. Often the platform team is also responsible to deliver the service implementations as also the client side service API in co-operation with the UI developers. The service implementation and client-side service APIs can also be seen as a task for a middle-ware team separated from the platform delivery, as there is much domain-specific knowledge required and adapting the service API towards the system is an effort where specialized knowledge is being required. Eventhough the service blocks look small on the diagram, they can be very large as there are many different services even many different servers required to map a larger feature set for a UI into service APIs. Relocating the UI Layer As the UI layer sits \"only\" on top of Qt5 and the Service APIs, it can be relocated onto another machine running a different OS. This allows the development of a host platform and using the services via an IPC protocol on the target device. This separation allows the UI layer to be developed independently from the HW if simulation services are available. Simulation Services A simulation service is a service which exposes the same client API as the native service but has only a simulated implementation. The implementation can be fairly easy, e.g. using hardcoded data or it can be already rather complete, by providing behavior. Ideally, the simulated service is independent of the HW so that it can also be relocated. Also as a simulated service is often used to test certain conditions, it should be able to load different scenarios and simulate not only data but also behavior in a generic way. A simulated service often uses a simulation framework to allow scripting of behavior and advanced simulation data generation. As a simulated service, it is not necessary to really do the thing, rather just to look from the API user perspective. For example in the case of a music player, it is not required to play back music, but rather change the API values about the current song, album the playtime and other properties. Ideally, to support a flexible setup, there is a central document which lists all services and allows the developer to easily switch from a simulated service to a native service. If all services are not depending on each other, then directly these switchings should happen without a considerable side-effect. In case a service is identified by an URI the listing could be something like this: org.example : tcp://localhost:8154/org.example org.phone : simu://localhost/org.example The first entry would use a TCP connection to connect to the service module discoverable on the port 8154. The second entry would for example use the simulation protocol to a central simulation server running on the localhost. These are just examples of a potentially deployment document and shall just display a potential way of encoding the information. The exact way depends on the used IPC technology.","title":"UI Layer"},{"location":"topics/uilayer/#user-interface-layer","text":"Info This material is work in progress and will change! The UI is the topmost layer in our software stack. It presents the user with important information and offers interactions to the user. It communicates vertically with the services.","title":"User Interface Layer"},{"location":"topics/uilayer/#blocks-of-the-ui-layer","text":"The UI layer is divided into the system UI (SysUI) which acts as the bootstrapping UI, the application UIs (AppUI) and the Common Controls library as also the UI style definition as part of the controls library. The service APIs are used to communicate vertically with the underlying middle-ware services. The UI uses the Qt5 UI toolkit to render the user interface but also to use its platform abstraction to allow the user interface layer to run on various supported platforms. The UI layers follow a defined folder structure to be able to grow the UI in a controlled way, across teams.","title":"Blocks of the UI Layer"},{"location":"topics/uilayer/#ui-tree","text":"We see the user interface as a tree of components. The root component often called Main.qml will import and create other child components and by this form the UI tree. Applications introduce boundaries into the tree. In a multi-process user interface these boundaries are created using processes. In the tree a window handle is used to keep track on the application process window. The window information is mirrored inside the application window surface. Other UI elements will then be childs to the window surface and continue the UI tree. In a single-process UI there are now windows for applications and an application boundary is just created by the physical location of the code. Note Create a diagram for UI tree The UI tree allows us to see the user interface layer not as a monolith it rather allows us to see the UI as a tree of sub-trees. And each sub-tree when it dependencies are satisfied can be run independent. To run a sub-tree in the simplest form your runtime will just load a different QML component then the Main.qml document. Passing the initial root document to the runtime is an important aspect of staying agile. As only this approach allows us to load partially UI trees. Based on the initial document loaded and the to be created sub-tree the UI may have different dependencies. It is important to understand the layers below the user interface to understand the UI layer itself.","title":"UI Tree"},{"location":"topics/uilayer/#beneath-the-ui-layer","text":"The platform, in general, encompasses the OS and the Qt5 UI Toolkit together with any custom Qt5 platform adaptation. Often the platform team is also responsible to deliver the service implementations as also the client side service API in co-operation with the UI developers. The service implementation and client-side service APIs can also be seen as a task for a middle-ware team separated from the platform delivery, as there is much domain-specific knowledge required and adapting the service API towards the system is an effort where specialized knowledge is being required. Eventhough the service blocks look small on the diagram, they can be very large as there are many different services even many different servers required to map a larger feature set for a UI into service APIs.","title":"Beneath the UI Layer"},{"location":"topics/uilayer/#relocating-the-ui-layer","text":"As the UI layer sits \"only\" on top of Qt5 and the Service APIs, it can be relocated onto another machine running a different OS. This allows the development of a host platform and using the services via an IPC protocol on the target device. This separation allows the UI layer to be developed independently from the HW if simulation services are available.","title":"Relocating the UI Layer"},{"location":"topics/uilayer/#simulation-services","text":"A simulation service is a service which exposes the same client API as the native service but has only a simulated implementation. The implementation can be fairly easy, e.g. using hardcoded data or it can be already rather complete, by providing behavior. Ideally, the simulated service is independent of the HW so that it can also be relocated. Also as a simulated service is often used to test certain conditions, it should be able to load different scenarios and simulate not only data but also behavior in a generic way. A simulated service often uses a simulation framework to allow scripting of behavior and advanced simulation data generation. As a simulated service, it is not necessary to really do the thing, rather just to look from the API user perspective. For example in the case of a music player, it is not required to play back music, but rather change the API values about the current song, album the playtime and other properties. Ideally, to support a flexible setup, there is a central document which lists all services and allows the developer to easily switch from a simulated service to a native service. If all services are not depending on each other, then directly these switchings should happen without a considerable side-effect. In case a service is identified by an URI the listing could be something like this: org.example : tcp://localhost:8154/org.example org.phone : simu://localhost/org.example The first entry would use a TCP connection to connect to the service module discoverable on the port 8154. The second entry would for example use the simulation protocol to a central simulation server running on the localhost. These are just examples of a potentially deployment document and shall just display a potential way of encoding the information. The exact way depends on the used IPC technology.","title":"Simulation Services"}]}